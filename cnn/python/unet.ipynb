{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1aaff52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nb\n",
    "import SimpleITK as sitk\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import torch \n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb963f23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noisyDataSet1 shape: (1726, 344, 344)\n",
      "noisyDataSet2 shape: (1726, 344, 344)\n",
      "groundTruth shape: (1726, 344, 344)\n"
     ]
    }
   ],
   "source": [
    "noisyDataSet1_nii = sitk.ReadImage('./noisyDataSet1.nii')\n",
    "img_noisyDataSet1 = sitk.GetArrayFromImage(noisyDataSet1_nii)\n",
    "\n",
    "noisyDataSet2_nii = sitk.ReadImage('./noisyDataSet2.nii')\n",
    "img_noisyDataSet2 = sitk.GetArrayFromImage(noisyDataSet2_nii)\n",
    "\n",
    "groundTruth_nii = sitk.ReadImage('./groundTruth.nii')\n",
    "img_groundTruth = sitk.GetArrayFromImage(groundTruth_nii)\n",
    "\n",
    "print(\"noisyDataSet1 shape:\",img_noisyDataSet1.shape)\n",
    "print(\"noisyDataSet2 shape:\",img_noisyDataSet2.shape)\n",
    "print(\"groundTruth shape:\",img_groundTruth.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5f1e5fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2a116b8b6c8>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img_noisyDataSet2[780,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6d0d00c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1726, 1, 256, 256)\n",
      "(1726, 1, 256, 256)\n",
      "(1726, 1, 256, 256)\n"
     ]
    }
   ],
   "source": [
    "# Reshape for training\n",
    "\n",
    "img_noisyDataSet1 =img_noisyDataSet1[:,44:300,44:300]\n",
    "img_noisyDataSet2 =img_noisyDataSet2[:,44:300,44:300]\n",
    "img_groundTruth =img_groundTruth[:,44:300,44:300]\n",
    "\n",
    "img_noisyDataSet1 = np.expand_dims(img_noisyDataSet1, axis=-3)\n",
    "img_noisyDataSet2 = np.expand_dims(img_noisyDataSet2, axis=-3)\n",
    "img_groundTruth = np.expand_dims(img_groundTruth, axis=-3)\n",
    "\n",
    "print(img_noisyDataSet1.shape)\n",
    "print(img_noisyDataSet2.shape)\n",
    "print(img_groundTruth.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a22e3467",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Unet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Unet,self).__init__()\n",
    "        \n",
    "        # Contract\n",
    "        self.layer1Down = nn.Sequential (\n",
    "            torch.nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.BatchNorm2d(32),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.BatchNorm2d(32),\n",
    "            torch.nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.layer2Down = nn.Sequential (\n",
    "            torch.nn.Conv2d(32, 64, kernel_size = 3, stride=1, padding=1),\n",
    "            torch.nn.BatchNorm2d(64),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(64, 64, kernel_size= 3, stride=1, padding=1),\n",
    "            torch.nn.BatchNorm2d(64),\n",
    "            torch.nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.layer3Down = nn.Sequential (\n",
    "            torch.nn.Conv2d(64, 128, kernel_size = 3, stride=1, padding=1),\n",
    "            torch.nn.BatchNorm2d(128),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(128, 128, kernel_size = 3, stride=1, padding=1),\n",
    "            torch.nn.BatchNorm2d(128),\n",
    "            torch.nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.layer4Down = nn.Sequential (\n",
    "            torch.nn.Conv2d(128, 256, kernel_size = 3, stride=1, padding=1),\n",
    "            torch.nn.BatchNorm2d(256),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(256, 256, kernel_size = 3, stride=1, padding=1),\n",
    "            torch.nn.BatchNorm2d(256),\n",
    "            torch.nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.layer5Down = nn.Sequential (\n",
    "            torch.nn.Conv2d(256, 512, kernel_size = 3, stride=1, padding=1),\n",
    "            torch.nn.BatchNorm2d(512),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(512, 512, kernel_size = 3, stride=1, padding=1),\n",
    "            torch.nn.BatchNorm2d(512),\n",
    "            torch.nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.Pooling = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        #Expand\n",
    "        \n",
    "        self.layer5ConvTransposed = nn.Sequential ( \n",
    "            torch.nn.ConvTranspose2d(512, 256, kernel_size = 2, stride = 2, padding = 0)\n",
    "        )\n",
    "        \n",
    "        self.layer4Up = nn.Sequential (\n",
    "            torch.nn.Conv2d(512, 256, kernel_size = 3, stride=1, padding=1),\n",
    "            torch.nn.BatchNorm2d(256),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(256, 256, kernel_size = 3, stride=1, padding=1),\n",
    "            torch.nn.BatchNorm2d(256),\n",
    "            torch.nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.layer4ConvTransposed = nn.Sequential ( \n",
    "            torch.nn.ConvTranspose2d(256, 128, kernel_size = 2, stride = 2, padding = 0)\n",
    "        )\n",
    "        \n",
    "        self.layer3Up = nn.Sequential (\n",
    "            torch.nn.Conv2d(256, 128, kernel_size = 3, stride=1, padding=1),\n",
    "            torch.nn.BatchNorm2d(128),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(128, 128, kernel_size = 3, stride=1, padding=1),\n",
    "            torch.nn.BatchNorm2d(128),\n",
    "            torch.nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.layer3ConvTransposed = nn.Sequential ( \n",
    "            torch.nn.ConvTranspose2d(128, 64, kernel_size = 2, stride = 2, padding = 0)\n",
    "        )\n",
    "        \n",
    "        self.layer2Up = nn.Sequential (\n",
    "            torch.nn.Conv2d(128, 64, kernel_size = 3, stride=1, padding=1),\n",
    "            torch.nn.BatchNorm2d(64),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(64, 64, kernel_size = 3, stride=1, padding=1),\n",
    "            torch.nn.BatchNorm2d(64),\n",
    "            torch.nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.layer2ConvTransposed = nn.Sequential ( \n",
    "            torch.nn.ConvTranspose2d(64, 32, kernel_size = 2, stride = 2, padding = 0)\n",
    "        )\n",
    "        \n",
    "        self.layer1Up = nn.Sequential (\n",
    "            torch.nn.Conv2d(64, 32, kernel_size = 3, stride=1, padding=1),\n",
    "            torch.nn.BatchNorm2d(32),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(32, 32, kernel_size = 3, stride=1, padding=1),\n",
    "            torch.nn.BatchNorm2d(32),\n",
    "            torch.nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        # Down\n",
    "        conv1 = self.layer1Down(x)\n",
    "        maxPool1 = self.Pooling(conv1)\n",
    "        \n",
    "        \n",
    "        conv2 = self.layer2Down(maxPool1)\n",
    "        maxPool2 = self.Pooling(conv2)\n",
    "        \n",
    "        conv3 = self.layer3Down(maxPool2)\n",
    "        maxPool3 = self.Pooling(conv3)\n",
    "        \n",
    "        conv4 = self.layer4Down(maxPool3)\n",
    "        maxPool4 = self.Pooling(conv4)\n",
    "        \n",
    "        conv5 = self.layer5Down(maxPool4)\n",
    "        \n",
    "        # Up\n",
    "        layerConvTransposed = self.layer5ConvTransposed(conv5)\n",
    "        layer4UpData = torch.cat((layerConvTransposed,conv4), dim=1)\n",
    "        convTrans4 = self.layer4Up(layer4UpData)\n",
    "        \n",
    " \n",
    "        layerConvTransposed = self.layer4ConvTransposed(convTrans4)\n",
    "        layer3UpData = torch.cat((layerConvTransposed,conv3), dim = 1)\n",
    "        convTrans3 = self.layer3Up(layer3UpData)\n",
    "        \n",
    "        layerConvTransposed = self.layer3ConvTransposed(convTrans3)\n",
    "        layer2UpData = torch.cat((layerConvTransposed,conv2), dim = 1)\n",
    "        convTrans2 = self.layer2Up(layer2UpData)\n",
    "        \n",
    "        layerConvTransposed = self.layer2ConvTransposed(convTrans2)\n",
    "        layer1UpData = torch.cat((layerConvTransposed,conv1), dim = 1)\n",
    "        convTrans1 = self.layer1Up(layer1UpData)\n",
    "        \n",
    "        outNet = torch.nn.Conv2d(32,2, kernel_size = 1)(convTrans1)\n",
    "        return outNet\n",
    "\n",
    "unet = Unet()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b12c23cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    image = torch.rand((4, 1, 256, 256))\n",
    "    model = Unet()\n",
    "    out = unet(image)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab9b8227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Sequential: 1-1                        [-1, 32, 256, 256]        --\n",
      "|    └─Conv2d: 2-1                       [-1, 32, 256, 256]        320\n",
      "|    └─BatchNorm2d: 2-2                  [-1, 32, 256, 256]        64\n",
      "|    └─ReLU: 2-3                         [-1, 32, 256, 256]        --\n",
      "|    └─Conv2d: 2-4                       [-1, 32, 256, 256]        9,248\n",
      "|    └─BatchNorm2d: 2-5                  [-1, 32, 256, 256]        64\n",
      "|    └─ReLU: 2-6                         [-1, 32, 256, 256]        --\n",
      "├─MaxPool2d: 1-2                         [-1, 32, 128, 128]        --\n",
      "├─Sequential: 1-3                        [-1, 64, 128, 128]        --\n",
      "|    └─Conv2d: 2-7                       [-1, 64, 128, 128]        18,496\n",
      "|    └─BatchNorm2d: 2-8                  [-1, 64, 128, 128]        128\n",
      "|    └─ReLU: 2-9                         [-1, 64, 128, 128]        --\n",
      "|    └─Conv2d: 2-10                      [-1, 64, 128, 128]        36,928\n",
      "|    └─BatchNorm2d: 2-11                 [-1, 64, 128, 128]        128\n",
      "|    └─ReLU: 2-12                        [-1, 64, 128, 128]        --\n",
      "├─MaxPool2d: 1-4                         [-1, 64, 64, 64]          --\n",
      "├─Sequential: 1-5                        [-1, 128, 64, 64]         --\n",
      "|    └─Conv2d: 2-13                      [-1, 128, 64, 64]         73,856\n",
      "|    └─BatchNorm2d: 2-14                 [-1, 128, 64, 64]         256\n",
      "|    └─ReLU: 2-15                        [-1, 128, 64, 64]         --\n",
      "|    └─Conv2d: 2-16                      [-1, 128, 64, 64]         147,584\n",
      "|    └─BatchNorm2d: 2-17                 [-1, 128, 64, 64]         256\n",
      "|    └─ReLU: 2-18                        [-1, 128, 64, 64]         --\n",
      "├─MaxPool2d: 1-6                         [-1, 128, 32, 32]         --\n",
      "├─Sequential: 1-7                        [-1, 256, 32, 32]         --\n",
      "|    └─Conv2d: 2-19                      [-1, 256, 32, 32]         295,168\n",
      "|    └─BatchNorm2d: 2-20                 [-1, 256, 32, 32]         512\n",
      "|    └─ReLU: 2-21                        [-1, 256, 32, 32]         --\n",
      "|    └─Conv2d: 2-22                      [-1, 256, 32, 32]         590,080\n",
      "|    └─BatchNorm2d: 2-23                 [-1, 256, 32, 32]         512\n",
      "|    └─ReLU: 2-24                        [-1, 256, 32, 32]         --\n",
      "├─MaxPool2d: 1-8                         [-1, 256, 16, 16]         --\n",
      "├─Sequential: 1-9                        [-1, 512, 16, 16]         --\n",
      "|    └─Conv2d: 2-25                      [-1, 512, 16, 16]         1,180,160\n",
      "|    └─BatchNorm2d: 2-26                 [-1, 512, 16, 16]         1,024\n",
      "|    └─ReLU: 2-27                        [-1, 512, 16, 16]         --\n",
      "|    └─Conv2d: 2-28                      [-1, 512, 16, 16]         2,359,808\n",
      "|    └─BatchNorm2d: 2-29                 [-1, 512, 16, 16]         1,024\n",
      "|    └─ReLU: 2-30                        [-1, 512, 16, 16]         --\n",
      "├─Sequential: 1-10                       [-1, 256, 32, 32]         --\n",
      "|    └─ConvTranspose2d: 2-31             [-1, 256, 32, 32]         524,544\n",
      "├─Sequential: 1-11                       [-1, 256, 32, 32]         --\n",
      "|    └─Conv2d: 2-32                      [-1, 256, 32, 32]         1,179,904\n",
      "|    └─BatchNorm2d: 2-33                 [-1, 256, 32, 32]         512\n",
      "|    └─ReLU: 2-34                        [-1, 256, 32, 32]         --\n",
      "|    └─Conv2d: 2-35                      [-1, 256, 32, 32]         590,080\n",
      "|    └─BatchNorm2d: 2-36                 [-1, 256, 32, 32]         512\n",
      "|    └─ReLU: 2-37                        [-1, 256, 32, 32]         --\n",
      "├─Sequential: 1-12                       [-1, 128, 64, 64]         --\n",
      "|    └─ConvTranspose2d: 2-38             [-1, 128, 64, 64]         131,200\n",
      "├─Sequential: 1-13                       [-1, 128, 64, 64]         --\n",
      "|    └─Conv2d: 2-39                      [-1, 128, 64, 64]         295,040\n",
      "|    └─BatchNorm2d: 2-40                 [-1, 128, 64, 64]         256\n",
      "|    └─ReLU: 2-41                        [-1, 128, 64, 64]         --\n",
      "|    └─Conv2d: 2-42                      [-1, 128, 64, 64]         147,584\n",
      "|    └─BatchNorm2d: 2-43                 [-1, 128, 64, 64]         256\n",
      "|    └─ReLU: 2-44                        [-1, 128, 64, 64]         --\n",
      "├─Sequential: 1-14                       [-1, 64, 128, 128]        --\n",
      "|    └─ConvTranspose2d: 2-45             [-1, 64, 128, 128]        32,832\n",
      "├─Sequential: 1-15                       [-1, 64, 128, 128]        --\n",
      "|    └─Conv2d: 2-46                      [-1, 64, 128, 128]        73,792\n",
      "|    └─BatchNorm2d: 2-47                 [-1, 64, 128, 128]        128\n",
      "|    └─ReLU: 2-48                        [-1, 64, 128, 128]        --\n",
      "|    └─Conv2d: 2-49                      [-1, 64, 128, 128]        36,928\n",
      "|    └─BatchNorm2d: 2-50                 [-1, 64, 128, 128]        128\n",
      "|    └─ReLU: 2-51                        [-1, 64, 128, 128]        --\n",
      "├─Sequential: 1-16                       [-1, 32, 256, 256]        --\n",
      "|    └─ConvTranspose2d: 2-52             [-1, 32, 256, 256]        8,224\n",
      "├─Sequential: 1-17                       [-1, 32, 256, 256]        --\n",
      "|    └─Conv2d: 2-53                      [-1, 32, 256, 256]        18,464\n",
      "|    └─BatchNorm2d: 2-54                 [-1, 32, 256, 256]        64\n",
      "|    └─ReLU: 2-55                        [-1, 32, 256, 256]        --\n",
      "|    └─Conv2d: 2-56                      [-1, 32, 256, 256]        9,248\n",
      "|    └─BatchNorm2d: 2-57                 [-1, 32, 256, 256]        64\n",
      "|    └─ReLU: 2-58                        [-1, 32, 256, 256]        --\n",
      "==========================================================================================\n",
      "Total params: 7,765,376\n",
      "Trainable params: 7,765,376\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 13.65\n",
      "==========================================================================================\n",
      "Input size (MB): 1.00\n",
      "Forward/backward pass size (MB): 274.00\n",
      "Params size (MB): 29.62\n",
      "Estimated Total Size (MB): 304.62\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary = summary(unet, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9785bbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17b31791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(unet.parameters(), lr=0.0001)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16c562d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training U-net Model\n",
    "\n",
    "train_noisyImage,test_noisyImage,train_groundTruth,test_groundTruth = train_test_split(img_noisyDataSet1, img_groundTruth, test_size=0.2)\n",
    "\n",
    "valid_noisyImage = train_noisyImage[-5:,:,:,:]\n",
    "valid_groundTruth = train_groundTruth[-5:,:,:,:]\n",
    "\n",
    "train_noisyImage = train_noisyImage [:-5,:,:,:]\n",
    "train_groundTruth = train_groundTruth[:-5:,:,:,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a13de0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader (No funciona)\n",
    "\n",
    "# np to Tensor\n",
    "tensor_train_noisyImage = torch.Tensor(train_noisyImage)\n",
    "tensor_train_groundTruth = torch.Tensor(train_groundTruth)\n",
    "\n",
    "tensor_test_noisyImage = torch.Tensor(test_noisyImage)\n",
    "tensor_test_groundTruth = torch.Tensor(test_groundTruth)\n",
    "\n",
    "tensor_valid_noisyImage = torch.Tensor(valid_noisyImage)\n",
    "tensor_valid_groundTruth = torch.Tensor(valid_groundTruth)\n",
    "\n",
    "\n",
    "# dataloader\n",
    "trainloader = torch.utils.data.DataLoader((tensor_train_noisyImage,tensor_train_groundTruth), batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "validloader = torch.utils.data.DataLoader((tensor_valid_noisyImage,tensor_valid_groundTruth), batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader((tensor_test_noisyImage,tensor_test_groundTruth), batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "\n",
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "    \n",
    "    running_loss = 0.0\n",
    "\n",
    "    for i, (inputs, trainGroundTruth) in enumerate(trainloader):\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = unet(inputs)\n",
    "        loss = criterion(outputs, trainGroundTruth)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf78e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,     1] loss: 0.025\n",
      "[1,   101] loss: 1.422\n",
      "[1,   201] loss: 1.295\n",
      "[1,   301] loss: 1.505\n",
      "[1,   401] loss: 1.431\n",
      "[1,   501] loss: 1.338\n"
     ]
    }
   ],
   "source": [
    "# Tensores\n",
    "\n",
    "for epoch in range(2):  \n",
    "    \n",
    "    running_loss = 0.0\n",
    "\n",
    "    for i in range(0, train_noisyImage.shape[0]):\n",
    "        \n",
    "        # Acondicionamiento de datos\n",
    "        \n",
    "        inputs = train_noisyImage[i]\n",
    "        inputs = np.expand_dims(inputs, axis=-3)\n",
    "        inputs = torch.Tensor(inputs)\n",
    "        \n",
    "        trainGroundTruth = train_groundTruth[i]\n",
    "        trainGroundTruth = np.expand_dims(trainGroundTruth, axis=-3)\n",
    "        trainGroundTruth = torch.Tensor(trainGroundTruth)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = unet(inputs)\n",
    "        loss = criterion(outputs, trainGroundTruth)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 0:    \n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss/100:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d978288",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
