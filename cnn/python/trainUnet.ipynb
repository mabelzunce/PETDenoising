{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "756ef75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nb\n",
    "import SimpleITK as sitk\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "\n",
    "import torch \n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import datetime\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbdc56a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unet CLASICA (nuevo formato)\n",
    "\n",
    "class DownConv(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels , out_channels):\n",
    "        super(DownConv, self).__init__()\n",
    "        self.DownLayer = nn.Sequential(\n",
    "\n",
    "            torch.nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            torch.nn.BatchNorm2d(out_channels),\n",
    "            torch.nn.ReLU(inplace = True),\n",
    "            torch.nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            torch.nn.BatchNorm2d(out_channels),\n",
    "            torch.nn.ReLU(inplace = True),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x ):\n",
    "        x = self.DownLayer(x)\n",
    "        return x\n",
    "    \n",
    "        \n",
    "class MaxPool(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MaxPool, self).__init__()\n",
    "        self.Pool = torch.nn.MaxPool2d(kernel_size = 2)\n",
    "        \n",
    "    def forward (self,x):\n",
    "        x = self.Pool(x)\n",
    "        return x\n",
    "    \n",
    "        \n",
    "class UpConv(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels , out_channels):\n",
    "        super(UpConv, self).__init__()\n",
    "        \n",
    "        self.ConvTransp = torch.nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        #self.ConvTransp = torch.nn.ConvTranspose2d((in_channels//2), out_channels, kernel_size = 2, stride = 2, padding = 0)\n",
    "        self.UpConv = DownConv(in_channels, out_channels)\n",
    "        \n",
    "    def forward(self, xAnt , xDown):\n",
    "            \n",
    "        layerConvTransposed = self.ConvTransp(xAnt)\n",
    "        concat = torch.cat([layerConvTransposed,xDown], dim=1)\n",
    "        x = self.UpConv(concat)\n",
    "            \n",
    "        return x\n",
    "\n",
    "class OutUnet(nn.Module):\n",
    "    def __init__(self, in_channels , out_channels):\n",
    "        super(OutUnet, self).__init__()\n",
    "        self.OutUnet = torch.nn.Conv2d(in_channels,out_channels, kernel_size = 1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.OutUnet(x)\n",
    "        return x\n",
    "\n",
    "class Unet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Unet,self).__init__()\n",
    "        \n",
    "        # Contract\n",
    "        self.Layer1Down = DownConv(1,32)\n",
    "        self.Layer2Down = DownConv(32,64)\n",
    "        self.Layer3Down = DownConv(64,128)\n",
    "        self.Layer4Down = DownConv(128,256)\n",
    "        self.Layer5Down = DownConv(256,512)\n",
    "        \n",
    "        self.Middle = DownConv(512,512)\n",
    "        \n",
    "        self.Layer1Up = UpConv(1024,256)\n",
    "        self.Layer2Up = UpConv(512,128)\n",
    "        self.Layer3Up = UpConv(256,64)\n",
    "        self.Layer4Up = UpConv(128,64)\n",
    "        self.Layer5Up = UpConv(64+32,32)\n",
    "        \n",
    "        self.MaxPool = MaxPool()\n",
    "        \n",
    "        self.Out = OutUnet(32,1)\n",
    "        \n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        # Down\n",
    "        conv1 = self.Layer1Down(x)\n",
    "        maxPool1 = self.MaxPool(conv1)\n",
    "        \n",
    "        conv2 = self.Layer2Down(maxPool1)\n",
    "        maxPool2 = self.MaxPool(conv2)\n",
    "        \n",
    "        conv3 = self.Layer3Down(maxPool2)\n",
    "        maxPool3 = self.MaxPool(conv3)\n",
    "        \n",
    "        conv4 = self.Layer4Down(maxPool3)\n",
    "        maxPool4 = self.MaxPool(conv4)\n",
    "        \n",
    "        conv5 = self.Layer5Down(maxPool4)\n",
    "        maxPool5 = self.MaxPool(conv5)\n",
    "        \n",
    "        middle = self.Middle(maxPool5)\n",
    "        \n",
    "        # Up\n",
    "        up1= self.Layer1Up(middle,conv5)\n",
    "        up2= self.Layer2Up(up1,conv4)\n",
    "        up3= self.Layer3Up(up2,conv3)\n",
    "        up4= self.Layer4Up(up3,conv2)\n",
    "        up5= self.Layer5Up(up4,conv1)\n",
    "        \n",
    "        outUNet = self.Out(up5)\n",
    "        \n",
    "        return outUNet\n",
    "\n",
    "unet = Unet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ea044b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noisyDataSet1 shape: (1726, 344, 344)\n",
      "noisyDataSet2 shape: (1726, 344, 344)\n",
      "groundTruth shape: (1726, 344, 344)\n"
     ]
    }
   ],
   "source": [
    "# Importo base de datos\n",
    "\n",
    "noisyDataSet1_nii = sitk.ReadImage('./noisyDataSet1.nii')\n",
    "img_noisyDataSet1 = sitk.GetArrayFromImage(noisyDataSet1_nii)\n",
    "\n",
    "noisyDataSet2_nii = sitk.ReadImage('./noisyDataSet2.nii')\n",
    "img_noisyDataSet2 = sitk.GetArrayFromImage(noisyDataSet2_nii)\n",
    "\n",
    "groundTruth_nii = sitk.ReadImage('./groundTruth.nii')\n",
    "img_groundTruth = sitk.GetArrayFromImage(groundTruth_nii)\n",
    "\n",
    "print(\"noisyDataSet1 shape:\",img_noisyDataSet1.shape)\n",
    "print(\"noisyDataSet2 shape:\",img_noisyDataSet2.shape)\n",
    "print(\"groundTruth shape:\",img_groundTruth.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2520a40d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1726, 1, 256, 256)\n",
      "(1726, 1, 256, 256)\n",
      "(1726, 1, 256, 256)\n"
     ]
    }
   ],
   "source": [
    "# Reshape for training\n",
    "\n",
    "img_noisyDataSet1 =img_noisyDataSet1[:,44:300,44:300]\n",
    "img_noisyDataSet2 =img_noisyDataSet2[:,44:300,44:300]\n",
    "img_groundTruth =img_groundTruth[:,44:300,44:300]\n",
    "\n",
    "\n",
    "img_noisyDataSet1 = (np.expand_dims(img_noisyDataSet1, axis=-3)).astype(np.float32)\n",
    "img_noisyDataSet2 = (np.expand_dims(img_noisyDataSet2, axis=-3)).astype(np.float32)\n",
    "img_groundTruth = (np.expand_dims(img_groundTruth, axis=-3)).astype(np.float32)\n",
    "\n",
    "print(img_noisyDataSet1.shape)\n",
    "print(img_noisyDataSet2.shape)\n",
    "print(img_groundTruth.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6eb18a7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data set size. Training set: 1208. Valid set: 518.\n"
     ]
    }
   ],
   "source": [
    "# Conjunto de entrenamiento, testeo y validacion\n",
    "\n",
    "train_noisyImage,valid_noisyImage,train_groundTruth,valid_groundTruth = train_test_split(img_noisyDataSet1, img_groundTruth, test_size=0.3)\n",
    "\n",
    "# Create dictionaries with training sets:\n",
    "trainingSet = dict([('input',train_noisyImage), ('output', train_groundTruth)])\n",
    "validSet = dict([('input',valid_noisyImage), ('output', valid_groundTruth)])\n",
    "\n",
    "print('Data set size. Training set: {0}. Valid set: {1}.'.format(trainingSet['input'].shape[0], validSet['input'].shape[0]))\n",
    "\n",
    "# Entrenamiento #\n",
    "\n",
    "# Loss and optimizer\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(unet.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e53df2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test set\n",
    "\n",
    "inputsTestSet = torch.from_numpy(trainingSet['input'][i*batchSize:(i+1)*batchSize,:,:,:])\n",
    "inputsTestSet = torchvision.transforms.functional.rotate(inputsTestSet,15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab85de4a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,     1] loss: 0.077\n",
      "[1,     2] loss: 0.113\n",
      "[1,     3] loss: 0.072\n",
      "[1,     4] loss: 0.143\n",
      "[1,     5] loss: 0.073\n",
      "[1,     6] loss: 0.100\n",
      "[1,     7] loss: 0.062\n",
      "[1,     8] loss: 0.076\n",
      "[1,     9] loss: 0.111\n",
      "[1,    10] loss: 0.068\n",
      "[1,    11] loss: 0.075\n",
      "[1,    12] loss: 0.063\n",
      "[1,    13] loss: 0.067\n",
      "[1,    14] loss: 0.137\n",
      "[1,    15] loss: 0.087\n",
      "[1,    16] loss: 0.069\n",
      "[1,    17] loss: 0.072\n",
      "[1,    18] loss: 0.059\n",
      "[1,    19] loss: 0.051\n",
      "[1,    20] loss: 0.070\n",
      "[1,    21] loss: 0.071\n",
      "[1,    22] loss: 0.116\n",
      "[1,    23] loss: 0.051\n",
      "[1,    24] loss: 0.060\n",
      "[1,    25] loss: 0.062\n",
      "[1,    26] loss: 0.161\n",
      "[1,    27] loss: 0.091\n",
      "[1,    28] loss: 0.108\n",
      "[1,    29] loss: 0.171\n",
      "[1,    30] loss: 0.060\n",
      "[1,    31] loss: 0.091\n",
      "[1,    32] loss: 0.062\n",
      "[1,    33] loss: 0.062\n",
      "[1,    34] loss: 0.072\n",
      "[1,    35] loss: 0.080\n",
      "[1,    36] loss: 0.097\n",
      "[1,    37] loss: 0.064\n",
      "[1,    38] loss: 0.085\n",
      "[1,    39] loss: 0.058\n",
      "[1,    40] loss: 0.097\n",
      "[1,    41] loss: 0.097\n",
      "[1,    42] loss: 0.152\n",
      "[1,    43] loss: 0.078\n",
      "[1,    44] loss: 0.063\n",
      "[1,    45] loss: 0.084\n",
      "[1,    46] loss: 0.071\n",
      "[1,    47] loss: 0.070\n",
      "[1,    48] loss: 0.099\n",
      "[1,    49] loss: 0.062\n",
      "[1,    50] loss: 0.058\n",
      "[1,    51] loss: 0.131\n",
      "[1,    52] loss: 0.237\n",
      "[1,    53] loss: 0.062\n",
      "[1,    54] loss: 0.098\n",
      "[1,    55] loss: 0.060\n",
      "[1,    56] loss: 0.090\n",
      "[1,    57] loss: 0.106\n",
      "[1,    58] loss: 0.084\n",
      "[1,    59] loss: 0.064\n",
      "[1,    60] loss: 0.073\n",
      "[1,    61] loss: 0.059\n",
      "[1,    62] loss: 0.073\n",
      "[1,    63] loss: 0.060\n",
      "[1,    64] loss: 0.116\n",
      "[1,    65] loss: 0.109\n",
      "[1,    66] loss: 0.091\n",
      "[1,    67] loss: 0.109\n",
      "[1,    68] loss: 0.199\n",
      "[1,    69] loss: 0.063\n",
      "[1,    70] loss: 0.092\n",
      "[1,    71] loss: 0.078\n",
      "[1,    72] loss: 0.079\n",
      "[1,    73] loss: 0.070\n",
      "[1,    74] loss: 0.058\n",
      "[1,    75] loss: 0.136\n",
      "[1,    76] loss: 0.074\n",
      "[1,    77] loss: 0.070\n",
      "[1,    78] loss: 0.058\n",
      "[1,    79] loss: 0.093\n",
      "[1,    80] loss: 0.055\n",
      "[1,    81] loss: 0.082\n",
      "[1,    82] loss: 0.050\n",
      "[1,    83] loss: 0.076\n",
      "[1,    84] loss: 0.060\n",
      "[1,    85] loss: 0.069\n",
      "[1,    86] loss: 0.061\n",
      "[1,    87] loss: 0.089\n",
      "[1,    88] loss: 0.083\n",
      "[1,    89] loss: 0.133\n",
      "[1,    90] loss: 0.087\n",
      "[1,    91] loss: 0.074\n",
      "[1,    92] loss: 0.123\n",
      "[1,    93] loss: 0.046\n",
      "[1,    94] loss: 0.051\n",
      "[1,    95] loss: 0.095\n",
      "[1,    96] loss: 0.076\n",
      "[1,    97] loss: 0.079\n",
      "[1,    98] loss: 0.095\n",
      "[1,    99] loss: 0.092\n",
      "[1,   100] loss: 0.060\n",
      "[1,   101] loss: 0.054\n",
      "[1,   102] loss: 0.083\n",
      "[1,   103] loss: 0.077\n",
      "[1,   104] loss: 0.122\n",
      "[1,   105] loss: 0.118\n",
      "[1,   106] loss: 0.075\n",
      "[1,   107] loss: 0.051\n",
      "[1,   108] loss: 0.063\n",
      "[1,   109] loss: 0.045\n",
      "[1,   110] loss: 0.054\n",
      "[1,   111] loss: 0.049\n",
      "[1,   112] loss: 0.061\n",
      "[1,   113] loss: 0.063\n",
      "[1,   114] loss: 0.060\n",
      "[1,   115] loss: 0.050\n",
      "[1,   116] loss: 0.044\n",
      "[1,   117] loss: 0.066\n",
      "[1,   118] loss: 0.068\n",
      "[1,   119] loss: 0.082\n",
      "[1,   120] loss: 0.077\n",
      "[1,   121] loss: 0.045\n",
      "[1,   122] loss: 0.066\n",
      "[1,   123] loss: 0.078\n",
      "[1,   124] loss: 0.051\n",
      "[1,   125] loss: 0.052\n",
      "[1,   126] loss: 0.084\n",
      "[1,   127] loss: 0.084\n",
      "[1,   128] loss: 0.102\n",
      "[1,   129] loss: 0.204\n",
      "[1,   130] loss: 0.135\n",
      "[1,   131] loss: 0.056\n",
      "[1,   132] loss: 0.071\n",
      "[1,   133] loss: 0.092\n",
      "[1,   134] loss: 0.055\n",
      "[1,   135] loss: 0.137\n",
      "[1,   136] loss: 0.102\n",
      "[1,   137] loss: 0.046\n",
      "[1,   138] loss: 0.104\n",
      "[1,   139] loss: 0.069\n",
      "[1,   140] loss: 0.099\n",
      "[1,   141] loss: 0.054\n",
      "[1,   142] loss: 0.137\n",
      "[1,   143] loss: 0.072\n",
      "[1,   144] loss: 0.076\n",
      "[1,   145] loss: 0.081\n",
      "[1,   146] loss: 0.061\n",
      "[1,   147] loss: 0.086\n",
      "[1,   148] loss: 0.074\n",
      "[1,   149] loss: 0.049\n",
      "[1,   150] loss: 0.059\n",
      "[1,   151] loss: 0.071\n",
      "[1,   152] loss: 0.067\n",
      "[1,   153] loss: 0.067\n",
      "[1,   154] loss: 0.053\n",
      "[1,   155] loss: 0.049\n",
      "[1,   156] loss: 0.047\n",
      "[1,   157] loss: 0.045\n",
      "[1,   158] loss: 0.203\n",
      "[1,   159] loss: 0.052\n",
      "[1,   160] loss: 0.107\n",
      "[1,   161] loss: 0.050\n",
      "[1,   162] loss: 0.080\n",
      "[1,   163] loss: 0.077\n",
      "[1,   164] loss: 0.038\n",
      "[1,   165] loss: 0.061\n",
      "[1,   166] loss: 0.040\n",
      "[1,   167] loss: 0.090\n",
      "[1,   168] loss: 0.098\n",
      "[1,   169] loss: 0.053\n",
      "[1,   170] loss: 0.070\n",
      "[1,   171] loss: 0.047\n",
      "[1,   172] loss: 0.090\n",
      "[1,   173] loss: 0.073\n",
      "[1,   174] loss: 0.060\n",
      "[1,   175] loss: 0.088\n",
      "[1,   176] loss: 0.071\n",
      "[1,   177] loss: 0.043\n",
      "[1,   178] loss: 0.081\n",
      "[1,   179] loss: 0.073\n",
      "[1,   180] loss: 0.075\n",
      "[1,   181] loss: 0.068\n",
      "[1,   182] loss: 0.068\n",
      "[1,   183] loss: 0.100\n",
      "[1,   184] loss: 0.057\n",
      "[1,   185] loss: 0.072\n",
      "[1,   186] loss: 0.084\n",
      "[1,   187] loss: 0.094\n",
      "[1,   188] loss: 0.083\n",
      "[1,   189] loss: 0.141\n",
      "[1,   190] loss: 0.037\n",
      "[1,   191] loss: 0.087\n",
      "[1,   192] loss: 0.073\n",
      "[1,   193] loss: 0.076\n",
      "[1,   194] loss: 0.051\n",
      "[1,   195] loss: 0.122\n",
      "[1,   196] loss: 0.142\n",
      "[1,   197] loss: 0.044\n",
      "[1,   198] loss: 0.116\n",
      "[1,   199] loss: 0.069\n",
      "[1,   200] loss: 0.080\n",
      "[1,   201] loss: 0.113\n",
      "[1,   202] loss: 0.046\n",
      "[1,   203] loss: 0.089\n",
      "[1,   204] loss: 0.083\n",
      "[1,   205] loss: 0.118\n",
      "[1,   206] loss: 0.066\n",
      "[1,   207] loss: 0.041\n",
      "[1,   208] loss: 0.083\n",
      "[1,   209] loss: 0.076\n",
      "[1,   210] loss: 0.074\n",
      "[1,   211] loss: 0.075\n",
      "[1,   212] loss: 0.078\n",
      "[1,   213] loss: 0.081\n",
      "[1,   214] loss: 0.084\n",
      "[1,   215] loss: 0.041\n",
      "[1,   216] loss: 0.055\n",
      "[1,   217] loss: 0.064\n",
      "[1,   218] loss: 0.097\n",
      "[1,   219] loss: 0.065\n",
      "[1,   220] loss: 0.052\n",
      "[1,   221] loss: 0.061\n",
      "[1,   222] loss: 0.072\n",
      "[1,   223] loss: 0.070\n",
      "[1,   224] loss: 0.126\n",
      "[1,   225] loss: 0.142\n",
      "[1,   226] loss: 0.065\n",
      "[1,   227] loss: 0.101\n",
      "[1,   228] loss: 0.084\n",
      "[1,   229] loss: 0.088\n",
      "[1,   230] loss: 0.082\n",
      "[1,   231] loss: 0.091\n",
      "[1,   232] loss: 0.107\n",
      "[1,   233] loss: 0.081\n",
      "[1,   234] loss: 0.080\n",
      "[1,   235] loss: 0.116\n",
      "[1,   236] loss: 0.062\n",
      "[1,   237] loss: 0.168\n",
      "[1,   238] loss: 0.055\n",
      "[1,   239] loss: 0.074\n",
      "[1,   240] loss: 0.066\n",
      "[1,   241] loss: 0.043\n",
      "[1,   242] loss: 0.084\n",
      "[1,   243] loss: 0.040\n",
      "[1,   244] loss: 0.052\n",
      "[1,   245] loss: 0.069\n",
      "[1,   246] loss: 0.075\n",
      "[1,   247] loss: 0.082\n",
      "[1,   248] loss: 0.089\n",
      "[1,   249] loss: 0.093\n",
      "[1,   250] loss: 0.035\n",
      "[1,   251] loss: 0.102\n",
      "[1,   252] loss: 0.036\n",
      "[1,   253] loss: 0.113\n",
      "[1,   254] loss: 0.082\n",
      "[1,   255] loss: 0.074\n",
      "[1,   256] loss: 0.074\n",
      "[1,   257] loss: 0.139\n",
      "[1,   258] loss: 0.065\n",
      "[1,   259] loss: 0.072\n",
      "[1,   260] loss: 0.085\n",
      "[1,   261] loss: 0.066\n",
      "[1,   262] loss: 0.107\n",
      "[1,   263] loss: 0.058\n",
      "[1,   264] loss: 0.067\n",
      "[1,   265] loss: 0.052\n",
      "[1,   266] loss: 0.079\n",
      "[1,   267] loss: 0.096\n",
      "[1,   268] loss: 0.091\n",
      "[1,   269] loss: 0.073\n",
      "[1,   270] loss: 0.092\n",
      "[1,   271] loss: 0.072\n",
      "[1,   272] loss: 0.058\n",
      "[1,   273] loss: 0.042\n",
      "[1,   274] loss: 0.087\n",
      "[1,   275] loss: 0.072\n",
      "[1,   276] loss: 0.075\n",
      "[1,   277] loss: 0.050\n",
      "[1,   278] loss: 0.071\n",
      "[1,   279] loss: 0.071\n",
      "[1,   280] loss: 0.049\n",
      "[1,   281] loss: 0.078\n",
      "[1,   282] loss: 0.056\n",
      "[1,   283] loss: 0.073\n",
      "[1,   284] loss: 0.127\n",
      "[1,   285] loss: 0.066\n",
      "[1,   286] loss: 0.054\n",
      "[1,   287] loss: 0.070\n",
      "[1,   288] loss: 0.047\n",
      "[1,   289] loss: 0.065\n",
      "[1,   290] loss: 0.078\n",
      "[1,   291] loss: 0.068\n",
      "[1,   292] loss: 0.124\n",
      "[1,   293] loss: 0.053\n",
      "[1,   294] loss: 0.110\n",
      "[1,   295] loss: 0.073\n",
      "[1,   296] loss: 0.079\n",
      "[1,   297] loss: 0.077\n",
      "[1,   298] loss: 0.055\n",
      "[1,   299] loss: 0.124\n",
      "[1,   300] loss: 0.088\n",
      "[1,   301] loss: 0.072\n",
      "[1,   302] loss: 0.089\n"
     ]
    }
   ],
   "source": [
    "# Codigo entrenamiento Martin \n",
    "\n",
    "# defino batches\n",
    "batchSize = 4\n",
    "numBatchesTrain = np.round(trainingSet['input'].shape[0]/batchSize).astype(int)\n",
    "numBatchesValid = np.round(validSet['input'].shape[0]/batchSize).astype(int)\n",
    "\n",
    "# Show dev set loss every showDevLossStep batches:\n",
    "showDevLossStep = 4\n",
    "\n",
    "printStep = 1\n",
    "#figImages, axs = plt.subplots(3, 1,figsize=(20,20))\n",
    "#figLoss, axLoss = plt.subplots(1, 1,figsize=(5,5))\n",
    "\n",
    "\n",
    "# Train\n",
    "loss_values = []\n",
    "lossValuesTrainingSet = []\n",
    "iterationNumbers = []\n",
    "lossValuesDevSet = []\n",
    "iterationNumbersForDevSet = []\n",
    "\n",
    "iter = 0\n",
    "\n",
    "EPOCHS = 1\n",
    "\n",
    "for epoch in range(EPOCHS):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    unet.train(True)\n",
    "    for i in range(numBatchesTrain):\n",
    "        # get the inputs\n",
    "        \n",
    "        inputs = torch.from_numpy(trainingSet['input'][i*batchSize:(i+1)*batchSize,:,:,:])\n",
    "        gt = torch.from_numpy(trainingSet['output'][i*batchSize:(i+1)*batchSize,:,:,:])\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = unet(inputs)\n",
    "        loss = criterion(outputs, gt)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        # Save loss values:\n",
    "        lossValuesTrainingSet.append(loss.item())\n",
    "        iterationNumbers.append(iter)\n",
    "     \n",
    "        if i % printStep == (printStep-1):    # print every printStep mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss))\n",
    "            running_loss = 0.0\n",
    "            \n",
    "            # Show input images:\n",
    "            #plt.figure(figImages)\n",
    "            #plt.axes(axs[0])\n",
    "            #imshow(torchvision.utils.make_grid(inputs, normalize=True))\n",
    "            #axs[0].set_title('Input Batch {0}'.format(i))\n",
    "            #plt.axes(axs[1])\n",
    "            #imshow(torchvision.utils.make_grid(outputs, normalize=True))\n",
    "            #axs[1].set_title('Output Epoch {0}'.format(epoch))\n",
    "            #plt.axes(axs[2])\n",
    "            #imshow(torchvision.utils.make_grid(gt, normalize=True))\n",
    "            #axs[2].set_title('Ground Truth')\n",
    "            # Show loss:\n",
    "            #plt.figure(figLoss)\n",
    "            #axLoss.plot(iterationNumbers, lossValuesTrainingSet)\n",
    "            #axLoss.plot(iterationNumbersForDevSet, lossValuesDevSet)\n",
    "            #plt.draw()\n",
    "            #plt.pause(0.0001)\n",
    "            \n",
    "            # Update iteration number:\n",
    "        iter = iter + 1\n",
    "    \n",
    "    unet.train(False)\n",
    "    running_vloss = 0.0\n",
    "    \n",
    "    for i in range(numBatchesValid):\n",
    "        \n",
    "        vinputs = torch.from_numpy(validSet['input'][i*batchSize:(i+1)*batchSize,:,:,:])\n",
    "        vgt = torch.from_numpy(validSet['output'][i*batchSize:(i+1)*batchSize,:,:,:])\n",
    "        \n",
    "        voutputs = unet(vinputs)\n",
    "        vloss =  criterion(voutputs, vgt)\n",
    "        running_vloss += vloss\n",
    "\n",
    "    avg_vloss = running_vloss\n",
    "    print('LOSS train {} valid {}'.format(lossValuesTrainingSet[-1], avg_vloss))\n",
    "        \n",
    "\n",
    "print('Finished Training')\n",
    "\n",
    "plt.pause(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49d9d46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
