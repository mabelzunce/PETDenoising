{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "756ef75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nb\n",
    "import SimpleITK as sitk\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "\n",
    "import torch \n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import datetime\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbdc56a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unet CLASICA (nuevo formato)\n",
    "\n",
    "class DownConv(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels , out_channels):\n",
    "        super(DownConv, self).__init__()\n",
    "        self.DownLayer = nn.Sequential(\n",
    "\n",
    "            torch.nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            torch.nn.BatchNorm2d(out_channels),\n",
    "            torch.nn.ReLU(inplace = True),\n",
    "            torch.nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            torch.nn.BatchNorm2d(out_channels),\n",
    "            torch.nn.ReLU(inplace = True),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x ):\n",
    "        x = self.DownLayer(x)\n",
    "        return x\n",
    "    \n",
    "        \n",
    "class MaxPool(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MaxPool, self).__init__()\n",
    "        self.Pool = torch.nn.MaxPool2d(kernel_size = 2)\n",
    "        \n",
    "    def forward (self,x):\n",
    "        x = self.Pool(x)\n",
    "        return x\n",
    "    \n",
    "        \n",
    "class UpConv(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels , out_channels):\n",
    "        super(UpConv, self).__init__()\n",
    "        \n",
    "        self.ConvTransp = torch.nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        #self.ConvTransp = torch.nn.ConvTranspose2d((in_channels//2), out_channels, kernel_size = 2, stride = 2, padding = 0)\n",
    "        self.UpConv = DownConv(in_channels, out_channels)\n",
    "        \n",
    "    def forward(self, xAnt , xDown):\n",
    "            \n",
    "        layerConvTransposed = self.ConvTransp(xAnt)\n",
    "        concat = torch.cat([layerConvTransposed,xDown], dim=1)\n",
    "        x = self.UpConv(concat)\n",
    "            \n",
    "        return x\n",
    "\n",
    "class OutUnet(nn.Module):\n",
    "    def __init__(self, in_channels , out_channels):\n",
    "        super(OutUnet, self).__init__()\n",
    "        self.OutUnet = torch.nn.Conv2d(in_channels,out_channels, kernel_size = 1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.OutUnet(x)\n",
    "        return x\n",
    "\n",
    "class Unet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Unet,self).__init__()\n",
    "        \n",
    "        # Contract\n",
    "        self.Layer1Down = DownConv(1,32)\n",
    "        self.Layer2Down = DownConv(32,64)\n",
    "        self.Layer3Down = DownConv(64,128)\n",
    "        self.Layer4Down = DownConv(128,256)\n",
    "        self.Layer5Down = DownConv(256,512)\n",
    "        \n",
    "        self.Middle = DownConv(512,512)\n",
    "        \n",
    "        self.Layer1Up = UpConv(1024,256)\n",
    "        self.Layer2Up = UpConv(512,128)\n",
    "        self.Layer3Up = UpConv(256,64)\n",
    "        self.Layer4Up = UpConv(128,64)\n",
    "        self.Layer5Up = UpConv(64+32,32)\n",
    "        \n",
    "        self.MaxPool = MaxPool()\n",
    "        \n",
    "        self.Out = OutUnet(32,1)\n",
    "        \n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        # Down\n",
    "        conv1 = self.Layer1Down(x)\n",
    "        maxPool1 = self.MaxPool(conv1)\n",
    "        \n",
    "        conv2 = self.Layer2Down(maxPool1)\n",
    "        maxPool2 = self.MaxPool(conv2)\n",
    "        \n",
    "        conv3 = self.Layer3Down(maxPool2)\n",
    "        maxPool3 = self.MaxPool(conv3)\n",
    "        \n",
    "        conv4 = self.Layer4Down(maxPool3)\n",
    "        maxPool4 = self.MaxPool(conv4)\n",
    "        \n",
    "        conv5 = self.Layer5Down(maxPool4)\n",
    "        maxPool5 = self.MaxPool(conv5)\n",
    "        \n",
    "        middle = self.Middle(maxPool5)\n",
    "        \n",
    "        # Up\n",
    "        up1= self.Layer1Up(middle,conv5)\n",
    "        up2= self.Layer2Up(up1,conv4)\n",
    "        up3= self.Layer3Up(up2,conv3)\n",
    "        up4= self.Layer4Up(up3,conv2)\n",
    "        up5= self.Layer5Up(up4,conv1)\n",
    "        \n",
    "        outUNet = self.Out(up5)\n",
    "        \n",
    "        return outUNet\n",
    "\n",
    "unet = Unet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0352f71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(img1, img2, cantPix = None):\n",
    "    cuadradoDeDif = ((img1 - img2) ** 2)\n",
    "    suma = np.sum(cuadradoDeDif)\n",
    "    if cantPix == 'None': \n",
    "        cantPix = img1.shape[2] * img1.shape[1]  # img1 and 2 should have same shape\n",
    "    error = suma / cantPix\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ea044b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noisyDataSet1 shape: (1726, 344, 344)\n",
      "noisyDataSet2 shape: (1726, 344, 344)\n",
      "groundTruth shape: (1726, 344, 344)\n"
     ]
    }
   ],
   "source": [
    "# Importo base de datos\n",
    "\n",
    "noisyDataSet1_nii = sitk.ReadImage('./noisyDataSet1.nii')\n",
    "img_noisyDataSet1 = sitk.GetArrayFromImage(noisyDataSet1_nii)\n",
    "\n",
    "noisyDataSet2_nii = sitk.ReadImage('./noisyDataSet2.nii')\n",
    "img_noisyDataSet2 = sitk.GetArrayFromImage(noisyDataSet2_nii)\n",
    "\n",
    "groundTruth_nii = sitk.ReadImage('./groundTruth.nii')\n",
    "img_groundTruth = sitk.GetArrayFromImage(groundTruth_nii)\n",
    "\n",
    "print(\"noisyDataSet1 shape:\",img_noisyDataSet1.shape)\n",
    "print(\"noisyDataSet2 shape:\",img_noisyDataSet2.shape)\n",
    "print(\"groundTruth shape:\",img_groundTruth.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2520a40d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1726, 1, 256, 256)\n",
      "(1726, 1, 256, 256)\n",
      "(1726, 1, 256, 256)\n"
     ]
    }
   ],
   "source": [
    "# Reshape for training\n",
    "\n",
    "img_noisyDataSet1 =img_noisyDataSet1[:,44:300,44:300]\n",
    "img_noisyDataSet2 =img_noisyDataSet2[:,44:300,44:300]\n",
    "img_groundTruth =img_groundTruth[:,44:300,44:300]\n",
    "\n",
    "\n",
    "img_noisyDataSet1 = (np.expand_dims(img_noisyDataSet1, axis=-3)).astype(np.float32)\n",
    "img_noisyDataSet2 = (np.expand_dims(img_noisyDataSet2, axis=-3)).astype(np.float32)\n",
    "img_groundTruth = (np.expand_dims(img_groundTruth, axis=-3)).astype(np.float32)\n",
    "\n",
    "print(img_noisyDataSet1.shape)\n",
    "print(img_noisyDataSet2.shape)\n",
    "print(img_groundTruth.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf57e7d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2011082119708667\n",
      "0.3494163649155729\n"
     ]
    }
   ],
   "source": [
    "# MSE dataset promedio\n",
    "MSEdataSet1 = []\n",
    "MSEdataSet2 = []\n",
    "for i in range(0,img_noisyDataSet1.shape[0]):\n",
    "    img1 = img_groundTruth[i]\n",
    "    img2 = img_noisyDataSet1[i]\n",
    "    img3 = img_noisyDataSet2[i]\n",
    "    MSEdataSet1.append(MSE(img1,img2))\n",
    "    MSEdataSet2.append(MSE(img1,img3))\n",
    "\n",
    "print(np.mean(MSEdataSet1))\n",
    "print(np.mean(MSEdataSet2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6eb18a7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data set size. Training set: 1208. Valid set: 518.\n"
     ]
    }
   ],
   "source": [
    "# Conjunto de entrenamiento, testeo y validacion\n",
    "\n",
    "train_noisyImage,valid_noisyImage,train_groundTruth,valid_groundTruth = train_test_split(img_noisyDataSet2, img_groundTruth, test_size=0.3)\n",
    "\n",
    "# Create dictionaries with training sets:\n",
    "trainingSet = dict([('input',train_noisyImage), ('output', train_groundTruth)])\n",
    "validSet = dict([('input',valid_noisyImage), ('output', valid_groundTruth)])\n",
    "\n",
    "print('Data set size. Training set: {0}. Valid set: {1}.'.format(trainingSet['input'].shape[0], validSet['input'].shape[0]))\n",
    "\n",
    "# Entrenamiento #\n",
    "\n",
    "# Loss and optimizer\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(unet.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab85de4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,     1] loss: 2.679\n",
      "[1,     2] loss: 1.586\n",
      "[1,     3] loss: 0.964\n",
      "[1,     4] loss: 1.253\n",
      "[1,     5] loss: 0.856\n",
      "[1,     6] loss: 0.836\n",
      "[1,     7] loss: 1.176\n",
      "[1,     8] loss: 0.850\n",
      "[1,     9] loss: 0.748\n",
      "[1,    10] loss: 0.526\n",
      "[1,    11] loss: 0.875\n",
      "[1,    12] loss: 0.713\n",
      "[1,    13] loss: 0.556\n",
      "[1,    14] loss: 0.302\n",
      "[1,    15] loss: 0.187\n",
      "[1,    16] loss: 0.364\n",
      "[1,    17] loss: 0.360\n",
      "[1,    18] loss: 0.447\n",
      "[1,    19] loss: 0.274\n",
      "[1,    20] loss: 0.607\n",
      "[1,    21] loss: 0.473\n",
      "[1,    22] loss: 0.199\n",
      "[1,    23] loss: 0.634\n",
      "[1,    24] loss: 0.304\n",
      "[1,    25] loss: 0.303\n",
      "[1,    26] loss: 0.182\n",
      "[1,    27] loss: 0.743\n",
      "[1,    28] loss: 0.639\n",
      "[1,    29] loss: 0.449\n",
      "[1,    30] loss: 0.216\n",
      "[1,    31] loss: 0.317\n",
      "[1,    32] loss: 0.169\n",
      "[1,    33] loss: 0.338\n",
      "[1,    34] loss: 0.265\n",
      "[1,    35] loss: 0.156\n",
      "[1,    36] loss: 0.125\n",
      "[1,    37] loss: 0.525\n",
      "[1,    38] loss: 0.279\n",
      "[1,    39] loss: 0.468\n",
      "[1,    40] loss: 0.420\n",
      "[1,    41] loss: 0.143\n",
      "[1,    42] loss: 0.474\n",
      "[1,    43] loss: 0.199\n",
      "[1,    44] loss: 0.541\n",
      "[1,    45] loss: 0.290\n",
      "[1,    46] loss: 0.380\n",
      "[1,    47] loss: 0.302\n",
      "[1,    48] loss: 0.147\n",
      "[1,    49] loss: 0.207\n",
      "[1,    50] loss: 0.261\n",
      "[1,    51] loss: 0.161\n",
      "[1,    52] loss: 0.169\n",
      "[1,    53] loss: 0.192\n",
      "[1,    54] loss: 0.123\n",
      "[1,    55] loss: 0.128\n",
      "[1,    56] loss: 0.214\n",
      "[1,    57] loss: 0.307\n",
      "[1,    58] loss: 0.203\n",
      "[1,    59] loss: 0.300\n",
      "[1,    60] loss: 0.169\n",
      "[1,    61] loss: 0.497\n",
      "[1,    62] loss: 0.127\n",
      "[1,    63] loss: 0.167\n",
      "[1,    64] loss: 0.305\n",
      "[1,    65] loss: 0.175\n",
      "[1,    66] loss: 0.201\n",
      "[1,    67] loss: 0.264\n",
      "[1,    68] loss: 0.264\n",
      "[1,    69] loss: 0.373\n",
      "[1,    70] loss: 0.291\n",
      "[1,    71] loss: 0.379\n",
      "[1,    72] loss: 0.178\n",
      "[1,    73] loss: 0.372\n",
      "[1,    74] loss: 0.162\n",
      "[1,    75] loss: 0.176\n",
      "[1,    76] loss: 0.274\n",
      "[1,    77] loss: 0.545\n",
      "[1,    78] loss: 0.361\n",
      "[1,    79] loss: 0.405\n",
      "[1,    80] loss: 0.190\n",
      "[1,    81] loss: 0.193\n",
      "[1,    82] loss: 0.206\n",
      "[1,    83] loss: 0.249\n",
      "[1,    84] loss: 0.141\n",
      "[1,    85] loss: 0.197\n",
      "[1,    86] loss: 0.158\n",
      "[1,    87] loss: 0.213\n",
      "[1,    88] loss: 0.140\n",
      "[1,    89] loss: 0.183\n",
      "[1,    90] loss: 0.196\n",
      "[1,    91] loss: 0.178\n",
      "[1,    92] loss: 0.223\n",
      "[1,    93] loss: 0.154\n",
      "[1,    94] loss: 0.161\n",
      "[1,    95] loss: 0.202\n",
      "[1,    96] loss: 0.359\n",
      "[1,    97] loss: 0.175\n",
      "[1,    98] loss: 0.122\n",
      "[1,    99] loss: 0.232\n",
      "[1,   100] loss: 0.106\n",
      "[1,   101] loss: 0.229\n",
      "[1,   102] loss: 0.237\n",
      "[1,   103] loss: 0.378\n",
      "[1,   104] loss: 0.485\n",
      "[1,   105] loss: 0.427\n",
      "[1,   106] loss: 0.194\n",
      "[1,   107] loss: 0.163\n",
      "[1,   108] loss: 0.364\n",
      "[1,   109] loss: 0.135\n",
      "[1,   110] loss: 0.429\n",
      "[1,   111] loss: 0.150\n",
      "[1,   112] loss: 0.255\n",
      "[1,   113] loss: 0.218\n",
      "[1,   114] loss: 0.123\n",
      "[1,   115] loss: 0.230\n",
      "[1,   116] loss: 0.178\n",
      "[1,   117] loss: 0.302\n",
      "[1,   118] loss: 0.175\n",
      "[1,   119] loss: 0.289\n",
      "[1,   120] loss: 0.366\n",
      "[1,   121] loss: 0.205\n",
      "[1,   122] loss: 0.131\n",
      "[1,   123] loss: 0.298\n",
      "[1,   124] loss: 0.155\n",
      "[1,   125] loss: 0.155\n",
      "[1,   126] loss: 0.168\n",
      "[1,   127] loss: 0.150\n",
      "[1,   128] loss: 0.122\n",
      "[1,   129] loss: 0.187\n",
      "[1,   130] loss: 0.163\n",
      "[1,   131] loss: 0.151\n",
      "[1,   132] loss: 0.118\n",
      "[1,   133] loss: 0.569\n",
      "[1,   134] loss: 0.209\n",
      "[1,   135] loss: 0.138\n",
      "[1,   136] loss: 0.196\n",
      "[1,   137] loss: 0.143\n",
      "[1,   138] loss: 0.168\n",
      "[1,   139] loss: 0.256\n",
      "[1,   140] loss: 0.213\n",
      "[1,   141] loss: 0.148\n",
      "[1,   142] loss: 0.145\n",
      "[1,   143] loss: 0.204\n",
      "[1,   144] loss: 0.198\n",
      "[1,   145] loss: 0.355\n",
      "[1,   146] loss: 0.155\n",
      "[1,   147] loss: 0.191\n",
      "[1,   148] loss: 0.262\n",
      "[1,   149] loss: 0.146\n",
      "[1,   150] loss: 0.129\n",
      "[1,   151] loss: 0.122\n",
      "[1,   152] loss: 0.309\n",
      "[1,   153] loss: 0.128\n",
      "[1,   154] loss: 0.142\n",
      "[1,   155] loss: 0.457\n",
      "[1,   156] loss: 0.348\n",
      "[1,   157] loss: 0.158\n",
      "[1,   158] loss: 0.259\n",
      "[1,   159] loss: 0.143\n",
      "[1,   160] loss: 0.255\n",
      "[1,   161] loss: 0.224\n",
      "[1,   162] loss: 0.229\n",
      "[1,   163] loss: 0.172\n",
      "[1,   164] loss: 0.093\n",
      "[1,   165] loss: 0.099\n",
      "[1,   166] loss: 0.113\n",
      "[1,   167] loss: 0.437\n",
      "[1,   168] loss: 0.134\n",
      "[1,   169] loss: 0.104\n",
      "[1,   170] loss: 0.095\n",
      "[1,   171] loss: 0.376\n",
      "[1,   172] loss: 0.139\n",
      "[1,   173] loss: 0.110\n",
      "[1,   174] loss: 0.107\n",
      "[1,   175] loss: 0.376\n",
      "[1,   176] loss: 0.203\n",
      "[1,   177] loss: 0.133\n",
      "[1,   178] loss: 0.246\n",
      "[1,   179] loss: 0.362\n",
      "[1,   180] loss: 0.538\n",
      "[1,   181] loss: 0.164\n",
      "[1,   182] loss: 0.465\n",
      "[1,   183] loss: 0.273\n",
      "[1,   184] loss: 0.197\n",
      "[1,   185] loss: 0.162\n",
      "[1,   186] loss: 0.160\n",
      "[1,   187] loss: 0.281\n",
      "[1,   188] loss: 0.190\n",
      "[1,   189] loss: 0.163\n",
      "[1,   190] loss: 0.177\n",
      "[1,   191] loss: 0.252\n",
      "[1,   192] loss: 0.250\n",
      "[1,   193] loss: 0.156\n",
      "[1,   194] loss: 0.140\n",
      "[1,   195] loss: 0.381\n",
      "[1,   196] loss: 0.137\n",
      "[1,   197] loss: 0.210\n",
      "[1,   198] loss: 0.131\n",
      "[1,   199] loss: 0.190\n",
      "[1,   200] loss: 0.197\n",
      "[1,   201] loss: 0.352\n",
      "[1,   202] loss: 0.192\n",
      "[1,   203] loss: 0.151\n",
      "[1,   204] loss: 0.208\n",
      "[1,   205] loss: 0.218\n",
      "[1,   206] loss: 0.207\n",
      "[1,   207] loss: 0.161\n",
      "[1,   208] loss: 0.404\n",
      "[1,   209] loss: 0.127\n",
      "[1,   210] loss: 0.189\n",
      "[1,   211] loss: 0.197\n",
      "[1,   212] loss: 0.232\n",
      "[1,   213] loss: 0.173\n",
      "[1,   214] loss: 0.221\n",
      "[1,   215] loss: 0.216\n",
      "[1,   216] loss: 0.163\n",
      "[1,   217] loss: 0.128\n",
      "[1,   218] loss: 0.169\n",
      "[1,   219] loss: 0.171\n",
      "[1,   220] loss: 0.230\n",
      "[1,   221] loss: 0.125\n",
      "[1,   222] loss: 0.116\n",
      "[1,   223] loss: 0.264\n",
      "[1,   224] loss: 0.139\n",
      "[1,   225] loss: 0.119\n",
      "[1,   226] loss: 0.313\n",
      "[1,   227] loss: 0.202\n",
      "[1,   228] loss: 0.153\n",
      "[1,   229] loss: 0.318\n",
      "[1,   230] loss: 0.224\n",
      "[1,   231] loss: 0.108\n",
      "[1,   232] loss: 0.222\n",
      "[1,   233] loss: 0.244\n",
      "[1,   234] loss: 0.233\n",
      "[1,   235] loss: 0.258\n",
      "[1,   236] loss: 0.296\n",
      "[1,   237] loss: 0.264\n",
      "[1,   238] loss: 0.127\n",
      "[1,   239] loss: 0.137\n",
      "[1,   240] loss: 0.221\n",
      "[1,   241] loss: 0.279\n",
      "[1,   242] loss: 0.130\n",
      "[1,   243] loss: 0.124\n",
      "[1,   244] loss: 0.139\n",
      "[1,   245] loss: 0.162\n",
      "[1,   246] loss: 0.163\n",
      "[1,   247] loss: 0.185\n",
      "[1,   248] loss: 0.215\n",
      "[1,   249] loss: 0.167\n",
      "[1,   250] loss: 0.154\n",
      "[1,   251] loss: 0.169\n",
      "[1,   252] loss: 0.132\n",
      "[1,   253] loss: 0.152\n",
      "[1,   254] loss: 0.149\n",
      "[1,   255] loss: 0.191\n",
      "[1,   256] loss: 0.119\n",
      "[1,   257] loss: 0.238\n",
      "[1,   258] loss: 0.247\n",
      "[1,   259] loss: 0.126\n",
      "[1,   260] loss: 0.202\n",
      "[1,   261] loss: 0.229\n",
      "[1,   262] loss: 0.285\n",
      "[1,   263] loss: 0.232\n",
      "[1,   264] loss: 0.275\n",
      "[1,   265] loss: 0.166\n",
      "[1,   266] loss: 0.282\n",
      "[1,   267] loss: 0.166\n",
      "[1,   268] loss: 0.347\n",
      "[1,   269] loss: 0.236\n",
      "[1,   270] loss: 0.274\n",
      "[1,   271] loss: 0.201\n",
      "[1,   272] loss: 0.125\n",
      "[1,   273] loss: 0.149\n",
      "[1,   274] loss: 0.255\n",
      "[1,   275] loss: 0.105\n",
      "[1,   276] loss: 0.198\n",
      "[1,   277] loss: 0.111\n",
      "[1,   278] loss: 0.138\n",
      "[1,   279] loss: 0.205\n",
      "[1,   280] loss: 0.124\n",
      "[1,   281] loss: 0.227\n",
      "[1,   282] loss: 0.236\n",
      "[1,   283] loss: 0.265\n",
      "[1,   284] loss: 0.284\n",
      "[1,   285] loss: 0.203\n",
      "[1,   286] loss: 0.138\n",
      "[1,   287] loss: 0.176\n",
      "[1,   288] loss: 0.201\n",
      "[1,   289] loss: 0.204\n",
      "[1,   290] loss: 0.208\n",
      "[1,   291] loss: 0.223\n",
      "[1,   292] loss: 0.146\n",
      "[1,   293] loss: 0.149\n",
      "[1,   294] loss: 0.333\n",
      "[1,   295] loss: 0.299\n",
      "[1,   296] loss: 0.114\n",
      "[1,   297] loss: 0.437\n",
      "[1,   298] loss: 0.105\n",
      "[1,   299] loss: 0.251\n",
      "[1,   300] loss: 0.227\n",
      "[1,   301] loss: 0.227\n",
      "[1,   302] loss: 0.186\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "LOSS train 0.2661759499583813 valid 0.20878402779881772\n",
      "[2,     1] loss: 0.315\n",
      "[2,     2] loss: 0.207\n",
      "[2,     3] loss: 0.136\n",
      "[2,     4] loss: 0.192\n",
      "[2,     5] loss: 0.176\n",
      "[2,     6] loss: 0.171\n",
      "[2,     7] loss: 0.309\n",
      "[2,     8] loss: 0.216\n",
      "[2,     9] loss: 0.196\n",
      "[2,    10] loss: 0.155\n",
      "[2,    11] loss: 0.254\n",
      "[2,    12] loss: 0.228\n",
      "[2,    13] loss: 0.179\n",
      "[2,    14] loss: 0.115\n",
      "[2,    15] loss: 0.185\n",
      "[2,    16] loss: 0.137\n",
      "[2,    17] loss: 0.140\n",
      "[2,    18] loss: 0.189\n",
      "[2,    19] loss: 0.133\n",
      "[2,    20] loss: 0.247\n",
      "[2,    21] loss: 0.190\n",
      "[2,    22] loss: 0.132\n",
      "[2,    23] loss: 0.273\n",
      "[2,    24] loss: 0.143\n",
      "[2,    25] loss: 0.141\n",
      "[2,    26] loss: 0.097\n",
      "[2,    27] loss: 0.352\n",
      "[2,    28] loss: 0.309\n",
      "[2,    29] loss: 0.209\n",
      "[2,    30] loss: 0.121\n",
      "[2,    31] loss: 0.146\n",
      "[2,    32] loss: 0.093\n",
      "[2,    33] loss: 0.177\n",
      "[2,    34] loss: 0.196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2,    35] loss: 0.082\n",
      "[2,    36] loss: 0.070\n",
      "[2,    37] loss: 0.247\n",
      "[2,    38] loss: 0.173\n",
      "[2,    39] loss: 0.237\n",
      "[2,    40] loss: 0.205\n",
      "[2,    41] loss: 0.107\n",
      "[2,    42] loss: 0.230\n",
      "[2,    43] loss: 0.122\n",
      "[2,    44] loss: 0.291\n",
      "[2,    45] loss: 0.148\n",
      "[2,    46] loss: 0.215\n",
      "[2,    47] loss: 0.200\n",
      "[2,    48] loss: 0.089\n",
      "[2,    49] loss: 0.131\n",
      "[2,    50] loss: 0.175\n",
      "[2,    51] loss: 0.116\n",
      "[2,    52] loss: 0.149\n",
      "[2,    53] loss: 0.141\n",
      "[2,    54] loss: 0.102\n",
      "[2,    55] loss: 0.092\n",
      "[2,    56] loss: 0.169\n",
      "[2,    57] loss: 0.215\n",
      "[2,    58] loss: 0.144\n",
      "[2,    59] loss: 0.172\n",
      "[2,    60] loss: 0.136\n",
      "[2,    61] loss: 0.286\n",
      "[2,    62] loss: 0.172\n",
      "[2,    63] loss: 0.156\n",
      "[2,    64] loss: 0.194\n",
      "[2,    65] loss: 0.135\n",
      "[2,    66] loss: 0.159\n",
      "[2,    67] loss: 0.189\n",
      "[2,    68] loss: 0.195\n",
      "[2,    69] loss: 0.256\n",
      "[2,    70] loss: 0.196\n",
      "[2,    71] loss: 0.261\n",
      "[2,    72] loss: 0.156\n",
      "[2,    73] loss: 0.229\n",
      "[2,    74] loss: 0.149\n",
      "[2,    75] loss: 0.135\n",
      "[2,    76] loss: 0.185\n",
      "[2,    77] loss: 0.348\n",
      "[2,    78] loss: 0.248\n",
      "[2,    79] loss: 0.291\n",
      "[2,    80] loss: 0.134\n",
      "[2,    81] loss: 0.146\n",
      "[2,    82] loss: 0.147\n",
      "[2,    83] loss: 0.177\n",
      "[2,    84] loss: 0.119\n",
      "[2,    85] loss: 0.150\n",
      "[2,    86] loss: 0.120\n",
      "[2,    87] loss: 0.147\n",
      "[2,    88] loss: 0.111\n",
      "[2,    89] loss: 0.148\n",
      "[2,    90] loss: 0.164\n",
      "[2,    91] loss: 0.075\n",
      "[2,    92] loss: 0.172\n",
      "[2,    93] loss: 0.129\n",
      "[2,    94] loss: 0.134\n",
      "[2,    95] loss: 0.165\n",
      "[2,    96] loss: 0.239\n",
      "[2,    97] loss: 0.145\n",
      "[2,    98] loss: 0.111\n",
      "[2,    99] loss: 0.169\n",
      "[2,   100] loss: 0.104\n",
      "[2,   101] loss: 0.176\n",
      "[2,   102] loss: 0.209\n",
      "[2,   103] loss: 0.261\n",
      "[2,   104] loss: 0.328\n",
      "[2,   105] loss: 0.296\n",
      "[2,   106] loss: 0.102\n",
      "[2,   107] loss: 0.092\n",
      "[2,   108] loss: 0.272\n",
      "[2,   109] loss: 0.089\n",
      "[2,   110] loss: 0.107\n",
      "[2,   111] loss: 0.097\n",
      "[2,   112] loss: 0.207\n",
      "[2,   113] loss: 0.176\n",
      "[2,   114] loss: 0.109\n",
      "[2,   115] loss: 0.180\n",
      "[2,   116] loss: 0.131\n",
      "[2,   117] loss: 0.209\n",
      "[2,   118] loss: 0.152\n",
      "[2,   119] loss: 0.198\n",
      "[2,   120] loss: 0.258\n",
      "[2,   121] loss: 0.155\n",
      "[2,   122] loss: 0.136\n",
      "[2,   123] loss: 0.219\n",
      "[2,   124] loss: 0.134\n",
      "[2,   125] loss: 0.113\n",
      "[2,   126] loss: 0.144\n",
      "[2,   127] loss: 0.130\n",
      "[2,   128] loss: 0.076\n",
      "[2,   129] loss: 0.048\n",
      "[2,   130] loss: 0.165\n",
      "[2,   131] loss: 0.136\n",
      "[2,   132] loss: 0.070\n",
      "[2,   133] loss: 0.392\n",
      "[2,   134] loss: 0.174\n",
      "[2,   135] loss: 0.115\n",
      "[2,   136] loss: 0.152\n",
      "[2,   137] loss: 0.093\n",
      "[2,   138] loss: 0.146\n",
      "[2,   139] loss: 0.186\n",
      "[2,   140] loss: 0.162\n",
      "[2,   141] loss: 0.148\n",
      "[2,   142] loss: 0.146\n",
      "[2,   143] loss: 0.170\n",
      "[2,   144] loss: 0.166\n",
      "[2,   145] loss: 0.272\n",
      "[2,   146] loss: 0.145\n",
      "[2,   147] loss: 0.159\n",
      "[2,   148] loss: 0.210\n",
      "[2,   149] loss: 0.131\n",
      "[2,   150] loss: 0.112\n",
      "[2,   151] loss: 0.120\n",
      "[2,   152] loss: 0.239\n",
      "[2,   153] loss: 0.108\n",
      "[2,   154] loss: 0.133\n",
      "[2,   155] loss: 0.336\n",
      "[2,   156] loss: 0.266\n",
      "[2,   157] loss: 0.138\n",
      "[2,   158] loss: 0.209\n",
      "[2,   159] loss: 0.111\n",
      "[2,   160] loss: 0.064\n",
      "[2,   161] loss: 0.179\n",
      "[2,   162] loss: 0.064\n",
      "[2,   163] loss: 0.135\n",
      "[2,   164] loss: 0.089\n",
      "[2,   165] loss: 0.066\n",
      "[2,   166] loss: 0.101\n",
      "[2,   167] loss: 0.293\n",
      "[2,   168] loss: 0.122\n",
      "[2,   169] loss: 0.092\n",
      "[2,   170] loss: 0.068\n",
      "[2,   171] loss: 0.259\n",
      "[2,   172] loss: 0.116\n",
      "[2,   173] loss: 0.087\n",
      "[2,   174] loss: 0.084\n",
      "[2,   175] loss: 0.246\n",
      "[2,   176] loss: 0.169\n",
      "[2,   177] loss: 0.113\n",
      "[2,   178] loss: 0.187\n",
      "[2,   179] loss: 0.250\n",
      "[2,   180] loss: 0.383\n",
      "[2,   181] loss: 0.145\n",
      "[2,   182] loss: 0.340\n",
      "[2,   183] loss: 0.202\n",
      "[2,   184] loss: 0.167\n",
      "[2,   185] loss: 0.077\n",
      "[2,   186] loss: 0.134\n",
      "[2,   187] loss: 0.229\n",
      "[2,   188] loss: 0.174\n",
      "[2,   189] loss: 0.118\n",
      "[2,   190] loss: 0.154\n",
      "[2,   191] loss: 0.198\n",
      "[2,   192] loss: 0.204\n",
      "[2,   193] loss: 0.139\n",
      "[2,   194] loss: 0.126\n",
      "[2,   195] loss: 0.282\n",
      "[2,   196] loss: 0.121\n",
      "[2,   197] loss: 0.177\n",
      "[2,   198] loss: 0.117\n",
      "[2,   199] loss: 0.158\n",
      "[2,   200] loss: 0.164\n",
      "[2,   201] loss: 0.260\n",
      "[2,   202] loss: 0.174\n",
      "[2,   203] loss: 0.108\n",
      "[2,   204] loss: 0.174\n",
      "[2,   205] loss: 0.184\n",
      "[2,   206] loss: 0.186\n",
      "[2,   207] loss: 0.155\n",
      "[2,   208] loss: 0.317\n",
      "[2,   209] loss: 0.116\n",
      "[2,   210] loss: 0.163\n",
      "[2,   211] loss: 0.170\n",
      "[2,   212] loss: 0.207\n",
      "[2,   213] loss: 0.168\n",
      "[2,   214] loss: 0.185\n",
      "[2,   215] loss: 0.181\n",
      "[2,   216] loss: 0.152\n",
      "[2,   217] loss: 0.116\n",
      "[2,   218] loss: 0.155\n",
      "[2,   219] loss: 0.153\n",
      "[2,   220] loss: 0.200\n",
      "[2,   221] loss: 0.117\n",
      "[2,   222] loss: 0.078\n",
      "[2,   223] loss: 0.220\n",
      "[2,   224] loss: 0.132\n",
      "[2,   225] loss: 0.108\n",
      "[2,   226] loss: 0.245\n",
      "[2,   227] loss: 0.112\n",
      "[2,   228] loss: 0.132\n",
      "[2,   229] loss: 0.241\n",
      "[2,   230] loss: 0.181\n",
      "[2,   231] loss: 0.076\n",
      "[2,   232] loss: 0.192\n",
      "[2,   233] loss: 0.204\n",
      "[2,   234] loss: 0.209\n",
      "[2,   235] loss: 0.208\n",
      "[2,   236] loss: 0.237\n",
      "[2,   237] loss: 0.208\n",
      "[2,   238] loss: 0.089\n",
      "[2,   239] loss: 0.114\n",
      "[2,   240] loss: 0.193\n",
      "[2,   241] loss: 0.222\n",
      "[2,   242] loss: 0.120\n",
      "[2,   243] loss: 0.114\n",
      "[2,   244] loss: 0.121\n",
      "[2,   245] loss: 0.147\n",
      "[2,   246] loss: 0.150\n",
      "[2,   247] loss: 0.174\n",
      "[2,   248] loss: 0.189\n",
      "[2,   249] loss: 0.157\n",
      "[2,   250] loss: 0.154\n",
      "[2,   251] loss: 0.154\n",
      "[2,   252] loss: 0.079\n",
      "[2,   253] loss: 0.142\n",
      "[2,   254] loss: 0.151\n",
      "[2,   255] loss: 0.171\n",
      "[2,   256] loss: 0.107\n",
      "[2,   257] loss: 0.212\n",
      "[2,   258] loss: 0.212\n",
      "[2,   259] loss: 0.116\n",
      "[2,   260] loss: 0.168\n",
      "[2,   261] loss: 0.197\n",
      "[2,   262] loss: 0.237\n",
      "[2,   263] loss: 0.073\n",
      "[2,   264] loss: 0.228\n",
      "[2,   265] loss: 0.156\n",
      "[2,   266] loss: 0.225\n",
      "[2,   267] loss: 0.143\n",
      "[2,   268] loss: 0.278\n",
      "[2,   269] loss: 0.195\n",
      "[2,   270] loss: 0.231\n",
      "[2,   271] loss: 0.174\n",
      "[2,   272] loss: 0.066\n",
      "[2,   273] loss: 0.079\n",
      "[2,   274] loss: 0.220\n",
      "[2,   275] loss: 0.084\n",
      "[2,   276] loss: 0.190\n",
      "[2,   277] loss: 0.101\n",
      "[2,   278] loss: 0.115\n",
      "[2,   279] loss: 0.171\n",
      "[2,   280] loss: 0.109\n",
      "[2,   281] loss: 0.189\n",
      "[2,   282] loss: 0.196\n",
      "[2,   283] loss: 0.219\n",
      "[2,   284] loss: 0.232\n",
      "[2,   285] loss: 0.178\n",
      "[2,   286] loss: 0.130\n",
      "[2,   287] loss: 0.105\n",
      "[2,   288] loss: 0.181\n",
      "[2,   289] loss: 0.074\n",
      "[2,   290] loss: 0.173\n",
      "[2,   291] loss: 0.193\n",
      "[2,   292] loss: 0.127\n",
      "[2,   293] loss: 0.125\n",
      "[2,   294] loss: 0.248\n",
      "[2,   295] loss: 0.237\n",
      "[2,   296] loss: 0.060\n",
      "[2,   297] loss: 0.341\n",
      "[2,   298] loss: 0.089\n",
      "[2,   299] loss: 0.201\n",
      "[2,   300] loss: 0.092\n",
      "[2,   301] loss: 0.209\n",
      "[2,   302] loss: 0.189\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "LOSS train 0.168891283085212 valid 0.15991988978706873\n",
      "[3,     1] loss: 0.241\n",
      "[3,     2] loss: 0.174\n",
      "[3,     3] loss: 0.126\n",
      "[3,     4] loss: 0.162\n",
      "[3,     5] loss: 0.162\n",
      "[3,     6] loss: 0.159\n",
      "[3,     7] loss: 0.254\n",
      "[3,     8] loss: 0.193\n",
      "[3,     9] loss: 0.175\n",
      "[3,    10] loss: 0.140\n",
      "[3,    11] loss: 0.206\n",
      "[3,    12] loss: 0.203\n",
      "[3,    13] loss: 0.167\n",
      "[3,    14] loss: 0.103\n",
      "[3,    15] loss: 0.085\n",
      "[3,    16] loss: 0.137\n",
      "[3,    17] loss: 0.130\n",
      "[3,    18] loss: 0.160\n",
      "[3,    19] loss: 0.133\n",
      "[3,    20] loss: 0.210\n",
      "[3,    21] loss: 0.166\n",
      "[3,    22] loss: 0.041\n",
      "[3,    23] loss: 0.231\n",
      "[3,    24] loss: 0.136\n",
      "[3,    25] loss: 0.131\n",
      "[3,    26] loss: 0.088\n",
      "[3,    27] loss: 0.281\n",
      "[3,    28] loss: 0.248\n",
      "[3,    29] loss: 0.188\n",
      "[3,    30] loss: 0.115\n",
      "[3,    31] loss: 0.134\n",
      "[3,    32] loss: 0.076\n",
      "[3,    33] loss: 0.160\n",
      "[3,    34] loss: 0.147\n",
      "[3,    35] loss: 0.071\n",
      "[3,    36] loss: 0.076\n",
      "[3,    37] loss: 0.214\n",
      "[3,    38] loss: 0.162\n",
      "[3,    39] loss: 0.206\n",
      "[3,    40] loss: 0.176\n",
      "[3,    41] loss: 0.105\n",
      "[3,    42] loss: 0.187\n",
      "[3,    43] loss: 0.113\n",
      "[3,    44] loss: 0.242\n",
      "[3,    45] loss: 0.090\n",
      "[3,    46] loss: 0.184\n",
      "[3,    47] loss: 0.181\n",
      "[3,    48] loss: 0.082\n",
      "[3,    49] loss: 0.123\n",
      "[3,    50] loss: 0.164\n",
      "[3,    51] loss: 0.109\n",
      "[3,    52] loss: 0.081\n",
      "[3,    53] loss: 0.133\n",
      "[3,    54] loss: 0.083\n",
      "[3,    55] loss: 0.083\n",
      "[3,    56] loss: 0.138\n",
      "[3,    57] loss: 0.158\n",
      "[3,    58] loss: 0.133\n",
      "[3,    59] loss: 0.154\n",
      "[3,    60] loss: 0.118\n",
      "[3,    61] loss: 0.232\n",
      "[3,    62] loss: 0.081\n",
      "[3,    63] loss: 0.127\n",
      "[3,    64] loss: 0.172\n",
      "[3,    65] loss: 0.075\n",
      "[3,    66] loss: 0.155\n",
      "[3,    67] loss: 0.146\n",
      "[3,    68] loss: 0.173\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3,    69] loss: 0.200\n",
      "[3,    70] loss: 0.168\n",
      "[3,    71] loss: 0.211\n",
      "[3,    72] loss: 0.088\n",
      "[3,    73] loss: 0.187\n",
      "[3,    74] loss: 0.132\n",
      "[3,    75] loss: 0.040\n",
      "[3,    76] loss: 0.168\n",
      "[3,    77] loss: 0.280\n",
      "[3,    78] loss: 0.183\n",
      "[3,    79] loss: 0.225\n",
      "[3,    80] loss: 0.123\n",
      "[3,    81] loss: 0.140\n",
      "[3,    82] loss: 0.136\n",
      "[3,    83] loss: 0.166\n",
      "[3,    84] loss: 0.104\n",
      "[3,    85] loss: 0.142\n",
      "[3,    86] loss: 0.109\n",
      "[3,    87] loss: 0.145\n",
      "[3,    88] loss: 0.108\n",
      "[3,    89] loss: 0.136\n",
      "[3,    90] loss: 0.147\n",
      "[3,    91] loss: 0.044\n",
      "[3,    92] loss: 0.154\n",
      "[3,    93] loss: 0.125\n",
      "[3,    94] loss: 0.130\n",
      "[3,    95] loss: 0.154\n",
      "[3,    96] loss: 0.214\n",
      "[3,    97] loss: 0.134\n",
      "[3,    98] loss: 0.091\n",
      "[3,    99] loss: 0.157\n",
      "[3,   100] loss: 0.068\n",
      "[3,   101] loss: 0.166\n",
      "[3,   102] loss: 0.162\n",
      "[3,   103] loss: 0.201\n",
      "[3,   104] loss: 0.267\n",
      "[3,   105] loss: 0.253\n",
      "[3,   106] loss: 0.093\n",
      "[3,   107] loss: 0.085\n",
      "[3,   108] loss: 0.236\n",
      "[3,   109] loss: 0.080\n",
      "[3,   110] loss: 0.066\n",
      "[3,   111] loss: 0.092\n",
      "[3,   112] loss: 0.186\n",
      "[3,   113] loss: 0.155\n",
      "[3,   114] loss: 0.110\n",
      "[3,   115] loss: 0.169\n",
      "[3,   116] loss: 0.126\n",
      "[3,   117] loss: 0.187\n",
      "[3,   118] loss: 0.153\n",
      "[3,   119] loss: 0.176\n",
      "[3,   120] loss: 0.229\n",
      "[3,   121] loss: 0.149\n",
      "[3,   122] loss: 0.105\n",
      "[3,   123] loss: 0.192\n",
      "[3,   124] loss: 0.108\n",
      "[3,   125] loss: 0.101\n",
      "[3,   126] loss: 0.134\n",
      "[3,   127] loss: 0.115\n",
      "[3,   128] loss: 0.075\n",
      "[3,   129] loss: 0.037\n",
      "[3,   130] loss: 0.144\n",
      "[3,   131] loss: 0.134\n",
      "[3,   132] loss: 0.065\n",
      "[3,   133] loss: 0.295\n",
      "[3,   134] loss: 0.143\n",
      "[3,   135] loss: 0.113\n",
      "[3,   136] loss: 0.142\n",
      "[3,   137] loss: 0.079\n",
      "[3,   138] loss: 0.142\n",
      "[3,   139] loss: 0.176\n",
      "[3,   140] loss: 0.157\n",
      "[3,   141] loss: 0.130\n",
      "[3,   142] loss: 0.127\n",
      "[3,   143] loss: 0.165\n",
      "[3,   144] loss: 0.156\n",
      "[3,   145] loss: 0.245\n",
      "[3,   146] loss: 0.140\n",
      "[3,   147] loss: 0.153\n",
      "[3,   148] loss: 0.191\n",
      "[3,   149] loss: 0.128\n",
      "[3,   150] loss: 0.106\n",
      "[3,   151] loss: 0.101\n",
      "[3,   152] loss: 0.215\n",
      "[3,   153] loss: 0.096\n",
      "[3,   154] loss: 0.126\n",
      "[3,   155] loss: 0.287\n",
      "[3,   156] loss: 0.235\n",
      "[3,   157] loss: 0.130\n",
      "[3,   158] loss: 0.194\n",
      "[3,   159] loss: 0.106\n",
      "[3,   160] loss: 0.044\n",
      "[3,   161] loss: 0.167\n",
      "[3,   162] loss: 0.047\n",
      "[3,   163] loss: 0.129\n",
      "[3,   164] loss: 0.080\n",
      "[3,   165] loss: 0.059\n",
      "[3,   166] loss: 0.092\n",
      "[3,   167] loss: 0.261\n",
      "[3,   168] loss: 0.127\n",
      "[3,   169] loss: 0.093\n",
      "[3,   170] loss: 0.064\n",
      "[3,   171] loss: 0.232\n",
      "[3,   172] loss: 0.110\n",
      "[3,   173] loss: 0.085\n",
      "[3,   174] loss: 0.085\n",
      "[3,   175] loss: 0.220\n",
      "[3,   176] loss: 0.166\n",
      "[3,   177] loss: 0.109\n",
      "[3,   178] loss: 0.177\n",
      "[3,   179] loss: 0.219\n",
      "[3,   180] loss: 0.330\n",
      "[3,   181] loss: 0.149\n",
      "[3,   182] loss: 0.294\n",
      "[3,   183] loss: 0.180\n",
      "[3,   184] loss: 0.167\n",
      "[3,   185] loss: 0.086\n",
      "[3,   186] loss: 0.130\n",
      "[3,   187] loss: 0.214\n",
      "[3,   188] loss: 0.163\n",
      "[3,   189] loss: 0.109\n",
      "[3,   190] loss: 0.148\n",
      "[3,   191] loss: 0.184\n",
      "[3,   192] loss: 0.194\n",
      "[3,   193] loss: 0.137\n",
      "[3,   194] loss: 0.128\n",
      "[3,   195] loss: 0.251\n",
      "[3,   196] loss: 0.116\n",
      "[3,   197] loss: 0.170\n",
      "[3,   198] loss: 0.113\n",
      "[3,   199] loss: 0.151\n",
      "[3,   200] loss: 0.159\n",
      "[3,   201] loss: 0.229\n",
      "[3,   202] loss: 0.169\n",
      "[3,   203] loss: 0.099\n",
      "[3,   204] loss: 0.166\n",
      "[3,   205] loss: 0.174\n",
      "[3,   206] loss: 0.180\n",
      "[3,   207] loss: 0.144\n",
      "[3,   208] loss: 0.283\n",
      "[3,   209] loss: 0.118\n",
      "[3,   210] loss: 0.159\n",
      "[3,   211] loss: 0.162\n",
      "[3,   212] loss: 0.197\n",
      "[3,   213] loss: 0.163\n",
      "[3,   214] loss: 0.175\n",
      "[3,   215] loss: 0.173\n",
      "[3,   216] loss: 0.147\n",
      "[3,   217] loss: 0.103\n",
      "[3,   218] loss: 0.149\n",
      "[3,   219] loss: 0.146\n",
      "[3,   220] loss: 0.191\n",
      "[3,   221] loss: 0.111\n",
      "[3,   222] loss: 0.071\n",
      "[3,   223] loss: 0.206\n",
      "[3,   224] loss: 0.126\n",
      "[3,   225] loss: 0.102\n",
      "[3,   226] loss: 0.219\n",
      "[3,   227] loss: 0.108\n",
      "[3,   228] loss: 0.124\n",
      "[3,   229] loss: 0.218\n",
      "[3,   230] loss: 0.171\n",
      "[3,   231] loss: 0.070\n",
      "[3,   232] loss: 0.187\n",
      "[3,   233] loss: 0.191\n",
      "[3,   234] loss: 0.203\n",
      "[3,   235] loss: 0.192\n",
      "[3,   236] loss: 0.214\n",
      "[3,   237] loss: 0.186\n",
      "[3,   238] loss: 0.084\n",
      "[3,   239] loss: 0.109\n",
      "[3,   240] loss: 0.181\n",
      "[3,   241] loss: 0.206\n",
      "[3,   242] loss: 0.113\n",
      "[3,   243] loss: 0.107\n",
      "[3,   244] loss: 0.116\n",
      "[3,   245] loss: 0.142\n",
      "[3,   246] loss: 0.142\n",
      "[3,   247] loss: 0.165\n",
      "[3,   248] loss: 0.181\n",
      "[3,   249] loss: 0.149\n",
      "[3,   250] loss: 0.144\n",
      "[3,   251] loss: 0.139\n",
      "[3,   252] loss: 0.072\n",
      "[3,   253] loss: 0.136\n",
      "[3,   254] loss: 0.138\n",
      "[3,   255] loss: 0.163\n",
      "[3,   256] loss: 0.105\n",
      "[3,   257] loss: 0.204\n",
      "[3,   258] loss: 0.202\n",
      "[3,   259] loss: 0.098\n",
      "[3,   260] loss: 0.158\n",
      "[3,   261] loss: 0.187\n",
      "[3,   262] loss: 0.219\n",
      "[3,   263] loss: 0.058\n",
      "[3,   264] loss: 0.207\n",
      "[3,   265] loss: 0.149\n",
      "[3,   266] loss: 0.206\n",
      "[3,   267] loss: 0.135\n",
      "[3,   268] loss: 0.253\n",
      "[3,   269] loss: 0.183\n",
      "[3,   270] loss: 0.219\n",
      "[3,   271] loss: 0.167\n",
      "[3,   272] loss: 0.066\n",
      "[3,   273] loss: 0.067\n",
      "[3,   274] loss: 0.209\n",
      "[3,   275] loss: 0.080\n",
      "[3,   276] loss: 0.191\n",
      "[3,   277] loss: 0.094\n",
      "[3,   278] loss: 0.117\n",
      "[3,   279] loss: 0.166\n",
      "[3,   280] loss: 0.109\n",
      "[3,   281] loss: 0.179\n",
      "[3,   282] loss: 0.185\n",
      "[3,   283] loss: 0.208\n",
      "[3,   284] loss: 0.216\n",
      "[3,   285] loss: 0.173\n",
      "[3,   286] loss: 0.127\n",
      "[3,   287] loss: 0.103\n",
      "[3,   288] loss: 0.177\n",
      "[3,   289] loss: 0.073\n",
      "[3,   290] loss: 0.166\n",
      "[3,   291] loss: 0.187\n",
      "[3,   292] loss: 0.110\n",
      "[3,   293] loss: 0.120\n",
      "[3,   294] loss: 0.228\n",
      "[3,   295] loss: 0.220\n",
      "[3,   296] loss: 0.050\n",
      "[3,   297] loss: 0.310\n",
      "[3,   298] loss: 0.072\n",
      "[3,   299] loss: 0.187\n",
      "[3,   300] loss: 0.082\n",
      "[3,   301] loss: 0.199\n",
      "[3,   302] loss: 0.180\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "LOSS train 0.15125357425025363 valid 0.17498411135031627\n",
      "[4,     1] loss: 0.228\n",
      "[4,     2] loss: 0.164\n",
      "[4,     3] loss: 0.129\n",
      "[4,     4] loss: 0.155\n",
      "[4,     5] loss: 0.155\n",
      "[4,     6] loss: 0.155\n",
      "[4,     7] loss: 0.237\n",
      "[4,     8] loss: 0.184\n",
      "[4,     9] loss: 0.167\n",
      "[4,    10] loss: 0.136\n",
      "[4,    11] loss: 0.194\n",
      "[4,    12] loss: 0.194\n",
      "[4,    13] loss: 0.159\n",
      "[4,    14] loss: 0.107\n",
      "[4,    15] loss: 0.035\n",
      "[4,    16] loss: 0.124\n",
      "[4,    17] loss: 0.124\n",
      "[4,    18] loss: 0.155\n",
      "[4,    19] loss: 0.122\n",
      "[4,    20] loss: 0.199\n",
      "[4,    21] loss: 0.160\n",
      "[4,    22] loss: 0.028\n",
      "[4,    23] loss: 0.215\n",
      "[4,    24] loss: 0.125\n",
      "[4,    25] loss: 0.125\n",
      "[4,    26] loss: 0.085\n",
      "[4,    27] loss: 0.255\n",
      "[4,    28] loss: 0.229\n",
      "[4,    29] loss: 0.182\n",
      "[4,    30] loss: 0.120\n",
      "[4,    31] loss: 0.133\n",
      "[4,    32] loss: 0.071\n",
      "[4,    33] loss: 0.154\n",
      "[4,    34] loss: 0.139\n",
      "[4,    35] loss: 0.074\n",
      "[4,    36] loss: 0.069\n",
      "[4,    37] loss: 0.208\n",
      "[4,    38] loss: 0.151\n",
      "[4,    39] loss: 0.199\n",
      "[4,    40] loss: 0.168\n",
      "[4,    41] loss: 0.101\n",
      "[4,    42] loss: 0.174\n",
      "[4,    43] loss: 0.115\n",
      "[4,    44] loss: 0.227\n",
      "[4,    45] loss: 0.098\n",
      "[4,    46] loss: 0.172\n",
      "[4,    47] loss: 0.152\n",
      "[4,    48] loss: 0.082\n",
      "[4,    49] loss: 0.122\n",
      "[4,    50] loss: 0.164\n",
      "[4,    51] loss: 0.113\n",
      "[4,    52] loss: 0.077\n",
      "[4,    53] loss: 0.126\n",
      "[4,    54] loss: 0.082\n",
      "[4,    55] loss: 0.086\n",
      "[4,    56] loss: 0.141\n",
      "[4,    57] loss: 0.153\n",
      "[4,    58] loss: 0.129\n",
      "[4,    59] loss: 0.150\n",
      "[4,    60] loss: 0.123\n",
      "[4,    61] loss: 0.217\n",
      "[4,    62] loss: 0.072\n",
      "[4,    63] loss: 0.115\n",
      "[4,    64] loss: 0.167\n",
      "[4,    65] loss: 0.074\n",
      "[4,    66] loss: 0.137\n",
      "[4,    67] loss: 0.138\n",
      "[4,    68] loss: 0.173\n",
      "[4,    69] loss: 0.192\n",
      "[4,    70] loss: 0.162\n",
      "[4,    71] loss: 0.208\n",
      "[4,    72] loss: 0.084\n",
      "[4,    73] loss: 0.177\n",
      "[4,    74] loss: 0.120\n",
      "[4,    75] loss: 0.037\n",
      "[4,    76] loss: 0.163\n",
      "[4,    77] loss: 0.262\n",
      "[4,    78] loss: 0.173\n",
      "[4,    79] loss: 0.206\n",
      "[4,    80] loss: 0.120\n",
      "[4,    81] loss: 0.139\n",
      "[4,    82] loss: 0.131\n",
      "[4,    83] loss: 0.162\n",
      "[4,    84] loss: 0.082\n",
      "[4,    85] loss: 0.139\n",
      "[4,    86] loss: 0.105\n",
      "[4,    87] loss: 0.133\n",
      "[4,    88] loss: 0.099\n",
      "[4,    89] loss: 0.125\n",
      "[4,    90] loss: 0.141\n",
      "[4,    91] loss: 0.039\n",
      "[4,    92] loss: 0.145\n",
      "[4,    93] loss: 0.121\n",
      "[4,    94] loss: 0.122\n",
      "[4,    95] loss: 0.149\n",
      "[4,    96] loss: 0.202\n",
      "[4,    97] loss: 0.130\n",
      "[4,    98] loss: 0.083\n",
      "[4,    99] loss: 0.151\n",
      "[4,   100] loss: 0.066\n",
      "[4,   101] loss: 0.162\n",
      "[4,   102] loss: 0.160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4,   103] loss: 0.207\n",
      "[4,   104] loss: 0.254\n",
      "[4,   105] loss: 0.239\n",
      "[4,   106] loss: 0.082\n",
      "[4,   107] loss: 0.085\n",
      "[4,   108] loss: 0.229\n",
      "[4,   109] loss: 0.081\n",
      "[4,   110] loss: 0.051\n",
      "[4,   111] loss: 0.081\n",
      "[4,   112] loss: 0.183\n",
      "[4,   113] loss: 0.149\n",
      "[4,   114] loss: 0.104\n",
      "[4,   115] loss: 0.171\n",
      "[4,   116] loss: 0.124\n",
      "[4,   117] loss: 0.181\n",
      "[4,   118] loss: 0.141\n",
      "[4,   119] loss: 0.169\n",
      "[4,   120] loss: 0.220\n",
      "[4,   121] loss: 0.146\n",
      "[4,   122] loss: 0.102\n",
      "[4,   123] loss: 0.187\n",
      "[4,   124] loss: 0.111\n",
      "[4,   125] loss: 0.102\n",
      "[4,   126] loss: 0.130\n",
      "[4,   127] loss: 0.118\n",
      "[4,   128] loss: 0.076\n",
      "[4,   129] loss: 0.038\n",
      "[4,   130] loss: 0.140\n",
      "[4,   131] loss: 0.116\n",
      "[4,   132] loss: 0.064\n",
      "[4,   133] loss: 0.279\n",
      "[4,   134] loss: 0.140\n",
      "[4,   135] loss: 0.106\n",
      "[4,   136] loss: 0.137\n",
      "[4,   137] loss: 0.076\n",
      "[4,   138] loss: 0.141\n",
      "[4,   139] loss: 0.171\n",
      "[4,   140] loss: 0.154\n",
      "[4,   141] loss: 0.125\n",
      "[4,   142] loss: 0.122\n",
      "[4,   143] loss: 0.161\n",
      "[4,   144] loss: 0.156\n",
      "[4,   145] loss: 0.246\n",
      "[4,   146] loss: 0.133\n",
      "[4,   147] loss: 0.147\n",
      "[4,   148] loss: 0.183\n",
      "[4,   149] loss: 0.123\n",
      "[4,   150] loss: 0.103\n",
      "[4,   151] loss: 0.104\n",
      "[4,   152] loss: 0.206\n",
      "[4,   153] loss: 0.094\n",
      "[4,   154] loss: 0.119\n",
      "[4,   155] loss: 0.272\n",
      "[4,   156] loss: 0.226\n",
      "[4,   157] loss: 0.127\n",
      "[4,   158] loss: 0.189\n",
      "[4,   159] loss: 0.103\n",
      "[4,   160] loss: 0.038\n",
      "[4,   161] loss: 0.163\n",
      "[4,   162] loss: 0.042\n",
      "[4,   163] loss: 0.131\n",
      "[4,   164] loss: 0.075\n",
      "[4,   165] loss: 0.056\n",
      "[4,   166] loss: 0.094\n",
      "[4,   167] loss: 0.248\n",
      "[4,   168] loss: 0.126\n",
      "[4,   169] loss: 0.095\n",
      "[4,   170] loss: 0.063\n",
      "[4,   171] loss: 0.224\n",
      "[4,   172] loss: 0.108\n",
      "[4,   173] loss: 0.088\n",
      "[4,   174] loss: 0.082\n",
      "[4,   175] loss: 0.212\n",
      "[4,   176] loss: 0.161\n",
      "[4,   177] loss: 0.108\n",
      "[4,   178] loss: 0.174\n",
      "[4,   179] loss: 0.207\n",
      "[4,   180] loss: 0.305\n",
      "[4,   181] loss: 0.152\n",
      "[4,   182] loss: 0.273\n",
      "[4,   183] loss: 0.173\n",
      "[4,   184] loss: 0.171\n",
      "[4,   185] loss: 0.080\n",
      "[4,   186] loss: 0.130\n",
      "[4,   187] loss: 0.207\n",
      "[4,   188] loss: 0.157\n",
      "[4,   189] loss: 0.106\n",
      "[4,   190] loss: 0.146\n",
      "[4,   191] loss: 0.179\n",
      "[4,   192] loss: 0.191\n",
      "[4,   193] loss: 0.136\n",
      "[4,   194] loss: 0.128\n",
      "[4,   195] loss: 0.237\n",
      "[4,   196] loss: 0.112\n",
      "[4,   197] loss: 0.168\n",
      "[4,   198] loss: 0.113\n",
      "[4,   199] loss: 0.148\n",
      "[4,   200] loss: 0.158\n",
      "[4,   201] loss: 0.217\n",
      "[4,   202] loss: 0.166\n",
      "[4,   203] loss: 0.094\n",
      "[4,   204] loss: 0.162\n",
      "[4,   205] loss: 0.167\n",
      "[4,   206] loss: 0.177\n",
      "[4,   207] loss: 0.143\n",
      "[4,   208] loss: 0.269\n",
      "[4,   209] loss: 0.112\n",
      "[4,   210] loss: 0.156\n",
      "[4,   211] loss: 0.158\n",
      "[4,   212] loss: 0.192\n",
      "[4,   213] loss: 0.156\n",
      "[4,   214] loss: 0.171\n",
      "[4,   215] loss: 0.169\n",
      "[4,   216] loss: 0.142\n",
      "[4,   217] loss: 0.095\n",
      "[4,   218] loss: 0.145\n",
      "[4,   219] loss: 0.142\n",
      "[4,   220] loss: 0.186\n",
      "[4,   221] loss: 0.106\n",
      "[4,   222] loss: 0.069\n",
      "[4,   223] loss: 0.195\n",
      "[4,   224] loss: 0.123\n",
      "[4,   225] loss: 0.100\n",
      "[4,   226] loss: 0.208\n",
      "[4,   227] loss: 0.097\n",
      "[4,   228] loss: 0.121\n",
      "[4,   229] loss: 0.210\n",
      "[4,   230] loss: 0.168\n",
      "[4,   231] loss: 0.067\n",
      "[4,   232] loss: 0.185\n",
      "[4,   233] loss: 0.186\n",
      "[4,   234] loss: 0.199\n",
      "[4,   235] loss: 0.185\n",
      "[4,   236] loss: 0.204\n",
      "[4,   237] loss: 0.178\n",
      "[4,   238] loss: 0.082\n",
      "[4,   239] loss: 0.107\n",
      "[4,   240] loss: 0.176\n",
      "[4,   241] loss: 0.200\n",
      "[4,   242] loss: 0.111\n",
      "[4,   243] loss: 0.104\n",
      "[4,   244] loss: 0.114\n",
      "[4,   245] loss: 0.138\n",
      "[4,   246] loss: 0.139\n",
      "[4,   247] loss: 0.162\n",
      "[4,   248] loss: 0.178\n",
      "[4,   249] loss: 0.146\n",
      "[4,   250] loss: 0.141\n",
      "[4,   251] loss: 0.135\n",
      "[4,   252] loss: 0.070\n",
      "[4,   253] loss: 0.134\n",
      "[4,   254] loss: 0.134\n",
      "[4,   255] loss: 0.159\n",
      "[4,   256] loss: 0.103\n",
      "[4,   257] loss: 0.199\n",
      "[4,   258] loss: 0.197\n",
      "[4,   259] loss: 0.095\n",
      "[4,   260] loss: 0.154\n",
      "[4,   261] loss: 0.184\n",
      "[4,   262] loss: 0.211\n",
      "[4,   263] loss: 0.054\n",
      "[4,   264] loss: 0.199\n",
      "[4,   265] loss: 0.146\n",
      "[4,   266] loss: 0.200\n",
      "[4,   267] loss: 0.132\n",
      "[4,   268] loss: 0.242\n",
      "[4,   269] loss: 0.175\n",
      "[4,   270] loss: 0.213\n",
      "[4,   271] loss: 0.164\n",
      "[4,   272] loss: 0.065\n",
      "[4,   273] loss: 0.064\n",
      "[4,   274] loss: 0.206\n",
      "[4,   275] loss: 0.078\n",
      "[4,   276] loss: 0.190\n",
      "[4,   277] loss: 0.091\n",
      "[4,   278] loss: 0.114\n",
      "[4,   279] loss: 0.163\n",
      "[4,   280] loss: 0.106\n",
      "[4,   281] loss: 0.174\n",
      "[4,   282] loss: 0.181\n",
      "[4,   283] loss: 0.199\n",
      "[4,   284] loss: 0.207\n",
      "[4,   285] loss: 0.167\n",
      "[4,   286] loss: 0.123\n",
      "[4,   287] loss: 0.101\n",
      "[4,   288] loss: 0.177\n",
      "[4,   289] loss: 0.069\n",
      "[4,   290] loss: 0.162\n",
      "[4,   291] loss: 0.182\n",
      "[4,   292] loss: 0.106\n",
      "[4,   293] loss: 0.115\n",
      "[4,   294] loss: 0.218\n",
      "[4,   295] loss: 0.211\n",
      "[4,   296] loss: 0.052\n",
      "[4,   297] loss: 0.292\n",
      "[4,   298] loss: 0.063\n",
      "[4,   299] loss: 0.182\n",
      "[4,   300] loss: 0.075\n",
      "[4,   301] loss: 0.196\n",
      "[4,   302] loss: 0.175\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "LOSS train 0.14570807921545986 valid 0.18289217261167673\n",
      "[5,     1] loss: 0.219\n",
      "[5,     2] loss: 0.164\n",
      "[5,     3] loss: 0.123\n",
      "[5,     4] loss: 0.153\n",
      "[5,     5] loss: 0.151\n",
      "[5,     6] loss: 0.151\n",
      "[5,     7] loss: 0.229\n",
      "[5,     8] loss: 0.181\n",
      "[5,     9] loss: 0.166\n",
      "[5,    10] loss: 0.136\n",
      "[5,    11] loss: 0.188\n",
      "[5,    12] loss: 0.192\n",
      "[5,    13] loss: 0.159\n",
      "[5,    14] loss: 0.107\n",
      "[5,    15] loss: 0.026\n",
      "[5,    16] loss: 0.120\n",
      "[5,    17] loss: 0.122\n",
      "[5,    18] loss: 0.153\n",
      "[5,    19] loss: 0.120\n",
      "[5,    20] loss: 0.194\n",
      "[5,    21] loss: 0.158\n",
      "[5,    22] loss: 0.022\n",
      "[5,    23] loss: 0.209\n",
      "[5,    24] loss: 0.123\n",
      "[5,    25] loss: 0.124\n",
      "[5,    26] loss: 0.084\n",
      "[5,    27] loss: 0.246\n",
      "[5,    28] loss: 0.222\n",
      "[5,    29] loss: 0.179\n",
      "[5,    30] loss: 0.114\n",
      "[5,    31] loss: 0.130\n",
      "[5,    32] loss: 0.069\n",
      "[5,    33] loss: 0.151\n",
      "[5,    34] loss: 0.134\n",
      "[5,    35] loss: 0.067\n",
      "[5,    36] loss: 0.068\n",
      "[5,    37] loss: 0.202\n",
      "[5,    38] loss: 0.146\n",
      "[5,    39] loss: 0.196\n",
      "[5,    40] loss: 0.164\n",
      "[5,    41] loss: 0.089\n",
      "[5,    42] loss: 0.166\n",
      "[5,    43] loss: 0.108\n",
      "[5,    44] loss: 0.219\n",
      "[5,    45] loss: 0.070\n",
      "[5,    46] loss: 0.169\n",
      "[5,    47] loss: 0.142\n",
      "[5,    48] loss: 0.080\n",
      "[5,    49] loss: 0.116\n",
      "[5,    50] loss: 0.156\n",
      "[5,    51] loss: 0.113\n",
      "[5,    52] loss: 0.078\n",
      "[5,    53] loss: 0.122\n",
      "[5,    54] loss: 0.081\n",
      "[5,    55] loss: 0.081\n",
      "[5,    56] loss: 0.136\n",
      "[5,    57] loss: 0.150\n",
      "[5,    58] loss: 0.131\n",
      "[5,    59] loss: 0.148\n",
      "[5,    60] loss: 0.111\n",
      "[5,    61] loss: 0.206\n",
      "[5,    62] loss: 0.072\n",
      "[5,    63] loss: 0.112\n",
      "[5,    64] loss: 0.164\n",
      "[5,    65] loss: 0.073\n",
      "[5,    66] loss: 0.138\n",
      "[5,    67] loss: 0.139\n",
      "[5,    68] loss: 0.166\n",
      "[5,    69] loss: 0.188\n",
      "[5,    70] loss: 0.159\n",
      "[5,    71] loss: 0.202\n",
      "[5,    72] loss: 0.085\n",
      "[5,    73] loss: 0.172\n",
      "[5,    74] loss: 0.118\n",
      "[5,    75] loss: 0.035\n",
      "[5,    76] loss: 0.162\n",
      "[5,    77] loss: 0.251\n",
      "[5,    78] loss: 0.170\n",
      "[5,    79] loss: 0.199\n",
      "[5,    80] loss: 0.118\n",
      "[5,    81] loss: 0.132\n",
      "[5,    82] loss: 0.129\n",
      "[5,    83] loss: 0.161\n",
      "[5,    84] loss: 0.082\n",
      "[5,    85] loss: 0.135\n",
      "[5,    86] loss: 0.104\n",
      "[5,    87] loss: 0.136\n",
      "[5,    88] loss: 0.096\n",
      "[5,    89] loss: 0.123\n",
      "[5,    90] loss: 0.139\n",
      "[5,    91] loss: 0.036\n",
      "[5,    92] loss: 0.141\n",
      "[5,    93] loss: 0.120\n",
      "[5,    94] loss: 0.122\n",
      "[5,    95] loss: 0.145\n",
      "[5,    96] loss: 0.198\n",
      "[5,    97] loss: 0.127\n",
      "[5,    98] loss: 0.082\n",
      "[5,    99] loss: 0.148\n",
      "[5,   100] loss: 0.065\n",
      "[5,   101] loss: 0.159\n",
      "[5,   102] loss: 0.151\n",
      "[5,   103] loss: 0.193\n",
      "[5,   104] loss: 0.242\n",
      "[5,   105] loss: 0.231\n",
      "[5,   106] loss: 0.074\n",
      "[5,   107] loss: 0.081\n",
      "[5,   108] loss: 0.222\n",
      "[5,   109] loss: 0.077\n",
      "[5,   110] loss: 0.046\n",
      "[5,   111] loss: 0.078\n",
      "[5,   112] loss: 0.178\n",
      "[5,   113] loss: 0.145\n",
      "[5,   114] loss: 0.089\n",
      "[5,   115] loss: 0.162\n",
      "[5,   116] loss: 0.125\n",
      "[5,   117] loss: 0.177\n",
      "[5,   118] loss: 0.132\n",
      "[5,   119] loss: 0.164\n",
      "[5,   120] loss: 0.215\n",
      "[5,   121] loss: 0.143\n",
      "[5,   122] loss: 0.075\n",
      "[5,   123] loss: 0.180\n",
      "[5,   124] loss: 0.102\n",
      "[5,   125] loss: 0.098\n",
      "[5,   126] loss: 0.126\n",
      "[5,   127] loss: 0.108\n",
      "[5,   128] loss: 0.078\n",
      "[5,   129] loss: 0.039\n",
      "[5,   130] loss: 0.130\n",
      "[5,   131] loss: 0.108\n",
      "[5,   132] loss: 0.061\n",
      "[5,   133] loss: 0.255\n",
      "[5,   134] loss: 0.134\n",
      "[5,   135] loss: 0.106\n",
      "[5,   136] loss: 0.135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5,   137] loss: 0.056\n",
      "[5,   138] loss: 0.128\n",
      "[5,   139] loss: 0.166\n",
      "[5,   140] loss: 0.148\n",
      "[5,   141] loss: 0.109\n",
      "[5,   142] loss: 0.115\n",
      "[5,   143] loss: 0.158\n",
      "[5,   144] loss: 0.152\n",
      "[5,   145] loss: 0.223\n",
      "[5,   146] loss: 0.126\n",
      "[5,   147] loss: 0.143\n",
      "[5,   148] loss: 0.173\n",
      "[5,   149] loss: 0.123\n",
      "[5,   150] loss: 0.104\n",
      "[5,   151] loss: 0.100\n",
      "[5,   152] loss: 0.202\n",
      "[5,   153] loss: 0.091\n",
      "[5,   154] loss: 0.118\n",
      "[5,   155] loss: 0.254\n",
      "[5,   156] loss: 0.223\n",
      "[5,   157] loss: 0.126\n",
      "[5,   158] loss: 0.185\n",
      "[5,   159] loss: 0.100\n",
      "[5,   160] loss: 0.035\n",
      "[5,   161] loss: 0.160\n",
      "[5,   162] loss: 0.040\n",
      "[5,   163] loss: 0.121\n",
      "[5,   164] loss: 0.073\n",
      "[5,   165] loss: 0.056\n",
      "[5,   166] loss: 0.088\n",
      "[5,   167] loss: 0.243\n",
      "[5,   168] loss: 0.116\n",
      "[5,   169] loss: 0.088\n",
      "[5,   170] loss: 0.062\n",
      "[5,   171] loss: 0.218\n",
      "[5,   172] loss: 0.108\n",
      "[5,   173] loss: 0.083\n",
      "[5,   174] loss: 0.076\n",
      "[5,   175] loss: 0.202\n",
      "[5,   176] loss: 0.157\n",
      "[5,   177] loss: 0.109\n",
      "[5,   178] loss: 0.171\n",
      "[5,   179] loss: 0.202\n",
      "[5,   180] loss: 0.293\n",
      "[5,   181] loss: 0.137\n",
      "[5,   182] loss: 0.260\n",
      "[5,   183] loss: 0.169\n",
      "[5,   184] loss: 0.165\n",
      "[5,   185] loss: 0.072\n",
      "[5,   186] loss: 0.128\n",
      "[5,   187] loss: 0.203\n",
      "[5,   188] loss: 0.153\n",
      "[5,   189] loss: 0.105\n",
      "[5,   190] loss: 0.143\n",
      "[5,   191] loss: 0.174\n",
      "[5,   192] loss: 0.186\n",
      "[5,   193] loss: 0.134\n",
      "[5,   194] loss: 0.124\n",
      "[5,   195] loss: 0.230\n",
      "[5,   196] loss: 0.110\n",
      "[5,   197] loss: 0.165\n",
      "[5,   198] loss: 0.109\n",
      "[5,   199] loss: 0.145\n",
      "[5,   200] loss: 0.154\n",
      "[5,   201] loss: 0.210\n",
      "[5,   202] loss: 0.162\n",
      "[5,   203] loss: 0.089\n",
      "[5,   204] loss: 0.159\n",
      "[5,   205] loss: 0.165\n",
      "[5,   206] loss: 0.175\n",
      "[5,   207] loss: 0.137\n",
      "[5,   208] loss: 0.258\n",
      "[5,   209] loss: 0.107\n",
      "[5,   210] loss: 0.152\n",
      "[5,   211] loss: 0.156\n",
      "[5,   212] loss: 0.190\n",
      "[5,   213] loss: 0.153\n",
      "[5,   214] loss: 0.168\n",
      "[5,   215] loss: 0.166\n",
      "[5,   216] loss: 0.136\n",
      "[5,   217] loss: 0.087\n",
      "[5,   218] loss: 0.140\n",
      "[5,   219] loss: 0.139\n",
      "[5,   220] loss: 0.183\n",
      "[5,   221] loss: 0.104\n",
      "[5,   222] loss: 0.067\n",
      "[5,   223] loss: 0.189\n",
      "[5,   224] loss: 0.117\n",
      "[5,   225] loss: 0.098\n",
      "[5,   226] loss: 0.198\n",
      "[5,   227] loss: 0.097\n",
      "[5,   228] loss: 0.118\n",
      "[5,   229] loss: 0.202\n",
      "[5,   230] loss: 0.165\n",
      "[5,   231] loss: 0.065\n",
      "[5,   232] loss: 0.183\n",
      "[5,   233] loss: 0.182\n",
      "[5,   234] loss: 0.192\n",
      "[5,   235] loss: 0.182\n",
      "[5,   236] loss: 0.200\n",
      "[5,   237] loss: 0.174\n",
      "[5,   238] loss: 0.080\n",
      "[5,   239] loss: 0.105\n",
      "[5,   240] loss: 0.176\n",
      "[5,   241] loss: 0.194\n",
      "[5,   242] loss: 0.108\n",
      "[5,   243] loss: 0.105\n",
      "[5,   244] loss: 0.113\n",
      "[5,   245] loss: 0.135\n",
      "[5,   246] loss: 0.137\n",
      "[5,   247] loss: 0.159\n",
      "[5,   248] loss: 0.174\n",
      "[5,   249] loss: 0.144\n",
      "[5,   250] loss: 0.146\n",
      "[5,   251] loss: 0.134\n",
      "[5,   252] loss: 0.068\n",
      "[5,   253] loss: 0.129\n",
      "[5,   254] loss: 0.136\n",
      "[5,   255] loss: 0.158\n",
      "[5,   256] loss: 0.099\n",
      "[5,   257] loss: 0.200\n",
      "[5,   258] loss: 0.194\n",
      "[5,   259] loss: 0.092\n",
      "[5,   260] loss: 0.152\n",
      "[5,   261] loss: 0.181\n",
      "[5,   262] loss: 0.206\n",
      "[5,   263] loss: 0.047\n",
      "[5,   264] loss: 0.194\n",
      "[5,   265] loss: 0.144\n",
      "[5,   266] loss: 0.199\n",
      "[5,   267] loss: 0.130\n",
      "[5,   268] loss: 0.233\n",
      "[5,   269] loss: 0.170\n",
      "[5,   270] loss: 0.207\n",
      "[5,   271] loss: 0.161\n",
      "[5,   272] loss: 0.058\n",
      "[5,   273] loss: 0.063\n",
      "[5,   274] loss: 0.203\n",
      "[5,   275] loss: 0.079\n",
      "[5,   276] loss: 0.187\n",
      "[5,   277] loss: 0.091\n",
      "[5,   278] loss: 0.107\n",
      "[5,   279] loss: 0.157\n",
      "[5,   280] loss: 0.101\n",
      "[5,   281] loss: 0.170\n",
      "[5,   282] loss: 0.178\n",
      "[5,   283] loss: 0.192\n",
      "[5,   284] loss: 0.202\n",
      "[5,   285] loss: 0.160\n",
      "[5,   286] loss: 0.119\n",
      "[5,   287] loss: 0.098\n",
      "[5,   288] loss: 0.172\n",
      "[5,   289] loss: 0.065\n",
      "[5,   290] loss: 0.158\n",
      "[5,   291] loss: 0.175\n",
      "[5,   292] loss: 0.105\n",
      "[5,   293] loss: 0.113\n",
      "[5,   294] loss: 0.212\n",
      "[5,   295] loss: 0.206\n",
      "[5,   296] loss: 0.045\n",
      "[5,   297] loss: 0.279\n",
      "[5,   298] loss: 0.062\n",
      "[5,   299] loss: 0.178\n",
      "[5,   300] loss: 0.074\n",
      "[5,   301] loss: 0.195\n",
      "[5,   302] loss: 0.177\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "LOSS train 0.14121830010083536 valid 0.17095285831735685\n",
      "[6,     1] loss: 0.211\n",
      "[6,     2] loss: 0.160\n",
      "[6,     3] loss: 0.119\n",
      "[6,     4] loss: 0.152\n",
      "[6,     5] loss: 0.152\n",
      "[6,     6] loss: 0.149\n",
      "[6,     7] loss: 0.223\n",
      "[6,     8] loss: 0.178\n",
      "[6,     9] loss: 0.164\n",
      "[6,    10] loss: 0.136\n",
      "[6,    11] loss: 0.183\n",
      "[6,    12] loss: 0.190\n",
      "[6,    13] loss: 0.159\n",
      "[6,    14] loss: 0.096\n",
      "[6,    15] loss: 0.025\n",
      "[6,    16] loss: 0.118\n",
      "[6,    17] loss: 0.121\n",
      "[6,    18] loss: 0.152\n",
      "[6,    19] loss: 0.119\n",
      "[6,    20] loss: 0.192\n",
      "[6,    21] loss: 0.156\n",
      "[6,    22] loss: 0.018\n",
      "[6,    23] loss: 0.205\n",
      "[6,    24] loss: 0.123\n",
      "[6,    25] loss: 0.123\n",
      "[6,    26] loss: 0.081\n",
      "[6,    27] loss: 0.238\n",
      "[6,    28] loss: 0.217\n",
      "[6,    29] loss: 0.177\n",
      "[6,    30] loss: 0.107\n",
      "[6,    31] loss: 0.124\n",
      "[6,    32] loss: 0.069\n",
      "[6,    33] loss: 0.148\n",
      "[6,    34] loss: 0.130\n",
      "[6,    35] loss: 0.067\n",
      "[6,    36] loss: 0.065\n",
      "[6,    37] loss: 0.189\n",
      "[6,    38] loss: 0.146\n",
      "[6,    39] loss: 0.190\n",
      "[6,    40] loss: 0.162\n",
      "[6,    41] loss: 0.084\n",
      "[6,    42] loss: 0.162\n",
      "[6,    43] loss: 0.099\n",
      "[6,    44] loss: 0.213\n",
      "[6,    45] loss: 0.059\n",
      "[6,    46] loss: 0.167\n",
      "[6,    47] loss: 0.140\n",
      "[6,    48] loss: 0.077\n",
      "[6,    49] loss: 0.113\n",
      "[6,    50] loss: 0.151\n",
      "[6,    51] loss: 0.108\n",
      "[6,    52] loss: 0.073\n",
      "[6,    53] loss: 0.119\n",
      "[6,    54] loss: 0.079\n",
      "[6,    55] loss: 0.076\n",
      "[6,    56] loss: 0.127\n",
      "[6,    57] loss: 0.145\n",
      "[6,    58] loss: 0.125\n",
      "[6,    59] loss: 0.145\n",
      "[6,    60] loss: 0.108\n",
      "[6,    61] loss: 0.198\n",
      "[6,    62] loss: 0.069\n",
      "[6,    63] loss: 0.109\n",
      "[6,    64] loss: 0.159\n",
      "[6,    65] loss: 0.069\n",
      "[6,    66] loss: 0.133\n",
      "[6,    67] loss: 0.135\n",
      "[6,    68] loss: 0.162\n",
      "[6,    69] loss: 0.183\n",
      "[6,    70] loss: 0.156\n",
      "[6,    71] loss: 0.199\n",
      "[6,    72] loss: 0.082\n",
      "[6,    73] loss: 0.168\n",
      "[6,    74] loss: 0.115\n",
      "[6,    75] loss: 0.034\n",
      "[6,    76] loss: 0.160\n",
      "[6,    77] loss: 0.243\n",
      "[6,    78] loss: 0.166\n",
      "[6,    79] loss: 0.194\n",
      "[6,    80] loss: 0.116\n",
      "[6,    81] loss: 0.132\n",
      "[6,    82] loss: 0.127\n",
      "[6,    83] loss: 0.159\n",
      "[6,    84] loss: 0.076\n",
      "[6,    85] loss: 0.135\n",
      "[6,    86] loss: 0.102\n",
      "[6,    87] loss: 0.127\n",
      "[6,    88] loss: 0.094\n",
      "[6,    89] loss: 0.121\n",
      "[6,    90] loss: 0.136\n",
      "[6,    91] loss: 0.036\n",
      "[6,    92] loss: 0.137\n",
      "[6,    93] loss: 0.116\n",
      "[6,    94] loss: 0.118\n",
      "[6,    95] loss: 0.142\n",
      "[6,    96] loss: 0.194\n",
      "[6,    97] loss: 0.125\n",
      "[6,    98] loss: 0.082\n",
      "[6,    99] loss: 0.146\n",
      "[6,   100] loss: 0.064\n",
      "[6,   101] loss: 0.156\n",
      "[6,   102] loss: 0.149\n",
      "[6,   103] loss: 0.186\n",
      "[6,   104] loss: 0.232\n",
      "[6,   105] loss: 0.225\n",
      "[6,   106] loss: 0.074\n",
      "[6,   107] loss: 0.078\n",
      "[6,   108] loss: 0.219\n",
      "[6,   109] loss: 0.075\n",
      "[6,   110] loss: 0.035\n",
      "[6,   111] loss: 0.077\n",
      "[6,   112] loss: 0.175\n",
      "[6,   113] loss: 0.144\n",
      "[6,   114] loss: 0.084\n",
      "[6,   115] loss: 0.159\n",
      "[6,   116] loss: 0.124\n",
      "[6,   117] loss: 0.174\n",
      "[6,   118] loss: 0.130\n",
      "[6,   119] loss: 0.162\n",
      "[6,   120] loss: 0.213\n",
      "[6,   121] loss: 0.138\n",
      "[6,   122] loss: 0.071\n",
      "[6,   123] loss: 0.178\n",
      "[6,   124] loss: 0.101\n",
      "[6,   125] loss: 0.095\n",
      "[6,   126] loss: 0.124\n",
      "[6,   127] loss: 0.106\n",
      "[6,   128] loss: 0.071\n",
      "[6,   129] loss: 0.038\n",
      "[6,   130] loss: 0.128\n",
      "[6,   131] loss: 0.106\n",
      "[6,   132] loss: 0.060\n",
      "[6,   133] loss: 0.247\n",
      "[6,   134] loss: 0.132\n",
      "[6,   135] loss: 0.102\n",
      "[6,   136] loss: 0.135\n",
      "[6,   137] loss: 0.055\n",
      "[6,   138] loss: 0.124\n",
      "[6,   139] loss: 0.164\n",
      "[6,   140] loss: 0.145\n",
      "[6,   141] loss: 0.109\n",
      "[6,   142] loss: 0.113\n",
      "[6,   143] loss: 0.154\n",
      "[6,   144] loss: 0.150\n",
      "[6,   145] loss: 0.211\n",
      "[6,   146] loss: 0.123\n",
      "[6,   147] loss: 0.141\n",
      "[6,   148] loss: 0.170\n",
      "[6,   149] loss: 0.121\n",
      "[6,   150] loss: 0.101\n",
      "[6,   151] loss: 0.088\n",
      "[6,   152] loss: 0.199\n",
      "[6,   153] loss: 0.090\n",
      "[6,   154] loss: 0.116\n",
      "[6,   155] loss: 0.244\n",
      "[6,   156] loss: 0.215\n",
      "[6,   157] loss: 0.125\n",
      "[6,   158] loss: 0.183\n",
      "[6,   159] loss: 0.099\n",
      "[6,   160] loss: 0.033\n",
      "[6,   161] loss: 0.158\n",
      "[6,   162] loss: 0.039\n",
      "[6,   163] loss: 0.120\n",
      "[6,   164] loss: 0.070\n",
      "[6,   165] loss: 0.054\n",
      "[6,   166] loss: 0.085\n",
      "[6,   167] loss: 0.234\n",
      "[6,   168] loss: 0.116\n",
      "[6,   169] loss: 0.088\n",
      "[6,   170] loss: 0.062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6,   171] loss: 0.214\n",
      "[6,   172] loss: 0.104\n",
      "[6,   173] loss: 0.082\n",
      "[6,   174] loss: 0.074\n",
      "[6,   175] loss: 0.200\n",
      "[6,   176] loss: 0.154\n",
      "[6,   177] loss: 0.106\n",
      "[6,   178] loss: 0.169\n",
      "[6,   179] loss: 0.196\n",
      "[6,   180] loss: 0.281\n",
      "[6,   181] loss: 0.138\n",
      "[6,   182] loss: 0.250\n",
      "[6,   183] loss: 0.167\n",
      "[6,   184] loss: 0.162\n",
      "[6,   185] loss: 0.074\n",
      "[6,   186] loss: 0.125\n",
      "[6,   187] loss: 0.200\n",
      "[6,   188] loss: 0.150\n",
      "[6,   189] loss: 0.105\n",
      "[6,   190] loss: 0.143\n",
      "[6,   191] loss: 0.174\n",
      "[6,   192] loss: 0.186\n",
      "[6,   193] loss: 0.129\n",
      "[6,   194] loss: 0.119\n",
      "[6,   195] loss: 0.223\n",
      "[6,   196] loss: 0.109\n",
      "[6,   197] loss: 0.165\n",
      "[6,   198] loss: 0.111\n",
      "[6,   199] loss: 0.144\n",
      "[6,   200] loss: 0.152\n",
      "[6,   201] loss: 0.205\n",
      "[6,   202] loss: 0.158\n",
      "[6,   203] loss: 0.085\n",
      "[6,   204] loss: 0.156\n",
      "[6,   205] loss: 0.165\n",
      "[6,   206] loss: 0.173\n",
      "[6,   207] loss: 0.134\n",
      "[6,   208] loss: 0.252\n",
      "[6,   209] loss: 0.106\n",
      "[6,   210] loss: 0.148\n",
      "[6,   211] loss: 0.154\n",
      "[6,   212] loss: 0.189\n",
      "[6,   213] loss: 0.152\n",
      "[6,   214] loss: 0.166\n",
      "[6,   215] loss: 0.164\n",
      "[6,   216] loss: 0.134\n",
      "[6,   217] loss: 0.084\n",
      "[6,   218] loss: 0.138\n",
      "[6,   219] loss: 0.138\n",
      "[6,   220] loss: 0.180\n",
      "[6,   221] loss: 0.103\n",
      "[6,   222] loss: 0.067\n",
      "[6,   223] loss: 0.185\n",
      "[6,   224] loss: 0.116\n",
      "[6,   225] loss: 0.096\n",
      "[6,   226] loss: 0.192\n",
      "[6,   227] loss: 0.093\n",
      "[6,   228] loss: 0.116\n",
      "[6,   229] loss: 0.199\n",
      "[6,   230] loss: 0.163\n",
      "[6,   231] loss: 0.064\n",
      "[6,   232] loss: 0.182\n",
      "[6,   233] loss: 0.180\n",
      "[6,   234] loss: 0.188\n",
      "[6,   235] loss: 0.180\n",
      "[6,   236] loss: 0.198\n",
      "[6,   237] loss: 0.171\n",
      "[6,   238] loss: 0.079\n",
      "[6,   239] loss: 0.103\n",
      "[6,   240] loss: 0.176\n",
      "[6,   241] loss: 0.190\n",
      "[6,   242] loss: 0.107\n",
      "[6,   243] loss: 0.105\n",
      "[6,   244] loss: 0.112\n",
      "[6,   245] loss: 0.134\n",
      "[6,   246] loss: 0.135\n",
      "[6,   247] loss: 0.157\n",
      "[6,   248] loss: 0.172\n",
      "[6,   249] loss: 0.142\n",
      "[6,   250] loss: 0.145\n",
      "[6,   251] loss: 0.132\n",
      "[6,   252] loss: 0.067\n",
      "[6,   253] loss: 0.127\n",
      "[6,   254] loss: 0.135\n",
      "[6,   255] loss: 0.156\n",
      "[6,   256] loss: 0.097\n",
      "[6,   257] loss: 0.198\n",
      "[6,   258] loss: 0.192\n",
      "[6,   259] loss: 0.091\n",
      "[6,   260] loss: 0.150\n",
      "[6,   261] loss: 0.178\n",
      "[6,   262] loss: 0.202\n",
      "[6,   263] loss: 0.044\n",
      "[6,   264] loss: 0.191\n",
      "[6,   265] loss: 0.142\n",
      "[6,   266] loss: 0.196\n",
      "[6,   267] loss: 0.128\n",
      "[6,   268] loss: 0.227\n",
      "[6,   269] loss: 0.167\n",
      "[6,   270] loss: 0.204\n",
      "[6,   271] loss: 0.160\n",
      "[6,   272] loss: 0.058\n",
      "[6,   273] loss: 0.062\n",
      "[6,   274] loss: 0.201\n",
      "[6,   275] loss: 0.079\n",
      "[6,   276] loss: 0.183\n",
      "[6,   277] loss: 0.089\n",
      "[6,   278] loss: 0.105\n",
      "[6,   279] loss: 0.154\n",
      "[6,   280] loss: 0.099\n",
      "[6,   281] loss: 0.167\n",
      "[6,   282] loss: 0.175\n",
      "[6,   283] loss: 0.190\n",
      "[6,   284] loss: 0.199\n",
      "[6,   285] loss: 0.157\n",
      "[6,   286] loss: 0.117\n",
      "[6,   287] loss: 0.096\n",
      "[6,   288] loss: 0.169\n",
      "[6,   289] loss: 0.064\n",
      "[6,   290] loss: 0.155\n",
      "[6,   291] loss: 0.171\n",
      "[6,   292] loss: 0.103\n",
      "[6,   293] loss: 0.113\n",
      "[6,   294] loss: 0.208\n",
      "[6,   295] loss: 0.204\n",
      "[6,   296] loss: 0.045\n",
      "[6,   297] loss: 0.271\n",
      "[6,   298] loss: 0.062\n",
      "[6,   299] loss: 0.175\n",
      "[6,   300] loss: 0.069\n",
      "[6,   301] loss: 0.192\n",
      "[6,   302] loss: 0.172\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "LOSS train 0.13826967560568984 valid 0.16427098942490725\n",
      "[7,     1] loss: 0.206\n",
      "[7,     2] loss: 0.161\n",
      "[7,     3] loss: 0.115\n",
      "[7,     4] loss: 0.149\n",
      "[7,     5] loss: 0.147\n",
      "[7,     6] loss: 0.147\n",
      "[7,     7] loss: 0.220\n",
      "[7,     8] loss: 0.176\n",
      "[7,     9] loss: 0.162\n",
      "[7,    10] loss: 0.131\n",
      "[7,    11] loss: 0.180\n",
      "[7,    12] loss: 0.188\n",
      "[7,    13] loss: 0.153\n",
      "[7,    14] loss: 0.096\n",
      "[7,    15] loss: 0.023\n",
      "[7,    16] loss: 0.116\n",
      "[7,    17] loss: 0.118\n",
      "[7,    18] loss: 0.150\n",
      "[7,    19] loss: 0.117\n",
      "[7,    20] loss: 0.190\n",
      "[7,    21] loss: 0.154\n",
      "[7,    22] loss: 0.018\n",
      "[7,    23] loss: 0.201\n",
      "[7,    24] loss: 0.121\n",
      "[7,    25] loss: 0.120\n",
      "[7,    26] loss: 0.079\n",
      "[7,    27] loss: 0.232\n",
      "[7,    28] loss: 0.213\n",
      "[7,    29] loss: 0.176\n",
      "[7,    30] loss: 0.108\n",
      "[7,    31] loss: 0.123\n",
      "[7,    32] loss: 0.068\n",
      "[7,    33] loss: 0.147\n",
      "[7,    34] loss: 0.128\n",
      "[7,    35] loss: 0.063\n",
      "[7,    36] loss: 0.064\n",
      "[7,    37] loss: 0.187\n",
      "[7,    38] loss: 0.142\n",
      "[7,    39] loss: 0.189\n",
      "[7,    40] loss: 0.159\n",
      "[7,    41] loss: 0.081\n",
      "[7,    42] loss: 0.159\n",
      "[7,    43] loss: 0.098\n",
      "[7,    44] loss: 0.209\n",
      "[7,    45] loss: 0.054\n",
      "[7,    46] loss: 0.165\n",
      "[7,    47] loss: 0.138\n",
      "[7,    48] loss: 0.076\n",
      "[7,    49] loss: 0.112\n",
      "[7,    50] loss: 0.149\n",
      "[7,    51] loss: 0.109\n",
      "[7,    52] loss: 0.073\n",
      "[7,    53] loss: 0.118\n",
      "[7,    54] loss: 0.080\n",
      "[7,    55] loss: 0.075\n",
      "[7,    56] loss: 0.124\n",
      "[7,    57] loss: 0.144\n",
      "[7,    58] loss: 0.127\n",
      "[7,    59] loss: 0.143\n",
      "[7,    60] loss: 0.106\n",
      "[7,    61] loss: 0.194\n",
      "[7,    62] loss: 0.067\n",
      "[7,    63] loss: 0.106\n",
      "[7,    64] loss: 0.159\n",
      "[7,    65] loss: 0.068\n",
      "[7,    66] loss: 0.130\n",
      "[7,    67] loss: 0.134\n",
      "[7,    68] loss: 0.160\n",
      "[7,    69] loss: 0.180\n",
      "[7,    70] loss: 0.155\n",
      "[7,    71] loss: 0.195\n",
      "[7,    72] loss: 0.081\n",
      "[7,    73] loss: 0.165\n",
      "[7,    74] loss: 0.114\n",
      "[7,    75] loss: 0.034\n",
      "[7,    76] loss: 0.159\n",
      "[7,    77] loss: 0.238\n",
      "[7,    78] loss: 0.164\n",
      "[7,    79] loss: 0.192\n",
      "[7,    80] loss: 0.115\n",
      "[7,    81] loss: 0.130\n",
      "[7,    82] loss: 0.126\n",
      "[7,    83] loss: 0.157\n",
      "[7,    84] loss: 0.074\n",
      "[7,    85] loss: 0.133\n",
      "[7,    86] loss: 0.101\n",
      "[7,    87] loss: 0.126\n",
      "[7,    88] loss: 0.093\n",
      "[7,    89] loss: 0.120\n",
      "[7,    90] loss: 0.136\n",
      "[7,    91] loss: 0.034\n",
      "[7,    92] loss: 0.135\n",
      "[7,    93] loss: 0.115\n",
      "[7,    94] loss: 0.116\n",
      "[7,    95] loss: 0.141\n",
      "[7,    96] loss: 0.192\n",
      "[7,    97] loss: 0.123\n",
      "[7,    98] loss: 0.082\n",
      "[7,    99] loss: 0.144\n",
      "[7,   100] loss: 0.063\n",
      "[7,   101] loss: 0.155\n",
      "[7,   102] loss: 0.146\n",
      "[7,   103] loss: 0.182\n",
      "[7,   104] loss: 0.226\n",
      "[7,   105] loss: 0.221\n",
      "[7,   106] loss: 0.072\n",
      "[7,   107] loss: 0.078\n",
      "[7,   108] loss: 0.217\n",
      "[7,   109] loss: 0.073\n",
      "[7,   110] loss: 0.032\n",
      "[7,   111] loss: 0.077\n",
      "[7,   112] loss: 0.172\n",
      "[7,   113] loss: 0.142\n",
      "[7,   114] loss: 0.082\n",
      "[7,   115] loss: 0.157\n",
      "[7,   116] loss: 0.120\n",
      "[7,   117] loss: 0.173\n",
      "[7,   118] loss: 0.128\n",
      "[7,   119] loss: 0.160\n",
      "[7,   120] loss: 0.211\n",
      "[7,   121] loss: 0.134\n",
      "[7,   122] loss: 0.071\n",
      "[7,   123] loss: 0.176\n",
      "[7,   124] loss: 0.099\n",
      "[7,   125] loss: 0.094\n",
      "[7,   126] loss: 0.124\n",
      "[7,   127] loss: 0.106\n",
      "[7,   128] loss: 0.065\n",
      "[7,   129] loss: 0.035\n",
      "[7,   130] loss: 0.127\n",
      "[7,   131] loss: 0.105\n",
      "[7,   132] loss: 0.058\n",
      "[7,   133] loss: 0.239\n",
      "[7,   134] loss: 0.130\n",
      "[7,   135] loss: 0.099\n",
      "[7,   136] loss: 0.134\n",
      "[7,   137] loss: 0.053\n",
      "[7,   138] loss: 0.123\n",
      "[7,   139] loss: 0.163\n",
      "[7,   140] loss: 0.143\n",
      "[7,   141] loss: 0.107\n",
      "[7,   142] loss: 0.111\n",
      "[7,   143] loss: 0.151\n",
      "[7,   144] loss: 0.148\n",
      "[7,   145] loss: 0.204\n",
      "[7,   146] loss: 0.122\n",
      "[7,   147] loss: 0.140\n",
      "[7,   148] loss: 0.169\n",
      "[7,   149] loss: 0.119\n",
      "[7,   150] loss: 0.099\n",
      "[7,   151] loss: 0.083\n",
      "[7,   152] loss: 0.197\n",
      "[7,   153] loss: 0.090\n",
      "[7,   154] loss: 0.115\n",
      "[7,   155] loss: 0.236\n",
      "[7,   156] loss: 0.211\n",
      "[7,   157] loss: 0.125\n",
      "[7,   158] loss: 0.183\n",
      "[7,   159] loss: 0.098\n",
      "[7,   160] loss: 0.032\n",
      "[7,   161] loss: 0.160\n",
      "[7,   162] loss: 0.038\n",
      "[7,   163] loss: 0.121\n",
      "[7,   164] loss: 0.066\n",
      "[7,   165] loss: 0.053\n",
      "[7,   166] loss: 0.084\n",
      "[7,   167] loss: 0.228\n",
      "[7,   168] loss: 0.113\n",
      "[7,   169] loss: 0.083\n",
      "[7,   170] loss: 0.061\n",
      "[7,   171] loss: 0.210\n",
      "[7,   172] loss: 0.102\n",
      "[7,   173] loss: 0.084\n",
      "[7,   174] loss: 0.074\n",
      "[7,   175] loss: 0.195\n",
      "[7,   176] loss: 0.148\n",
      "[7,   177] loss: 0.103\n",
      "[7,   178] loss: 0.167\n",
      "[7,   179] loss: 0.193\n",
      "[7,   180] loss: 0.273\n",
      "[7,   181] loss: 0.134\n",
      "[7,   182] loss: 0.244\n",
      "[7,   183] loss: 0.164\n",
      "[7,   184] loss: 0.152\n",
      "[7,   185] loss: 0.073\n",
      "[7,   186] loss: 0.119\n",
      "[7,   187] loss: 0.198\n",
      "[7,   188] loss: 0.148\n",
      "[7,   189] loss: 0.102\n",
      "[7,   190] loss: 0.141\n",
      "[7,   191] loss: 0.168\n",
      "[7,   192] loss: 0.181\n",
      "[7,   193] loss: 0.127\n",
      "[7,   194] loss: 0.118\n",
      "[7,   195] loss: 0.218\n",
      "[7,   196] loss: 0.108\n",
      "[7,   197] loss: 0.161\n",
      "[7,   198] loss: 0.108\n",
      "[7,   199] loss: 0.142\n",
      "[7,   200] loss: 0.149\n",
      "[7,   201] loss: 0.201\n",
      "[7,   202] loss: 0.156\n",
      "[7,   203] loss: 0.084\n",
      "[7,   204] loss: 0.155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7,   205] loss: 0.163\n",
      "[7,   206] loss: 0.170\n",
      "[7,   207] loss: 0.133\n",
      "[7,   208] loss: 0.246\n",
      "[7,   209] loss: 0.106\n",
      "[7,   210] loss: 0.147\n",
      "[7,   211] loss: 0.152\n",
      "[7,   212] loss: 0.185\n",
      "[7,   213] loss: 0.151\n",
      "[7,   214] loss: 0.165\n",
      "[7,   215] loss: 0.163\n",
      "[7,   216] loss: 0.132\n",
      "[7,   217] loss: 0.083\n",
      "[7,   218] loss: 0.137\n",
      "[7,   219] loss: 0.136\n",
      "[7,   220] loss: 0.179\n",
      "[7,   221] loss: 0.101\n",
      "[7,   222] loss: 0.066\n",
      "[7,   223] loss: 0.181\n",
      "[7,   224] loss: 0.114\n",
      "[7,   225] loss: 0.095\n",
      "[7,   226] loss: 0.189\n",
      "[7,   227] loss: 0.091\n",
      "[7,   228] loss: 0.115\n",
      "[7,   229] loss: 0.197\n",
      "[7,   230] loss: 0.162\n",
      "[7,   231] loss: 0.064\n",
      "[7,   232] loss: 0.177\n",
      "[7,   233] loss: 0.179\n",
      "[7,   234] loss: 0.187\n",
      "[7,   235] loss: 0.177\n",
      "[7,   236] loss: 0.194\n",
      "[7,   237] loss: 0.167\n",
      "[7,   238] loss: 0.078\n",
      "[7,   239] loss: 0.103\n",
      "[7,   240] loss: 0.172\n",
      "[7,   241] loss: 0.188\n",
      "[7,   242] loss: 0.105\n",
      "[7,   243] loss: 0.103\n",
      "[7,   244] loss: 0.113\n",
      "[7,   245] loss: 0.133\n",
      "[7,   246] loss: 0.134\n",
      "[7,   247] loss: 0.156\n",
      "[7,   248] loss: 0.171\n",
      "[7,   249] loss: 0.141\n",
      "[7,   250] loss: 0.138\n",
      "[7,   251] loss: 0.129\n",
      "[7,   252] loss: 0.067\n",
      "[7,   253] loss: 0.126\n",
      "[7,   254] loss: 0.130\n",
      "[7,   255] loss: 0.153\n",
      "[7,   256] loss: 0.096\n",
      "[7,   257] loss: 0.198\n",
      "[7,   258] loss: 0.190\n",
      "[7,   259] loss: 0.090\n",
      "[7,   260] loss: 0.149\n",
      "[7,   261] loss: 0.177\n",
      "[7,   262] loss: 0.200\n",
      "[7,   263] loss: 0.040\n",
      "[7,   264] loss: 0.188\n",
      "[7,   265] loss: 0.141\n",
      "[7,   266] loss: 0.193\n",
      "[7,   267] loss: 0.127\n",
      "[7,   268] loss: 0.222\n",
      "[7,   269] loss: 0.165\n",
      "[7,   270] loss: 0.202\n",
      "[7,   271] loss: 0.158\n",
      "[7,   272] loss: 0.057\n",
      "[7,   273] loss: 0.062\n",
      "[7,   274] loss: 0.200\n",
      "[7,   275] loss: 0.077\n",
      "[7,   276] loss: 0.169\n",
      "[7,   277] loss: 0.088\n",
      "[7,   278] loss: 0.104\n",
      "[7,   279] loss: 0.152\n",
      "[7,   280] loss: 0.098\n",
      "[7,   281] loss: 0.165\n",
      "[7,   282] loss: 0.172\n",
      "[7,   283] loss: 0.184\n",
      "[7,   284] loss: 0.197\n",
      "[7,   285] loss: 0.156\n",
      "[7,   286] loss: 0.116\n",
      "[7,   287] loss: 0.100\n",
      "[7,   288] loss: 0.165\n",
      "[7,   289] loss: 0.062\n",
      "[7,   290] loss: 0.154\n",
      "[7,   291] loss: 0.168\n",
      "[7,   292] loss: 0.102\n",
      "[7,   293] loss: 0.112\n",
      "[7,   294] loss: 0.212\n",
      "[7,   295] loss: 0.206\n",
      "[7,   296] loss: 0.043\n",
      "[7,   297] loss: 0.263\n",
      "[7,   298] loss: 0.062\n",
      "[7,   299] loss: 0.175\n",
      "[7,   300] loss: 0.073\n",
      "[7,   301] loss: 0.193\n",
      "[7,   302] loss: 0.167\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "LOSS train 0.13611503623253265 valid 0.1920278430558168\n",
      "[8,     1] loss: 0.208\n",
      "[8,     2] loss: 0.182\n",
      "[8,     3] loss: 0.115\n",
      "[8,     4] loss: 0.149\n",
      "[8,     5] loss: 0.148\n",
      "[8,     6] loss: 0.150\n",
      "[8,     7] loss: 0.218\n",
      "[8,     8] loss: 0.175\n",
      "[8,     9] loss: 0.158\n",
      "[8,    10] loss: 0.126\n",
      "[8,    11] loss: 0.183\n",
      "[8,    12] loss: 0.185\n",
      "[8,    13] loss: 0.149\n",
      "[8,    14] loss: 0.095\n",
      "[8,    15] loss: 0.023\n",
      "[8,    16] loss: 0.116\n",
      "[8,    17] loss: 0.118\n",
      "[8,    18] loss: 0.148\n",
      "[8,    19] loss: 0.118\n",
      "[8,    20] loss: 0.187\n",
      "[8,    21] loss: 0.153\n",
      "[8,    22] loss: 0.017\n",
      "[8,    23] loss: 0.200\n",
      "[8,    24] loss: 0.119\n",
      "[8,    25] loss: 0.118\n",
      "[8,    26] loss: 0.079\n",
      "[8,    27] loss: 0.229\n",
      "[8,    28] loss: 0.211\n",
      "[8,    29] loss: 0.175\n",
      "[8,    30] loss: 0.102\n",
      "[8,    31] loss: 0.127\n",
      "[8,    32] loss: 0.068\n",
      "[8,    33] loss: 0.146\n",
      "[8,    34] loss: 0.132\n",
      "[8,    35] loss: 0.063\n",
      "[8,    36] loss: 0.095\n",
      "[8,    37] loss: 0.190\n",
      "[8,    38] loss: 0.143\n",
      "[8,    39] loss: 0.185\n",
      "[8,    40] loss: 0.161\n",
      "[8,    41] loss: 0.101\n",
      "[8,    42] loss: 0.158\n",
      "[8,    43] loss: 0.100\n",
      "[8,    44] loss: 0.205\n",
      "[8,    45] loss: 0.077\n",
      "[8,    46] loss: 0.162\n",
      "[8,    47] loss: 0.144\n",
      "[8,    48] loss: 0.076\n",
      "[8,    49] loss: 0.116\n",
      "[8,    50] loss: 0.153\n",
      "[8,    51] loss: 0.106\n",
      "[8,    52] loss: 0.076\n",
      "[8,    53] loss: 0.117\n",
      "[8,    54] loss: 0.078\n",
      "[8,    55] loss: 0.075\n",
      "[8,    56] loss: 0.122\n",
      "[8,    57] loss: 0.145\n",
      "[8,    58] loss: 0.122\n",
      "[8,    59] loss: 0.142\n",
      "[8,    60] loss: 0.111\n",
      "[8,    61] loss: 0.192\n",
      "[8,    62] loss: 0.066\n",
      "[8,    63] loss: 0.112\n",
      "[8,    64] loss: 0.159\n",
      "[8,    65] loss: 0.067\n",
      "[8,    66] loss: 0.127\n",
      "[8,    67] loss: 0.130\n",
      "[8,    68] loss: 0.159\n",
      "[8,    69] loss: 0.180\n",
      "[8,    70] loss: 0.153\n",
      "[8,    71] loss: 0.202\n",
      "[8,    72] loss: 0.088\n",
      "[8,    73] loss: 0.162\n",
      "[8,    74] loss: 0.112\n",
      "[8,    75] loss: 0.035\n",
      "[8,    76] loss: 0.162\n",
      "[8,    77] loss: 0.235\n",
      "[8,    78] loss: 0.161\n",
      "[8,    79] loss: 0.187\n",
      "[8,    80] loss: 0.115\n",
      "[8,    81] loss: 0.129\n",
      "[8,    82] loss: 0.125\n",
      "[8,    83] loss: 0.157\n",
      "[8,    84] loss: 0.072\n",
      "[8,    85] loss: 0.135\n",
      "[8,    86] loss: 0.103\n",
      "[8,    87] loss: 0.120\n",
      "[8,    88] loss: 0.092\n",
      "[8,    89] loss: 0.120\n",
      "[8,    90] loss: 0.134\n",
      "[8,    91] loss: 0.041\n",
      "[8,    92] loss: 0.134\n",
      "[8,    93] loss: 0.115\n",
      "[8,    94] loss: 0.116\n",
      "[8,    95] loss: 0.139\n",
      "[8,    96] loss: 0.192\n",
      "[8,    97] loss: 0.122\n",
      "[8,    98] loss: 0.080\n",
      "[8,    99] loss: 0.143\n",
      "[8,   100] loss: 0.063\n",
      "[8,   101] loss: 0.156\n",
      "[8,   102] loss: 0.146\n",
      "[8,   103] loss: 0.187\n",
      "[8,   104] loss: 0.229\n",
      "[8,   105] loss: 0.219\n",
      "[8,   106] loss: 0.068\n",
      "[8,   107] loss: 0.079\n",
      "[8,   108] loss: 0.219\n",
      "[8,   109] loss: 0.074\n",
      "[8,   110] loss: 0.034\n",
      "[8,   111] loss: 0.074\n",
      "[8,   112] loss: 0.175\n",
      "[8,   113] loss: 0.141\n",
      "[8,   114] loss: 0.084\n",
      "[8,   115] loss: 0.159\n",
      "[8,   116] loss: 0.128\n",
      "[8,   117] loss: 0.171\n",
      "[8,   118] loss: 0.128\n",
      "[8,   119] loss: 0.160\n",
      "[8,   120] loss: 0.210\n",
      "[8,   121] loss: 0.134\n",
      "[8,   122] loss: 0.069\n",
      "[8,   123] loss: 0.175\n",
      "[8,   124] loss: 0.098\n",
      "[8,   125] loss: 0.093\n",
      "[8,   126] loss: 0.123\n",
      "[8,   127] loss: 0.104\n",
      "[8,   128] loss: 0.065\n",
      "[8,   129] loss: 0.034\n",
      "[8,   130] loss: 0.126\n",
      "[8,   131] loss: 0.105\n",
      "[8,   132] loss: 0.058\n",
      "[8,   133] loss: 0.234\n",
      "[8,   134] loss: 0.130\n",
      "[8,   135] loss: 0.099\n",
      "[8,   136] loss: 0.132\n",
      "[8,   137] loss: 0.053\n",
      "[8,   138] loss: 0.122\n",
      "[8,   139] loss: 0.161\n",
      "[8,   140] loss: 0.142\n",
      "[8,   141] loss: 0.106\n",
      "[8,   142] loss: 0.110\n",
      "[8,   143] loss: 0.149\n",
      "[8,   144] loss: 0.146\n",
      "[8,   145] loss: 0.205\n",
      "[8,   146] loss: 0.121\n",
      "[8,   147] loss: 0.140\n",
      "[8,   148] loss: 0.168\n",
      "[8,   149] loss: 0.119\n",
      "[8,   150] loss: 0.098\n",
      "[8,   151] loss: 0.081\n",
      "[8,   152] loss: 0.197\n",
      "[8,   153] loss: 0.088\n",
      "[8,   154] loss: 0.113\n",
      "[8,   155] loss: 0.234\n",
      "[8,   156] loss: 0.209\n",
      "[8,   157] loss: 0.121\n",
      "[8,   158] loss: 0.181\n",
      "[8,   159] loss: 0.098\n",
      "[8,   160] loss: 0.033\n",
      "[8,   161] loss: 0.152\n",
      "[8,   162] loss: 0.037\n",
      "[8,   163] loss: 0.118\n",
      "[8,   164] loss: 0.064\n",
      "[8,   165] loss: 0.051\n",
      "[8,   166] loss: 0.084\n",
      "[8,   167] loss: 0.228\n",
      "[8,   168] loss: 0.117\n",
      "[8,   169] loss: 0.086\n",
      "[8,   170] loss: 0.061\n",
      "[8,   171] loss: 0.209\n",
      "[8,   172] loss: 0.101\n",
      "[8,   173] loss: 0.083\n",
      "[8,   174] loss: 0.075\n",
      "[8,   175] loss: 0.192\n",
      "[8,   176] loss: 0.148\n",
      "[8,   177] loss: 0.102\n",
      "[8,   178] loss: 0.166\n",
      "[8,   179] loss: 0.191\n",
      "[8,   180] loss: 0.268\n",
      "[8,   181] loss: 0.131\n",
      "[8,   182] loss: 0.239\n",
      "[8,   183] loss: 0.164\n",
      "[8,   184] loss: 0.153\n",
      "[8,   185] loss: 0.073\n",
      "[8,   186] loss: 0.122\n",
      "[8,   187] loss: 0.198\n",
      "[8,   188] loss: 0.146\n",
      "[8,   189] loss: 0.104\n",
      "[8,   190] loss: 0.144\n",
      "[8,   191] loss: 0.171\n",
      "[8,   192] loss: 0.181\n",
      "[8,   193] loss: 0.124\n",
      "[8,   194] loss: 0.115\n",
      "[8,   195] loss: 0.216\n",
      "[8,   196] loss: 0.107\n",
      "[8,   197] loss: 0.163\n",
      "[8,   198] loss: 0.108\n",
      "[8,   199] loss: 0.142\n",
      "[8,   200] loss: 0.149\n",
      "[8,   201] loss: 0.200\n",
      "[8,   202] loss: 0.154\n",
      "[8,   203] loss: 0.083\n",
      "[8,   204] loss: 0.154\n",
      "[8,   205] loss: 0.162\n",
      "[8,   206] loss: 0.169\n",
      "[8,   207] loss: 0.131\n",
      "[8,   208] loss: 0.244\n",
      "[8,   209] loss: 0.105\n",
      "[8,   210] loss: 0.145\n",
      "[8,   211] loss: 0.151\n",
      "[8,   212] loss: 0.184\n",
      "[8,   213] loss: 0.149\n",
      "[8,   214] loss: 0.164\n",
      "[8,   215] loss: 0.161\n",
      "[8,   216] loss: 0.131\n",
      "[8,   217] loss: 0.082\n",
      "[8,   218] loss: 0.136\n",
      "[8,   219] loss: 0.135\n",
      "[8,   220] loss: 0.177\n",
      "[8,   221] loss: 0.100\n",
      "[8,   222] loss: 0.065\n",
      "[8,   223] loss: 0.180\n",
      "[8,   224] loss: 0.114\n",
      "[8,   225] loss: 0.094\n",
      "[8,   226] loss: 0.186\n",
      "[8,   227] loss: 0.086\n",
      "[8,   228] loss: 0.114\n",
      "[8,   229] loss: 0.194\n",
      "[8,   230] loss: 0.160\n",
      "[8,   231] loss: 0.063\n",
      "[8,   232] loss: 0.174\n",
      "[8,   233] loss: 0.177\n",
      "[8,   234] loss: 0.184\n",
      "[8,   235] loss: 0.175\n",
      "[8,   236] loss: 0.192\n",
      "[8,   237] loss: 0.165\n",
      "[8,   238] loss: 0.077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8,   239] loss: 0.101\n",
      "[8,   240] loss: 0.170\n",
      "[8,   241] loss: 0.187\n",
      "[8,   242] loss: 0.105\n",
      "[8,   243] loss: 0.101\n",
      "[8,   244] loss: 0.111\n",
      "[8,   245] loss: 0.132\n",
      "[8,   246] loss: 0.133\n",
      "[8,   247] loss: 0.155\n",
      "[8,   248] loss: 0.169\n",
      "[8,   249] loss: 0.139\n",
      "[8,   250] loss: 0.139\n",
      "[8,   251] loss: 0.129\n",
      "[8,   252] loss: 0.066\n",
      "[8,   253] loss: 0.127\n",
      "[8,   254] loss: 0.129\n",
      "[8,   255] loss: 0.151\n",
      "[8,   256] loss: 0.095\n",
      "[8,   257] loss: 0.198\n",
      "[8,   258] loss: 0.189\n",
      "[8,   259] loss: 0.090\n",
      "[8,   260] loss: 0.147\n",
      "[8,   261] loss: 0.176\n",
      "[8,   262] loss: 0.199\n",
      "[8,   263] loss: 0.043\n",
      "[8,   264] loss: 0.187\n",
      "[8,   265] loss: 0.139\n",
      "[8,   266] loss: 0.196\n",
      "[8,   267] loss: 0.126\n",
      "[8,   268] loss: 0.219\n",
      "[8,   269] loss: 0.163\n",
      "[8,   270] loss: 0.200\n",
      "[8,   271] loss: 0.157\n",
      "[8,   272] loss: 0.056\n",
      "[8,   273] loss: 0.061\n",
      "[8,   274] loss: 0.199\n",
      "[8,   275] loss: 0.076\n",
      "[8,   276] loss: 0.169\n",
      "[8,   277] loss: 0.086\n",
      "[8,   278] loss: 0.103\n",
      "[8,   279] loss: 0.151\n",
      "[8,   280] loss: 0.094\n",
      "[8,   281] loss: 0.163\n",
      "[8,   282] loss: 0.169\n",
      "[8,   283] loss: 0.183\n",
      "[8,   284] loss: 0.196\n",
      "[8,   285] loss: 0.153\n",
      "[8,   286] loss: 0.115\n",
      "[8,   287] loss: 0.095\n",
      "[8,   288] loss: 0.163\n",
      "[8,   289] loss: 0.059\n",
      "[8,   290] loss: 0.152\n",
      "[8,   291] loss: 0.166\n",
      "[8,   292] loss: 0.107\n",
      "[8,   293] loss: 0.111\n",
      "[8,   294] loss: 0.204\n",
      "[8,   295] loss: 0.200\n",
      "[8,   296] loss: 0.045\n",
      "[8,   297] loss: 0.258\n",
      "[8,   298] loss: 0.069\n",
      "[8,   299] loss: 0.173\n",
      "[8,   300] loss: 0.076\n",
      "[8,   301] loss: 0.187\n",
      "[8,   302] loss: 0.167\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "LOSS train 0.13567214061364236 valid 0.19116772820170108\n",
      "[9,     1] loss: 0.203\n",
      "[9,     2] loss: 0.168\n",
      "[9,     3] loss: 0.118\n",
      "[9,     4] loss: 0.148\n",
      "[9,     5] loss: 0.146\n",
      "[9,     6] loss: 0.144\n",
      "[9,     7] loss: 0.215\n",
      "[9,     8] loss: 0.176\n",
      "[9,     9] loss: 0.163\n",
      "[9,    10] loss: 0.138\n",
      "[9,    11] loss: 0.177\n",
      "[9,    12] loss: 0.182\n",
      "[9,    13] loss: 0.148\n",
      "[9,    14] loss: 0.096\n",
      "[9,    15] loss: 0.024\n",
      "[9,    16] loss: 0.116\n",
      "[9,    17] loss: 0.118\n",
      "[9,    18] loss: 0.151\n",
      "[9,    19] loss: 0.115\n",
      "[9,    20] loss: 0.187\n",
      "[9,    21] loss: 0.152\n",
      "[9,    22] loss: 0.023\n",
      "[9,    23] loss: 0.196\n",
      "[9,    24] loss: 0.125\n",
      "[9,    25] loss: 0.121\n",
      "[9,    26] loss: 0.077\n",
      "[9,    27] loss: 0.230\n",
      "[9,    28] loss: 0.212\n",
      "[9,    29] loss: 0.174\n",
      "[9,    30] loss: 0.101\n",
      "[9,    31] loss: 0.119\n",
      "[9,    32] loss: 0.070\n",
      "[9,    33] loss: 0.145\n",
      "[9,    34] loss: 0.127\n",
      "[9,    35] loss: 0.063\n",
      "[9,    36] loss: 0.060\n",
      "[9,    37] loss: 0.179\n",
      "[9,    38] loss: 0.143\n",
      "[9,    39] loss: 0.183\n",
      "[9,    40] loss: 0.156\n",
      "[9,    41] loss: 0.077\n",
      "[9,    42] loss: 0.157\n",
      "[9,    43] loss: 0.095\n",
      "[9,    44] loss: 0.201\n",
      "[9,    45] loss: 0.046\n",
      "[9,    46] loss: 0.160\n",
      "[9,    47] loss: 0.136\n",
      "[9,    48] loss: 0.074\n",
      "[9,    49] loss: 0.108\n",
      "[9,    50] loss: 0.146\n",
      "[9,    51] loss: 0.103\n",
      "[9,    52] loss: 0.073\n",
      "[9,    53] loss: 0.115\n",
      "[9,    54] loss: 0.077\n",
      "[9,    55] loss: 0.072\n",
      "[9,    56] loss: 0.119\n",
      "[9,    57] loss: 0.142\n",
      "[9,    58] loss: 0.121\n",
      "[9,    59] loss: 0.140\n",
      "[9,    60] loss: 0.104\n",
      "[9,    61] loss: 0.189\n",
      "[9,    62] loss: 0.064\n",
      "[9,    63] loss: 0.105\n",
      "[9,    64] loss: 0.155\n",
      "[9,    65] loss: 0.066\n",
      "[9,    66] loss: 0.130\n",
      "[9,    67] loss: 0.131\n",
      "[9,    68] loss: 0.158\n",
      "[9,    69] loss: 0.175\n",
      "[9,    70] loss: 0.151\n",
      "[9,    71] loss: 0.192\n",
      "[9,    72] loss: 0.078\n",
      "[9,    73] loss: 0.161\n",
      "[9,    74] loss: 0.110\n",
      "[9,    75] loss: 0.033\n",
      "[9,    76] loss: 0.154\n",
      "[9,    77] loss: 0.232\n",
      "[9,    78] loss: 0.162\n",
      "[9,    79] loss: 0.187\n",
      "[9,    80] loss: 0.113\n",
      "[9,    81] loss: 0.131\n",
      "[9,    82] loss: 0.124\n",
      "[9,    83] loss: 0.154\n",
      "[9,    84] loss: 0.070\n",
      "[9,    85] loss: 0.130\n",
      "[9,    86] loss: 0.101\n",
      "[9,    87] loss: 0.120\n",
      "[9,    88] loss: 0.092\n",
      "[9,    89] loss: 0.118\n",
      "[9,    90] loss: 0.133\n",
      "[9,    91] loss: 0.034\n",
      "[9,    92] loss: 0.133\n",
      "[9,    93] loss: 0.113\n",
      "[9,    94] loss: 0.114\n",
      "[9,    95] loss: 0.138\n",
      "[9,    96] loss: 0.187\n",
      "[9,    97] loss: 0.121\n",
      "[9,    98] loss: 0.082\n",
      "[9,    99] loss: 0.142\n",
      "[9,   100] loss: 0.062\n",
      "[9,   101] loss: 0.151\n",
      "[9,   102] loss: 0.147\n",
      "[9,   103] loss: 0.177\n",
      "[9,   104] loss: 0.219\n",
      "[9,   105] loss: 0.217\n",
      "[9,   106] loss: 0.073\n",
      "[9,   107] loss: 0.076\n",
      "[9,   108] loss: 0.216\n",
      "[9,   109] loss: 0.073\n",
      "[9,   110] loss: 0.029\n",
      "[9,   111] loss: 0.074\n",
      "[9,   112] loss: 0.169\n",
      "[9,   113] loss: 0.138\n",
      "[9,   114] loss: 0.080\n",
      "[9,   115] loss: 0.153\n",
      "[9,   116] loss: 0.121\n",
      "[9,   117] loss: 0.169\n",
      "[9,   118] loss: 0.127\n",
      "[9,   119] loss: 0.157\n",
      "[9,   120] loss: 0.207\n",
      "[9,   121] loss: 0.132\n",
      "[9,   122] loss: 0.069\n",
      "[9,   123] loss: 0.173\n",
      "[9,   124] loss: 0.098\n",
      "[9,   125] loss: 0.092\n",
      "[9,   126] loss: 0.121\n",
      "[9,   127] loss: 0.104\n",
      "[9,   128] loss: 0.062\n",
      "[9,   129] loss: 0.035\n",
      "[9,   130] loss: 0.124\n",
      "[9,   131] loss: 0.104\n",
      "[9,   132] loss: 0.058\n",
      "[9,   133] loss: 0.227\n",
      "[9,   134] loss: 0.128\n",
      "[9,   135] loss: 0.096\n",
      "[9,   136] loss: 0.131\n",
      "[9,   137] loss: 0.048\n",
      "[9,   138] loss: 0.119\n",
      "[9,   139] loss: 0.159\n",
      "[9,   140] loss: 0.141\n",
      "[9,   141] loss: 0.104\n",
      "[9,   142] loss: 0.111\n",
      "[9,   143] loss: 0.146\n",
      "[9,   144] loss: 0.144\n",
      "[9,   145] loss: 0.195\n",
      "[9,   146] loss: 0.120\n",
      "[9,   147] loss: 0.138\n",
      "[9,   148] loss: 0.165\n",
      "[9,   149] loss: 0.115\n",
      "[9,   150] loss: 0.096\n",
      "[9,   151] loss: 0.078\n",
      "[9,   152] loss: 0.195\n",
      "[9,   153] loss: 0.090\n",
      "[9,   154] loss: 0.112\n",
      "[9,   155] loss: 0.228\n",
      "[9,   156] loss: 0.206\n",
      "[9,   157] loss: 0.121\n",
      "[9,   158] loss: 0.179\n",
      "[9,   159] loss: 0.096\n",
      "[9,   160] loss: 0.031\n",
      "[9,   161] loss: 0.149\n",
      "[9,   162] loss: 0.037\n",
      "[9,   163] loss: 0.117\n",
      "[9,   164] loss: 0.067\n",
      "[9,   165] loss: 0.051\n",
      "[9,   166] loss: 0.083\n",
      "[9,   167] loss: 0.224\n",
      "[9,   168] loss: 0.113\n",
      "[9,   169] loss: 0.086\n",
      "[9,   170] loss: 0.060\n",
      "[9,   171] loss: 0.207\n",
      "[9,   172] loss: 0.100\n",
      "[9,   173] loss: 0.081\n",
      "[9,   174] loss: 0.071\n",
      "[9,   175] loss: 0.192\n",
      "[9,   176] loss: 0.149\n",
      "[9,   177] loss: 0.101\n",
      "[9,   178] loss: 0.166\n",
      "[9,   179] loss: 0.189\n",
      "[9,   180] loss: 0.263\n",
      "[9,   181] loss: 0.126\n",
      "[9,   182] loss: 0.236\n",
      "[9,   183] loss: 0.165\n",
      "[9,   184] loss: 0.156\n",
      "[9,   185] loss: 0.073\n",
      "[9,   186] loss: 0.117\n",
      "[9,   187] loss: 0.196\n",
      "[9,   188] loss: 0.145\n",
      "[9,   189] loss: 0.102\n",
      "[9,   190] loss: 0.142\n",
      "[9,   191] loss: 0.164\n",
      "[9,   192] loss: 0.177\n",
      "[9,   193] loss: 0.124\n",
      "[9,   194] loss: 0.115\n",
      "[9,   195] loss: 0.214\n",
      "[9,   196] loss: 0.106\n",
      "[9,   197] loss: 0.157\n",
      "[9,   198] loss: 0.107\n",
      "[9,   199] loss: 0.139\n",
      "[9,   200] loss: 0.147\n",
      "[9,   201] loss: 0.198\n",
      "[9,   202] loss: 0.155\n",
      "[9,   203] loss: 0.083\n",
      "[9,   204] loss: 0.153\n",
      "[9,   205] loss: 0.159\n",
      "[9,   206] loss: 0.169\n",
      "[9,   207] loss: 0.131\n",
      "[9,   208] loss: 0.241\n",
      "[9,   209] loss: 0.105\n",
      "[9,   210] loss: 0.144\n",
      "[9,   211] loss: 0.150\n",
      "[9,   212] loss: 0.185\n",
      "[9,   213] loss: 0.147\n",
      "[9,   214] loss: 0.163\n",
      "[9,   215] loss: 0.160\n",
      "[9,   216] loss: 0.130\n",
      "[9,   217] loss: 0.081\n",
      "[9,   218] loss: 0.134\n",
      "[9,   219] loss: 0.134\n",
      "[9,   220] loss: 0.176\n",
      "[9,   221] loss: 0.097\n",
      "[9,   222] loss: 0.065\n",
      "[9,   223] loss: 0.178\n",
      "[9,   224] loss: 0.113\n",
      "[9,   225] loss: 0.094\n",
      "[9,   226] loss: 0.184\n",
      "[9,   227] loss: 0.084\n",
      "[9,   228] loss: 0.113\n",
      "[9,   229] loss: 0.194\n",
      "[9,   230] loss: 0.160\n",
      "[9,   231] loss: 0.063\n",
      "[9,   232] loss: 0.173\n",
      "[9,   233] loss: 0.175\n",
      "[9,   234] loss: 0.183\n",
      "[9,   235] loss: 0.174\n",
      "[9,   236] loss: 0.190\n",
      "[9,   237] loss: 0.163\n",
      "[9,   238] loss: 0.076\n",
      "[9,   239] loss: 0.100\n",
      "[9,   240] loss: 0.171\n",
      "[9,   241] loss: 0.186\n",
      "[9,   242] loss: 0.104\n",
      "[9,   243] loss: 0.098\n",
      "[9,   244] loss: 0.108\n",
      "[9,   245] loss: 0.131\n",
      "[9,   246] loss: 0.134\n",
      "[9,   247] loss: 0.153\n",
      "[9,   248] loss: 0.168\n",
      "[9,   249] loss: 0.140\n",
      "[9,   250] loss: 0.132\n",
      "[9,   251] loss: 0.126\n",
      "[9,   252] loss: 0.066\n",
      "[9,   253] loss: 0.126\n",
      "[9,   254] loss: 0.129\n",
      "[9,   255] loss: 0.150\n",
      "[9,   256] loss: 0.094\n",
      "[9,   257] loss: 0.189\n",
      "[9,   258] loss: 0.187\n",
      "[9,   259] loss: 0.090\n",
      "[9,   260] loss: 0.145\n",
      "[9,   261] loss: 0.175\n",
      "[9,   262] loss: 0.197\n",
      "[9,   263] loss: 0.040\n",
      "[9,   264] loss: 0.185\n",
      "[9,   265] loss: 0.138\n",
      "[9,   266] loss: 0.191\n",
      "[9,   267] loss: 0.125\n",
      "[9,   268] loss: 0.218\n",
      "[9,   269] loss: 0.162\n",
      "[9,   270] loss: 0.199\n",
      "[9,   271] loss: 0.155\n",
      "[9,   272] loss: 0.056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9,   273] loss: 0.060\n",
      "[9,   274] loss: 0.198\n",
      "[9,   275] loss: 0.076\n",
      "[9,   276] loss: 0.167\n",
      "[9,   277] loss: 0.086\n",
      "[9,   278] loss: 0.103\n",
      "[9,   279] loss: 0.149\n",
      "[9,   280] loss: 0.094\n",
      "[9,   281] loss: 0.162\n",
      "[9,   282] loss: 0.167\n",
      "[9,   283] loss: 0.181\n",
      "[9,   284] loss: 0.194\n",
      "[9,   285] loss: 0.151\n",
      "[9,   286] loss: 0.113\n",
      "[9,   287] loss: 0.099\n",
      "[9,   288] loss: 0.161\n",
      "[9,   289] loss: 0.058\n",
      "[9,   290] loss: 0.151\n",
      "[9,   291] loss: 0.168\n",
      "[9,   292] loss: 0.100\n",
      "[9,   293] loss: 0.111\n",
      "[9,   294] loss: 0.202\n",
      "[9,   295] loss: 0.200\n",
      "[9,   296] loss: 0.039\n",
      "[9,   297] loss: 0.255\n",
      "[9,   298] loss: 0.058\n",
      "[9,   299] loss: 0.171\n",
      "[9,   300] loss: 0.070\n",
      "[9,   301] loss: 0.185\n",
      "[9,   302] loss: 0.177\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "LOSS train 0.13353832068526192 valid 0.15221428117499902\n",
      "[10,     1] loss: 0.197\n",
      "[10,     2] loss: 0.150\n",
      "[10,     3] loss: 0.109\n",
      "[10,     4] loss: 0.149\n",
      "[10,     5] loss: 0.148\n",
      "[10,     6] loss: 0.145\n",
      "[10,     7] loss: 0.213\n",
      "[10,     8] loss: 0.173\n",
      "[10,     9] loss: 0.158\n",
      "[10,    10] loss: 0.133\n",
      "[10,    11] loss: 0.175\n",
      "[10,    12] loss: 0.186\n",
      "[10,    13] loss: 0.151\n",
      "[10,    14] loss: 0.090\n",
      "[10,    15] loss: 0.022\n",
      "[10,    16] loss: 0.114\n",
      "[10,    17] loss: 0.118\n",
      "[10,    18] loss: 0.153\n",
      "[10,    19] loss: 0.114\n",
      "[10,    20] loss: 0.186\n",
      "[10,    21] loss: 0.152\n",
      "[10,    22] loss: 0.020\n",
      "[10,    23] loss: 0.194\n",
      "[10,    24] loss: 0.128\n",
      "[10,    25] loss: 0.122\n",
      "[10,    26] loss: 0.083\n",
      "[10,    27] loss: 0.225\n",
      "[10,    28] loss: 0.210\n",
      "[10,    29] loss: 0.177\n",
      "[10,    30] loss: 0.100\n",
      "[10,    31] loss: 0.117\n",
      "[10,    32] loss: 0.068\n",
      "[10,    33] loss: 0.143\n",
      "[10,    34] loss: 0.128\n",
      "[10,    35] loss: 0.062\n",
      "[10,    36] loss: 0.059\n",
      "[10,    37] loss: 0.175\n",
      "[10,    38] loss: 0.144\n",
      "[10,    39] loss: 0.182\n",
      "[10,    40] loss: 0.156\n",
      "[10,    41] loss: 0.078\n",
      "[10,    42] loss: 0.156\n",
      "[10,    43] loss: 0.096\n",
      "[10,    44] loss: 0.199\n",
      "[10,    45] loss: 0.041\n",
      "[10,    46] loss: 0.160\n",
      "[10,    47] loss: 0.135\n",
      "[10,    48] loss: 0.077\n",
      "[10,    49] loss: 0.107\n",
      "[10,    50] loss: 0.143\n",
      "[10,    51] loss: 0.098\n",
      "[10,    52] loss: 0.071\n",
      "[10,    53] loss: 0.116\n",
      "[10,    54] loss: 0.082\n",
      "[10,    55] loss: 0.072\n",
      "[10,    56] loss: 0.118\n",
      "[10,    57] loss: 0.142\n",
      "[10,    58] loss: 0.119\n",
      "[10,    59] loss: 0.140\n",
      "[10,    60] loss: 0.106\n",
      "[10,    61] loss: 0.188\n",
      "[10,    62] loss: 0.069\n",
      "[10,    63] loss: 0.103\n",
      "[10,    64] loss: 0.155\n",
      "[10,    65] loss: 0.066\n",
      "[10,    66] loss: 0.132\n",
      "[10,    67] loss: 0.133\n",
      "[10,    68] loss: 0.157\n",
      "[10,    69] loss: 0.174\n",
      "[10,    70] loss: 0.150\n",
      "[10,    71] loss: 0.190\n",
      "[10,    72] loss: 0.081\n",
      "[10,    73] loss: 0.160\n",
      "[10,    74] loss: 0.111\n",
      "[10,    75] loss: 0.032\n",
      "[10,    76] loss: 0.152\n",
      "[10,    77] loss: 0.230\n",
      "[10,    78] loss: 0.160\n",
      "[10,    79] loss: 0.187\n",
      "[10,    80] loss: 0.112\n",
      "[10,    81] loss: 0.124\n",
      "[10,    82] loss: 0.123\n",
      "[10,    83] loss: 0.152\n",
      "[10,    84] loss: 0.075\n",
      "[10,    85] loss: 0.128\n",
      "[10,    86] loss: 0.100\n",
      "[10,    87] loss: 0.135\n",
      "[10,    88] loss: 0.092\n",
      "[10,    89] loss: 0.118\n",
      "[10,    90] loss: 0.131\n",
      "[10,    91] loss: 0.033\n",
      "[10,    92] loss: 0.132\n",
      "[10,    93] loss: 0.113\n",
      "[10,    94] loss: 0.113\n",
      "[10,    95] loss: 0.137\n",
      "[10,    96] loss: 0.186\n",
      "[10,    97] loss: 0.120\n",
      "[10,    98] loss: 0.078\n",
      "[10,    99] loss: 0.141\n",
      "[10,   100] loss: 0.062\n",
      "[10,   101] loss: 0.151\n",
      "[10,   102] loss: 0.144\n",
      "[10,   103] loss: 0.178\n",
      "[10,   104] loss: 0.216\n",
      "[10,   105] loss: 0.214\n",
      "[10,   106] loss: 0.072\n",
      "[10,   107] loss: 0.078\n",
      "[10,   108] loss: 0.214\n",
      "[10,   109] loss: 0.072\n",
      "[10,   110] loss: 0.031\n",
      "[10,   111] loss: 0.075\n",
      "[10,   112] loss: 0.167\n",
      "[10,   113] loss: 0.137\n",
      "[10,   114] loss: 0.080\n",
      "[10,   115] loss: 0.152\n",
      "[10,   116] loss: 0.117\n",
      "[10,   117] loss: 0.168\n",
      "[10,   118] loss: 0.126\n",
      "[10,   119] loss: 0.155\n",
      "[10,   120] loss: 0.206\n",
      "[10,   121] loss: 0.131\n",
      "[10,   122] loss: 0.069\n",
      "[10,   123] loss: 0.172\n",
      "[10,   124] loss: 0.097\n",
      "[10,   125] loss: 0.091\n",
      "[10,   126] loss: 0.122\n",
      "[10,   127] loss: 0.103\n",
      "[10,   128] loss: 0.061\n",
      "[10,   129] loss: 0.034\n",
      "[10,   130] loss: 0.124\n",
      "[10,   131] loss: 0.103\n",
      "[10,   132] loss: 0.058\n",
      "[10,   133] loss: 0.225\n",
      "[10,   134] loss: 0.128\n",
      "[10,   135] loss: 0.096\n",
      "[10,   136] loss: 0.130\n",
      "[10,   137] loss: 0.049\n",
      "[10,   138] loss: 0.122\n",
      "[10,   139] loss: 0.159\n",
      "[10,   140] loss: 0.139\n",
      "[10,   141] loss: 0.105\n",
      "[10,   142] loss: 0.108\n",
      "[10,   143] loss: 0.147\n",
      "[10,   144] loss: 0.145\n",
      "[10,   145] loss: 0.202\n",
      "[10,   146] loss: 0.120\n",
      "[10,   147] loss: 0.138\n",
      "[10,   148] loss: 0.164\n",
      "[10,   149] loss: 0.116\n",
      "[10,   150] loss: 0.098\n",
      "[10,   151] loss: 0.078\n",
      "[10,   152] loss: 0.194\n",
      "[10,   153] loss: 0.089\n",
      "[10,   154] loss: 0.111\n",
      "[10,   155] loss: 0.225\n",
      "[10,   156] loss: 0.205\n",
      "[10,   157] loss: 0.121\n",
      "[10,   158] loss: 0.179\n",
      "[10,   159] loss: 0.096\n",
      "[10,   160] loss: 0.031\n",
      "[10,   161] loss: 0.148\n",
      "[10,   162] loss: 0.037\n",
      "[10,   163] loss: 0.116\n",
      "[10,   164] loss: 0.063\n",
      "[10,   165] loss: 0.050\n",
      "[10,   166] loss: 0.082\n",
      "[10,   167] loss: 0.226\n",
      "[10,   168] loss: 0.113\n",
      "[10,   169] loss: 0.084\n",
      "[10,   170] loss: 0.059\n",
      "[10,   171] loss: 0.206\n",
      "[10,   172] loss: 0.100\n",
      "[10,   173] loss: 0.086\n",
      "[10,   174] loss: 0.073\n",
      "[10,   175] loss: 0.187\n",
      "[10,   176] loss: 0.143\n",
      "[10,   177] loss: 0.100\n",
      "[10,   178] loss: 0.164\n",
      "[10,   179] loss: 0.187\n",
      "[10,   180] loss: 0.263\n",
      "[10,   181] loss: 0.121\n",
      "[10,   182] loss: 0.233\n",
      "[10,   183] loss: 0.164\n",
      "[10,   184] loss: 0.152\n",
      "[10,   185] loss: 0.069\n",
      "[10,   186] loss: 0.118\n",
      "[10,   187] loss: 0.204\n",
      "[10,   188] loss: 0.147\n",
      "[10,   189] loss: 0.100\n",
      "[10,   190] loss: 0.141\n",
      "[10,   191] loss: 0.173\n",
      "[10,   192] loss: 0.180\n",
      "[10,   193] loss: 0.122\n",
      "[10,   194] loss: 0.121\n",
      "[10,   195] loss: 0.212\n",
      "[10,   196] loss: 0.107\n",
      "[10,   197] loss: 0.163\n",
      "[10,   198] loss: 0.106\n",
      "[10,   199] loss: 0.139\n",
      "[10,   200] loss: 0.147\n",
      "[10,   201] loss: 0.198\n",
      "[10,   202] loss: 0.155\n",
      "[10,   203] loss: 0.087\n",
      "[10,   204] loss: 0.154\n",
      "[10,   205] loss: 0.161\n",
      "[10,   206] loss: 0.166\n",
      "[10,   207] loss: 0.129\n",
      "[10,   208] loss: 0.240\n",
      "[10,   209] loss: 0.103\n",
      "[10,   210] loss: 0.143\n",
      "[10,   211] loss: 0.150\n",
      "[10,   212] loss: 0.182\n",
      "[10,   213] loss: 0.148\n",
      "[10,   214] loss: 0.162\n",
      "[10,   215] loss: 0.160\n",
      "[10,   216] loss: 0.130\n",
      "[10,   217] loss: 0.081\n",
      "[10,   218] loss: 0.135\n",
      "[10,   219] loss: 0.135\n",
      "[10,   220] loss: 0.174\n",
      "[10,   221] loss: 0.098\n",
      "[10,   222] loss: 0.065\n",
      "[10,   223] loss: 0.178\n",
      "[10,   224] loss: 0.112\n",
      "[10,   225] loss: 0.094\n",
      "[10,   226] loss: 0.183\n",
      "[10,   227] loss: 0.088\n",
      "[10,   228] loss: 0.112\n",
      "[10,   229] loss: 0.192\n",
      "[10,   230] loss: 0.159\n",
      "[10,   231] loss: 0.063\n",
      "[10,   232] loss: 0.170\n",
      "[10,   233] loss: 0.174\n",
      "[10,   234] loss: 0.181\n",
      "[10,   235] loss: 0.174\n",
      "[10,   236] loss: 0.189\n",
      "[10,   237] loss: 0.162\n",
      "[10,   238] loss: 0.077\n",
      "[10,   239] loss: 0.100\n",
      "[10,   240] loss: 0.173\n",
      "[10,   241] loss: 0.184\n",
      "[10,   242] loss: 0.103\n",
      "[10,   243] loss: 0.097\n",
      "[10,   244] loss: 0.107\n",
      "[10,   245] loss: 0.131\n",
      "[10,   246] loss: 0.132\n",
      "[10,   247] loss: 0.152\n",
      "[10,   248] loss: 0.167\n",
      "[10,   249] loss: 0.138\n",
      "[10,   250] loss: 0.135\n",
      "[10,   251] loss: 0.127\n",
      "[10,   252] loss: 0.065\n",
      "[10,   253] loss: 0.124\n",
      "[10,   254] loss: 0.130\n",
      "[10,   255] loss: 0.149\n",
      "[10,   256] loss: 0.093\n",
      "[10,   257] loss: 0.190\n",
      "[10,   258] loss: 0.185\n",
      "[10,   259] loss: 0.088\n",
      "[10,   260] loss: 0.145\n",
      "[10,   261] loss: 0.173\n",
      "[10,   262] loss: 0.196\n",
      "[10,   263] loss: 0.045\n",
      "[10,   264] loss: 0.184\n",
      "[10,   265] loss: 0.138\n",
      "[10,   266] loss: 0.189\n",
      "[10,   267] loss: 0.124\n",
      "[10,   268] loss: 0.215\n",
      "[10,   269] loss: 0.160\n",
      "[10,   270] loss: 0.198\n",
      "[10,   271] loss: 0.155\n",
      "[10,   272] loss: 0.056\n",
      "[10,   273] loss: 0.058\n",
      "[10,   274] loss: 0.195\n",
      "[10,   275] loss: 0.074\n",
      "[10,   276] loss: 0.173\n",
      "[10,   277] loss: 0.086\n",
      "[10,   278] loss: 0.102\n",
      "[10,   279] loss: 0.149\n",
      "[10,   280] loss: 0.093\n",
      "[10,   281] loss: 0.160\n",
      "[10,   282] loss: 0.166\n",
      "[10,   283] loss: 0.179\n",
      "[10,   284] loss: 0.193\n",
      "[10,   285] loss: 0.153\n",
      "[10,   286] loss: 0.112\n",
      "[10,   287] loss: 0.092\n",
      "[10,   288] loss: 0.162\n",
      "[10,   289] loss: 0.058\n",
      "[10,   290] loss: 0.150\n",
      "[10,   291] loss: 0.165\n",
      "[10,   292] loss: 0.097\n",
      "[10,   293] loss: 0.110\n",
      "[10,   294] loss: 0.199\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10,   295] loss: 0.198\n",
      "[10,   296] loss: 0.040\n",
      "[10,   297] loss: 0.251\n",
      "[10,   298] loss: 0.065\n",
      "[10,   299] loss: 0.171\n",
      "[10,   300] loss: 0.069\n",
      "[10,   301] loss: 0.184\n",
      "[10,   302] loss: 0.169\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "LOSS train 0.13293054176260108 valid 0.16245730883226944\n",
      "[11,     1] loss: 0.197\n",
      "[11,     2] loss: 0.152\n",
      "[11,     3] loss: 0.109\n",
      "[11,     4] loss: 0.149\n",
      "[11,     5] loss: 0.148\n",
      "[11,     6] loss: 0.142\n",
      "[11,     7] loss: 0.211\n",
      "[11,     8] loss: 0.170\n",
      "[11,     9] loss: 0.159\n",
      "[11,    10] loss: 0.133\n",
      "[11,    11] loss: 0.174\n",
      "[11,    12] loss: 0.185\n",
      "[11,    13] loss: 0.150\n",
      "[11,    14] loss: 0.090\n",
      "[11,    15] loss: 0.023\n",
      "[11,    16] loss: 0.113\n",
      "[11,    17] loss: 0.116\n",
      "[11,    18] loss: 0.153\n",
      "[11,    19] loss: 0.114\n",
      "[11,    20] loss: 0.187\n",
      "[11,    21] loss: 0.151\n",
      "[11,    22] loss: 0.017\n",
      "[11,    23] loss: 0.194\n",
      "[11,    24] loss: 0.127\n",
      "[11,    25] loss: 0.119\n",
      "[11,    26] loss: 0.079\n",
      "[11,    27] loss: 0.222\n",
      "[11,    28] loss: 0.206\n",
      "[11,    29] loss: 0.170\n",
      "[11,    30] loss: 0.098\n",
      "[11,    31] loss: 0.117\n",
      "[11,    32] loss: 0.065\n",
      "[11,    33] loss: 0.144\n",
      "[11,    34] loss: 0.124\n",
      "[11,    35] loss: 0.064\n",
      "[11,    36] loss: 0.058\n",
      "[11,    37] loss: 0.173\n",
      "[11,    38] loss: 0.146\n",
      "[11,    39] loss: 0.180\n",
      "[11,    40] loss: 0.155\n",
      "[11,    41] loss: 0.077\n",
      "[11,    42] loss: 0.153\n",
      "[11,    43] loss: 0.093\n",
      "[11,    44] loss: 0.196\n",
      "[11,    45] loss: 0.041\n",
      "[11,    46] loss: 0.157\n",
      "[11,    47] loss: 0.134\n",
      "[11,    48] loss: 0.071\n",
      "[11,    49] loss: 0.106\n",
      "[11,    50] loss: 0.142\n",
      "[11,    51] loss: 0.099\n",
      "[11,    52] loss: 0.071\n",
      "[11,    53] loss: 0.113\n",
      "[11,    54] loss: 0.074\n",
      "[11,    55] loss: 0.071\n",
      "[11,    56] loss: 0.117\n",
      "[11,    57] loss: 0.140\n",
      "[11,    58] loss: 0.118\n",
      "[11,    59] loss: 0.138\n",
      "[11,    60] loss: 0.103\n",
      "[11,    61] loss: 0.187\n",
      "[11,    62] loss: 0.062\n",
      "[11,    63] loss: 0.107\n",
      "[11,    64] loss: 0.154\n",
      "[11,    65] loss: 0.064\n",
      "[11,    66] loss: 0.125\n",
      "[11,    67] loss: 0.127\n",
      "[11,    68] loss: 0.154\n",
      "[11,    69] loss: 0.172\n",
      "[11,    70] loss: 0.147\n",
      "[11,    71] loss: 0.190\n",
      "[11,    72] loss: 0.082\n",
      "[11,    73] loss: 0.158\n",
      "[11,    74] loss: 0.109\n",
      "[11,    75] loss: 0.032\n",
      "[11,    76] loss: 0.155\n",
      "[11,    77] loss: 0.227\n",
      "[11,    78] loss: 0.157\n",
      "[11,    79] loss: 0.182\n",
      "[11,    80] loss: 0.113\n",
      "[11,    81] loss: 0.127\n",
      "[11,    82] loss: 0.122\n",
      "[11,    83] loss: 0.152\n",
      "[11,    84] loss: 0.067\n",
      "[11,    85] loss: 0.132\n",
      "[11,    86] loss: 0.102\n",
      "[11,    87] loss: 0.118\n",
      "[11,    88] loss: 0.091\n",
      "[11,    89] loss: 0.117\n",
      "[11,    90] loss: 0.131\n",
      "[11,    91] loss: 0.040\n",
      "[11,    92] loss: 0.131\n",
      "[11,    93] loss: 0.112\n",
      "[11,    94] loss: 0.112\n",
      "[11,    95] loss: 0.137\n",
      "[11,    96] loss: 0.184\n",
      "[11,    97] loss: 0.119\n",
      "[11,    98] loss: 0.082\n",
      "[11,    99] loss: 0.140\n",
      "[11,   100] loss: 0.061\n",
      "[11,   101] loss: 0.149\n",
      "[11,   102] loss: 0.151\n",
      "[11,   103] loss: 0.178\n",
      "[11,   104] loss: 0.217\n",
      "[11,   105] loss: 0.212\n",
      "[11,   106] loss: 0.069\n",
      "[11,   107] loss: 0.074\n",
      "[11,   108] loss: 0.216\n",
      "[11,   109] loss: 0.075\n",
      "[11,   110] loss: 0.031\n",
      "[11,   111] loss: 0.074\n",
      "[11,   112] loss: 0.169\n",
      "[11,   113] loss: 0.137\n",
      "[11,   114] loss: 0.081\n",
      "[11,   115] loss: 0.153\n",
      "[11,   116] loss: 0.128\n",
      "[11,   117] loss: 0.167\n",
      "[11,   118] loss: 0.128\n",
      "[11,   119] loss: 0.155\n",
      "[11,   120] loss: 0.205\n",
      "[11,   121] loss: 0.131\n",
      "[11,   122] loss: 0.068\n",
      "[11,   123] loss: 0.171\n",
      "[11,   124] loss: 0.098\n",
      "[11,   125] loss: 0.091\n",
      "[11,   126] loss: 0.120\n",
      "[11,   127] loss: 0.103\n",
      "[11,   128] loss: 0.062\n",
      "[11,   129] loss: 0.035\n",
      "[11,   130] loss: 0.124\n",
      "[11,   131] loss: 0.106\n",
      "[11,   132] loss: 0.058\n",
      "[11,   133] loss: 0.222\n",
      "[11,   134] loss: 0.127\n",
      "[11,   135] loss: 0.095\n",
      "[11,   136] loss: 0.126\n",
      "[11,   137] loss: 0.046\n",
      "[11,   138] loss: 0.121\n",
      "[11,   139] loss: 0.158\n",
      "[11,   140] loss: 0.140\n",
      "[11,   141] loss: 0.105\n",
      "[11,   142] loss: 0.109\n",
      "[11,   143] loss: 0.143\n",
      "[11,   144] loss: 0.141\n",
      "[11,   145] loss: 0.200\n",
      "[11,   146] loss: 0.123\n",
      "[11,   147] loss: 0.138\n",
      "[11,   148] loss: 0.165\n",
      "[11,   149] loss: 0.110\n",
      "[11,   150] loss: 0.094\n",
      "[11,   151] loss: 0.080\n",
      "[11,   152] loss: 0.197\n",
      "[11,   153] loss: 0.088\n",
      "[11,   154] loss: 0.110\n",
      "[11,   155] loss: 0.223\n",
      "[11,   156] loss: 0.202\n",
      "[11,   157] loss: 0.120\n",
      "[11,   158] loss: 0.178\n",
      "[11,   159] loss: 0.098\n",
      "[11,   160] loss: 0.033\n",
      "[11,   161] loss: 0.153\n",
      "[11,   162] loss: 0.036\n",
      "[11,   163] loss: 0.123\n",
      "[11,   164] loss: 0.061\n",
      "[11,   165] loss: 0.050\n",
      "[11,   166] loss: 0.082\n",
      "[11,   167] loss: 0.218\n",
      "[11,   168] loss: 0.109\n",
      "[11,   169] loss: 0.093\n",
      "[11,   170] loss: 0.058\n",
      "[11,   171] loss: 0.203\n",
      "[11,   172] loss: 0.099\n",
      "[11,   173] loss: 0.080\n",
      "[11,   174] loss: 0.071\n",
      "[11,   175] loss: 0.190\n",
      "[11,   176] loss: 0.144\n",
      "[11,   177] loss: 0.099\n",
      "[11,   178] loss: 0.163\n",
      "[11,   179] loss: 0.185\n",
      "[11,   180] loss: 0.260\n",
      "[11,   181] loss: 0.121\n",
      "[11,   182] loss: 0.231\n",
      "[11,   183] loss: 0.162\n",
      "[11,   184] loss: 0.152\n",
      "[11,   185] loss: 0.066\n",
      "[11,   186] loss: 0.119\n",
      "[11,   187] loss: 0.195\n",
      "[11,   188] loss: 0.145\n",
      "[11,   189] loss: 0.100\n",
      "[11,   190] loss: 0.136\n",
      "[11,   191] loss: 0.162\n",
      "[11,   192] loss: 0.179\n",
      "[11,   193] loss: 0.127\n",
      "[11,   194] loss: 0.117\n",
      "[11,   195] loss: 0.212\n",
      "[11,   196] loss: 0.104\n",
      "[11,   197] loss: 0.157\n",
      "[11,   198] loss: 0.104\n",
      "[11,   199] loss: 0.138\n",
      "[11,   200] loss: 0.146\n",
      "[11,   201] loss: 0.195\n",
      "[11,   202] loss: 0.157\n",
      "[11,   203] loss: 0.082\n",
      "[11,   204] loss: 0.152\n",
      "[11,   205] loss: 0.160\n",
      "[11,   206] loss: 0.167\n",
      "[11,   207] loss: 0.128\n",
      "[11,   208] loss: 0.237\n",
      "[11,   209] loss: 0.106\n",
      "[11,   210] loss: 0.145\n",
      "[11,   211] loss: 0.148\n",
      "[11,   212] loss: 0.182\n",
      "[11,   213] loss: 0.149\n",
      "[11,   214] loss: 0.163\n",
      "[11,   215] loss: 0.159\n",
      "[11,   216] loss: 0.129\n",
      "[11,   217] loss: 0.080\n",
      "[11,   218] loss: 0.134\n",
      "[11,   219] loss: 0.132\n",
      "[11,   220] loss: 0.174\n",
      "[11,   221] loss: 0.096\n",
      "[11,   222] loss: 0.066\n",
      "[11,   223] loss: 0.178\n",
      "[11,   224] loss: 0.111\n",
      "[11,   225] loss: 0.094\n",
      "[11,   226] loss: 0.182\n",
      "[11,   227] loss: 0.087\n",
      "[11,   228] loss: 0.112\n",
      "[11,   229] loss: 0.191\n",
      "[11,   230] loss: 0.159\n",
      "[11,   231] loss: 0.064\n",
      "[11,   232] loss: 0.169\n",
      "[11,   233] loss: 0.172\n",
      "[11,   234] loss: 0.180\n",
      "[11,   235] loss: 0.172\n",
      "[11,   236] loss: 0.187\n",
      "[11,   237] loss: 0.162\n",
      "[11,   238] loss: 0.074\n",
      "[11,   239] loss: 0.099\n",
      "[11,   240] loss: 0.169\n",
      "[11,   241] loss: 0.184\n",
      "[11,   242] loss: 0.103\n",
      "[11,   243] loss: 0.096\n",
      "[11,   244] loss: 0.107\n",
      "[11,   245] loss: 0.130\n",
      "[11,   246] loss: 0.131\n",
      "[11,   247] loss: 0.152\n",
      "[11,   248] loss: 0.167\n",
      "[11,   249] loss: 0.137\n",
      "[11,   250] loss: 0.131\n",
      "[11,   251] loss: 0.124\n",
      "[11,   252] loss: 0.066\n",
      "[11,   253] loss: 0.124\n",
      "[11,   254] loss: 0.125\n",
      "[11,   255] loss: 0.147\n",
      "[11,   256] loss: 0.092\n",
      "[11,   257] loss: 0.183\n",
      "[11,   258] loss: 0.185\n",
      "[11,   259] loss: 0.087\n",
      "[11,   260] loss: 0.143\n",
      "[11,   261] loss: 0.173\n",
      "[11,   262] loss: 0.195\n",
      "[11,   263] loss: 0.040\n",
      "[11,   264] loss: 0.183\n",
      "[11,   265] loss: 0.137\n",
      "[11,   266] loss: 0.187\n",
      "[11,   267] loss: 0.123\n",
      "[11,   268] loss: 0.214\n",
      "[11,   269] loss: 0.159\n",
      "[11,   270] loss: 0.196\n",
      "[11,   271] loss: 0.154\n",
      "[11,   272] loss: 0.055\n",
      "[11,   273] loss: 0.058\n",
      "[11,   274] loss: 0.194\n",
      "[11,   275] loss: 0.076\n",
      "[11,   276] loss: 0.160\n",
      "[11,   277] loss: 0.084\n",
      "[11,   278] loss: 0.102\n",
      "[11,   279] loss: 0.150\n",
      "[11,   280] loss: 0.093\n",
      "[11,   281] loss: 0.159\n",
      "[11,   282] loss: 0.165\n",
      "[11,   283] loss: 0.179\n",
      "[11,   284] loss: 0.191\n",
      "[11,   285] loss: 0.151\n",
      "[11,   286] loss: 0.113\n",
      "[11,   287] loss: 0.094\n",
      "[11,   288] loss: 0.161\n",
      "[11,   289] loss: 0.057\n",
      "[11,   290] loss: 0.151\n",
      "[11,   291] loss: 0.166\n",
      "[11,   292] loss: 0.097\n",
      "[11,   293] loss: 0.109\n",
      "[11,   294] loss: 0.198\n",
      "[11,   295] loss: 0.196\n",
      "[11,   296] loss: 0.040\n",
      "[11,   297] loss: 0.250\n",
      "[11,   298] loss: 0.058\n",
      "[11,   299] loss: 0.169\n",
      "[11,   300] loss: 0.065\n",
      "[11,   301] loss: 0.185\n",
      "[11,   302] loss: 0.169\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "LOSS train 0.13189357661006862 valid 0.14552280864176842\n",
      "[12,     1] loss: 0.194\n",
      "[12,     2] loss: 0.149\n",
      "[12,     3] loss: 0.108\n",
      "[12,     4] loss: 0.144\n",
      "[12,     5] loss: 0.144\n",
      "[12,     6] loss: 0.143\n",
      "[12,     7] loss: 0.215\n",
      "[12,     8] loss: 0.177\n",
      "[12,     9] loss: 0.152\n",
      "[12,    10] loss: 0.124\n",
      "[12,    11] loss: 0.174\n",
      "[12,    12] loss: 0.187\n",
      "[12,    13] loss: 0.158\n",
      "[12,    14] loss: 0.089\n",
      "[12,    15] loss: 0.026\n",
      "[12,    16] loss: 0.112\n",
      "[12,    17] loss: 0.117\n",
      "[12,    18] loss: 0.156\n",
      "[12,    19] loss: 0.116\n",
      "[12,    20] loss: 0.185\n",
      "[12,    21] loss: 0.151\n",
      "[12,    22] loss: 0.015\n",
      "[12,    23] loss: 0.194\n",
      "[12,    24] loss: 0.125\n",
      "[12,    25] loss: 0.120\n",
      "[12,    26] loss: 0.078\n",
      "[12,    27] loss: 0.221\n",
      "[12,    28] loss: 0.204\n",
      "[12,    29] loss: 0.170\n",
      "[12,    30] loss: 0.098\n",
      "[12,    31] loss: 0.115\n",
      "[12,    32] loss: 0.065\n",
      "[12,    33] loss: 0.142\n",
      "[12,    34] loss: 0.123\n",
      "[12,    35] loss: 0.060\n",
      "[12,    36] loss: 0.058\n",
      "[12,    37] loss: 0.176\n",
      "[12,    38] loss: 0.138\n",
      "[12,    39] loss: 0.180\n",
      "[12,    40] loss: 0.155\n",
      "[12,    41] loss: 0.079\n",
      "[12,    42] loss: 0.151\n",
      "[12,    43] loss: 0.092\n",
      "[12,    44] loss: 0.196\n",
      "[12,    45] loss: 0.040\n",
      "[12,    46] loss: 0.157\n",
      "[12,    47] loss: 0.133\n",
      "[12,    48] loss: 0.070\n",
      "[12,    49] loss: 0.107\n",
      "[12,    50] loss: 0.142\n",
      "[12,    51] loss: 0.100\n",
      "[12,    52] loss: 0.069\n",
      "[12,    53] loss: 0.113\n",
      "[12,    54] loss: 0.074\n",
      "[12,    55] loss: 0.073\n",
      "[12,    56] loss: 0.117\n",
      "[12,    57] loss: 0.139\n",
      "[12,    58] loss: 0.118\n",
      "[12,    59] loss: 0.137\n",
      "[12,    60] loss: 0.103\n",
      "[12,    61] loss: 0.185\n",
      "[12,    62] loss: 0.061\n",
      "[12,    63] loss: 0.105\n",
      "[12,    64] loss: 0.154\n",
      "[12,    65] loss: 0.064\n",
      "[12,    66] loss: 0.126\n",
      "[12,    67] loss: 0.126\n",
      "[12,    68] loss: 0.153\n",
      "[12,    69] loss: 0.172\n",
      "[12,    70] loss: 0.146\n",
      "[12,    71] loss: 0.188\n",
      "[12,    72] loss: 0.077\n",
      "[12,    73] loss: 0.157\n",
      "[12,    74] loss: 0.108\n",
      "[12,    75] loss: 0.032\n",
      "[12,    76] loss: 0.151\n",
      "[12,    77] loss: 0.224\n",
      "[12,    78] loss: 0.155\n",
      "[12,    79] loss: 0.181\n",
      "[12,    80] loss: 0.112\n",
      "[12,    81] loss: 0.124\n",
      "[12,    82] loss: 0.121\n",
      "[12,    83] loss: 0.151\n",
      "[12,    84] loss: 0.066\n",
      "[12,    85] loss: 0.130\n",
      "[12,    86] loss: 0.102\n",
      "[12,    87] loss: 0.117\n",
      "[12,    88] loss: 0.090\n",
      "[12,    89] loss: 0.116\n",
      "[12,    90] loss: 0.130\n",
      "[12,    91] loss: 0.034\n",
      "[12,    92] loss: 0.131\n",
      "[12,    93] loss: 0.112\n",
      "[12,    94] loss: 0.112\n",
      "[12,    95] loss: 0.137\n",
      "[12,    96] loss: 0.182\n",
      "[12,    97] loss: 0.118\n",
      "[12,    98] loss: 0.080\n",
      "[12,    99] loss: 0.138\n",
      "[12,   100] loss: 0.061\n",
      "[12,   101] loss: 0.149\n",
      "[12,   102] loss: 0.148\n",
      "[12,   103] loss: 0.177\n",
      "[12,   104] loss: 0.215\n",
      "[12,   105] loss: 0.209\n",
      "[12,   106] loss: 0.069\n",
      "[12,   107] loss: 0.074\n",
      "[12,   108] loss: 0.215\n",
      "[12,   109] loss: 0.072\n",
      "[12,   110] loss: 0.030\n",
      "[12,   111] loss: 0.073\n",
      "[12,   112] loss: 0.167\n",
      "[12,   113] loss: 0.136\n",
      "[12,   114] loss: 0.079\n",
      "[12,   115] loss: 0.152\n",
      "[12,   116] loss: 0.124\n",
      "[12,   117] loss: 0.168\n",
      "[12,   118] loss: 0.130\n",
      "[12,   119] loss: 0.155\n",
      "[12,   120] loss: 0.203\n",
      "[12,   121] loss: 0.130\n",
      "[12,   122] loss: 0.066\n",
      "[12,   123] loss: 0.172\n",
      "[12,   124] loss: 0.096\n",
      "[12,   125] loss: 0.090\n",
      "[12,   126] loss: 0.124\n",
      "[12,   127] loss: 0.103\n",
      "[12,   128] loss: 0.060\n",
      "[12,   129] loss: 0.035\n",
      "[12,   130] loss: 0.122\n",
      "[12,   131] loss: 0.099\n",
      "[12,   132] loss: 0.060\n",
      "[12,   133] loss: 0.216\n",
      "[12,   134] loss: 0.128\n",
      "[12,   135] loss: 0.095\n",
      "[12,   136] loss: 0.127\n",
      "[12,   137] loss: 0.048\n",
      "[12,   138] loss: 0.116\n",
      "[12,   139] loss: 0.156\n",
      "[12,   140] loss: 0.136\n",
      "[12,   141] loss: 0.103\n",
      "[12,   142] loss: 0.108\n",
      "[12,   143] loss: 0.144\n",
      "[12,   144] loss: 0.142\n",
      "[12,   145] loss: 0.191\n",
      "[12,   146] loss: 0.117\n",
      "[12,   147] loss: 0.136\n",
      "[12,   148] loss: 0.163\n",
      "[12,   149] loss: 0.110\n",
      "[12,   150] loss: 0.094\n",
      "[12,   151] loss: 0.075\n",
      "[12,   152] loss: 0.191\n",
      "[12,   153] loss: 0.086\n",
      "[12,   154] loss: 0.110\n",
      "[12,   155] loss: 0.220\n",
      "[12,   156] loss: 0.201\n",
      "[12,   157] loss: 0.124\n",
      "[12,   158] loss: 0.177\n",
      "[12,   159] loss: 0.096\n",
      "[12,   160] loss: 0.030\n",
      "[12,   161] loss: 0.153\n",
      "[12,   162] loss: 0.035\n",
      "[12,   163] loss: 0.127\n",
      "[12,   164] loss: 0.064\n",
      "[12,   165] loss: 0.050\n",
      "[12,   166] loss: 0.081\n",
      "[12,   167] loss: 0.214\n",
      "[12,   168] loss: 0.109\n",
      "[12,   169] loss: 0.090\n",
      "[12,   170] loss: 0.060\n",
      "[12,   171] loss: 0.202\n",
      "[12,   172] loss: 0.103\n",
      "[12,   173] loss: 0.077\n",
      "[12,   174] loss: 0.070\n",
      "[12,   175] loss: 0.188\n",
      "[12,   176] loss: 0.143\n",
      "[12,   177] loss: 0.108\n",
      "[12,   178] loss: 0.164\n",
      "[12,   179] loss: 0.185\n",
      "[12,   180] loss: 0.257\n",
      "[12,   181] loss: 0.125\n",
      "[12,   182] loss: 0.228\n",
      "[12,   183] loss: 0.163\n",
      "[12,   184] loss: 0.155\n",
      "[12,   185] loss: 0.070\n",
      "[12,   186] loss: 0.116\n",
      "[12,   187] loss: 0.193\n",
      "[12,   188] loss: 0.142\n",
      "[12,   189] loss: 0.102\n",
      "[12,   190] loss: 0.136\n",
      "[12,   191] loss: 0.160\n",
      "[12,   192] loss: 0.174\n",
      "[12,   193] loss: 0.123\n",
      "[12,   194] loss: 0.127\n",
      "[12,   195] loss: 0.212\n",
      "[12,   196] loss: 0.110\n",
      "[12,   197] loss: 0.153\n",
      "[12,   198] loss: 0.105\n",
      "[12,   199] loss: 0.138\n",
      "[12,   200] loss: 0.151\n",
      "[12,   201] loss: 0.194\n",
      "[12,   202] loss: 0.164\n",
      "[12,   203] loss: 0.093\n",
      "[12,   204] loss: 0.153\n",
      "[12,   205] loss: 0.156\n",
      "[12,   206] loss: 0.165\n",
      "[12,   207] loss: 0.130\n",
      "[12,   208] loss: 0.238\n",
      "[12,   209] loss: 0.104\n",
      "[12,   210] loss: 0.154\n",
      "[12,   211] loss: 0.150\n",
      "[12,   212] loss: 0.181\n",
      "[12,   213] loss: 0.149\n",
      "[12,   214] loss: 0.161\n",
      "[12,   215] loss: 0.158\n",
      "[12,   216] loss: 0.131\n",
      "[12,   217] loss: 0.083\n",
      "[12,   218] loss: 0.133\n",
      "[12,   219] loss: 0.133\n",
      "[12,   220] loss: 0.174\n",
      "[12,   221] loss: 0.096\n",
      "[12,   222] loss: 0.066\n",
      "[12,   223] loss: 0.184\n",
      "[12,   224] loss: 0.113\n",
      "[12,   225] loss: 0.092\n",
      "[12,   226] loss: 0.184\n",
      "[12,   227] loss: 0.094\n",
      "[12,   228] loss: 0.112\n",
      "[12,   229] loss: 0.190\n",
      "[12,   230] loss: 0.157\n",
      "[12,   231] loss: 0.062\n",
      "[12,   232] loss: 0.168\n",
      "[12,   233] loss: 0.172\n",
      "[12,   234] loss: 0.181\n",
      "[12,   235] loss: 0.172\n",
      "[12,   236] loss: 0.188\n",
      "[12,   237] loss: 0.162\n",
      "[12,   238] loss: 0.076\n",
      "[12,   239] loss: 0.100\n",
      "[12,   240] loss: 0.175\n",
      "[12,   241] loss: 0.185\n",
      "[12,   242] loss: 0.103\n",
      "[12,   243] loss: 0.097\n",
      "[12,   244] loss: 0.106\n",
      "[12,   245] loss: 0.129\n",
      "[12,   246] loss: 0.130\n",
      "[12,   247] loss: 0.151\n",
      "[12,   248] loss: 0.168\n",
      "[12,   249] loss: 0.136\n",
      "[12,   250] loss: 0.132\n",
      "[12,   251] loss: 0.124\n",
      "[12,   252] loss: 0.066\n",
      "[12,   253] loss: 0.123\n",
      "[12,   254] loss: 0.128\n",
      "[12,   255] loss: 0.147\n",
      "[12,   256] loss: 0.092\n",
      "[12,   257] loss: 0.182\n",
      "[12,   258] loss: 0.184\n",
      "[12,   259] loss: 0.086\n",
      "[12,   260] loss: 0.144\n",
      "[12,   261] loss: 0.173\n",
      "[12,   262] loss: 0.194\n",
      "[12,   263] loss: 0.046\n",
      "[12,   264] loss: 0.182\n",
      "[12,   265] loss: 0.137\n",
      "[12,   266] loss: 0.186\n",
      "[12,   267] loss: 0.123\n",
      "[12,   268] loss: 0.212\n",
      "[12,   269] loss: 0.159\n",
      "[12,   270] loss: 0.195\n",
      "[12,   271] loss: 0.154\n",
      "[12,   272] loss: 0.057\n",
      "[12,   273] loss: 0.057\n",
      "[12,   274] loss: 0.193\n",
      "[12,   275] loss: 0.073\n",
      "[12,   276] loss: 0.164\n",
      "[12,   277] loss: 0.085\n",
      "[12,   278] loss: 0.101\n",
      "[12,   279] loss: 0.148\n",
      "[12,   280] loss: 0.092\n",
      "[12,   281] loss: 0.159\n",
      "[12,   282] loss: 0.164\n",
      "[12,   283] loss: 0.176\n",
      "[12,   284] loss: 0.191\n",
      "[12,   285] loss: 0.149\n",
      "[12,   286] loss: 0.110\n",
      "[12,   287] loss: 0.092\n",
      "[12,   288] loss: 0.163\n",
      "[12,   289] loss: 0.057\n",
      "[12,   290] loss: 0.147\n",
      "[12,   291] loss: 0.163\n",
      "[12,   292] loss: 0.098\n",
      "[12,   293] loss: 0.108\n",
      "[12,   294] loss: 0.197\n",
      "[12,   295] loss: 0.195\n",
      "[12,   296] loss: 0.043\n",
      "[12,   297] loss: 0.246\n",
      "[12,   298] loss: 0.060\n",
      "[12,   299] loss: 0.167\n",
      "[12,   300] loss: 0.064\n",
      "[12,   301] loss: 0.180\n",
      "[12,   302] loss: 0.158\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "LOSS train 0.13137666121223904 valid 0.15785619732565603\n",
      "[13,     1] loss: 0.194\n",
      "[13,     2] loss: 0.151\n",
      "[13,     3] loss: 0.109\n",
      "[13,     4] loss: 0.144\n",
      "[13,     5] loss: 0.144\n",
      "[13,     6] loss: 0.139\n",
      "[13,     7] loss: 0.208\n",
      "[13,     8] loss: 0.169\n",
      "[13,     9] loss: 0.156\n",
      "[13,    10] loss: 0.120\n",
      "[13,    11] loss: 0.172\n",
      "[13,    12] loss: 0.177\n",
      "[13,    13] loss: 0.145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13,    14] loss: 0.087\n",
      "[13,    15] loss: 0.022\n",
      "[13,    16] loss: 0.111\n",
      "[13,    17] loss: 0.113\n",
      "[13,    18] loss: 0.147\n",
      "[13,    19] loss: 0.111\n",
      "[13,    20] loss: 0.182\n",
      "[13,    21] loss: 0.149\n",
      "[13,    22] loss: 0.015\n",
      "[13,    23] loss: 0.190\n",
      "[13,    24] loss: 0.116\n",
      "[13,    25] loss: 0.113\n",
      "[13,    26] loss: 0.078\n",
      "[13,    27] loss: 0.214\n",
      "[13,    28] loss: 0.202\n",
      "[13,    29] loss: 0.176\n",
      "[13,    30] loss: 0.106\n",
      "[13,    31] loss: 0.117\n",
      "[13,    32] loss: 0.071\n",
      "[13,    33] loss: 0.143\n",
      "[13,    34] loss: 0.128\n",
      "[13,    35] loss: 0.062\n",
      "[13,    36] loss: 0.077\n",
      "[13,    37] loss: 0.193\n",
      "[13,    38] loss: 0.139\n",
      "[13,    39] loss: 0.180\n",
      "[13,    40] loss: 0.154\n",
      "[13,    41] loss: 0.097\n",
      "[13,    42] loss: 0.152\n",
      "[13,    43] loss: 0.103\n",
      "[13,    44] loss: 0.195\n",
      "[13,    45] loss: 0.066\n",
      "[13,    46] loss: 0.157\n",
      "[13,    47] loss: 0.135\n",
      "[13,    48] loss: 0.074\n",
      "[13,    49] loss: 0.109\n",
      "[13,    50] loss: 0.144\n",
      "[13,    51] loss: 0.102\n",
      "[13,    52] loss: 0.074\n",
      "[13,    53] loss: 0.115\n",
      "[13,    54] loss: 0.075\n",
      "[13,    55] loss: 0.077\n",
      "[13,    56] loss: 0.120\n",
      "[13,    57] loss: 0.140\n",
      "[13,    58] loss: 0.118\n",
      "[13,    59] loss: 0.138\n",
      "[13,    60] loss: 0.103\n",
      "[13,    61] loss: 0.186\n",
      "[13,    62] loss: 0.066\n",
      "[13,    63] loss: 0.103\n",
      "[13,    64] loss: 0.153\n",
      "[13,    65] loss: 0.067\n",
      "[13,    66] loss: 0.123\n",
      "[13,    67] loss: 0.127\n",
      "[13,    68] loss: 0.156\n",
      "[13,    69] loss: 0.172\n",
      "[13,    70] loss: 0.148\n",
      "[13,    71] loss: 0.185\n",
      "[13,    72] loss: 0.077\n",
      "[13,    73] loss: 0.157\n",
      "[13,    74] loss: 0.111\n",
      "[13,    75] loss: 0.033\n",
      "[13,    76] loss: 0.151\n",
      "[13,    77] loss: 0.223\n",
      "[13,    78] loss: 0.156\n",
      "[13,    79] loss: 0.181\n",
      "[13,    80] loss: 0.112\n",
      "[13,    81] loss: 0.130\n",
      "[13,    82] loss: 0.122\n",
      "[13,    83] loss: 0.151\n",
      "[13,    84] loss: 0.066\n",
      "[13,    85] loss: 0.129\n",
      "[13,    86] loss: 0.100\n",
      "[13,    87] loss: 0.117\n",
      "[13,    88] loss: 0.094\n",
      "[13,    89] loss: 0.120\n",
      "[13,    90] loss: 0.129\n",
      "[13,    91] loss: 0.036\n",
      "[13,    92] loss: 0.129\n",
      "[13,    93] loss: 0.112\n",
      "[13,    94] loss: 0.111\n",
      "[13,    95] loss: 0.139\n",
      "[13,    96] loss: 0.180\n",
      "[13,    97] loss: 0.119\n",
      "[13,    98] loss: 0.079\n",
      "[13,    99] loss: 0.139\n",
      "[13,   100] loss: 0.062\n",
      "[13,   101] loss: 0.148\n",
      "[13,   102] loss: 0.156\n",
      "[13,   103] loss: 0.183\n",
      "[13,   104] loss: 0.219\n",
      "[13,   105] loss: 0.208\n",
      "[13,   106] loss: 0.067\n",
      "[13,   107] loss: 0.075\n",
      "[13,   108] loss: 0.217\n",
      "[13,   109] loss: 0.075\n",
      "[13,   110] loss: 0.033\n",
      "[13,   111] loss: 0.076\n",
      "[13,   112] loss: 0.171\n",
      "[13,   113] loss: 0.140\n",
      "[13,   114] loss: 0.080\n",
      "[13,   115] loss: 0.153\n",
      "[13,   116] loss: 0.125\n",
      "[13,   117] loss: 0.166\n",
      "[13,   118] loss: 0.131\n",
      "[13,   119] loss: 0.156\n",
      "[13,   120] loss: 0.204\n",
      "[13,   121] loss: 0.131\n",
      "[13,   122] loss: 0.067\n",
      "[13,   123] loss: 0.172\n",
      "[13,   124] loss: 0.100\n",
      "[13,   125] loss: 0.090\n",
      "[13,   126] loss: 0.119\n",
      "[13,   127] loss: 0.102\n",
      "[13,   128] loss: 0.061\n",
      "[13,   129] loss: 0.035\n",
      "[13,   130] loss: 0.123\n",
      "[13,   131] loss: 0.101\n",
      "[13,   132] loss: 0.057\n",
      "[13,   133] loss: 0.218\n",
      "[13,   134] loss: 0.127\n",
      "[13,   135] loss: 0.092\n",
      "[13,   136] loss: 0.124\n",
      "[13,   137] loss: 0.045\n",
      "[13,   138] loss: 0.118\n",
      "[13,   139] loss: 0.156\n",
      "[13,   140] loss: 0.152\n",
      "[13,   141] loss: 0.103\n",
      "[13,   142] loss: 0.124\n",
      "[13,   143] loss: 0.146\n",
      "[13,   144] loss: 0.143\n",
      "[13,   145] loss: 0.196\n",
      "[13,   146] loss: 0.117\n",
      "[13,   147] loss: 0.136\n",
      "[13,   148] loss: 0.162\n",
      "[13,   149] loss: 0.118\n",
      "[13,   150] loss: 0.101\n",
      "[13,   151] loss: 0.079\n",
      "[13,   152] loss: 0.192\n",
      "[13,   153] loss: 0.087\n",
      "[13,   154] loss: 0.109\n",
      "[13,   155] loss: 0.223\n",
      "[13,   156] loss: 0.206\n",
      "[13,   157] loss: 0.119\n",
      "[13,   158] loss: 0.178\n",
      "[13,   159] loss: 0.096\n",
      "[13,   160] loss: 0.031\n",
      "[13,   161] loss: 0.151\n",
      "[13,   162] loss: 0.036\n",
      "[13,   163] loss: 0.114\n",
      "[13,   164] loss: 0.068\n",
      "[13,   165] loss: 0.054\n",
      "[13,   166] loss: 0.080\n",
      "[13,   167] loss: 0.215\n",
      "[13,   168] loss: 0.107\n",
      "[13,   169] loss: 0.083\n",
      "[13,   170] loss: 0.059\n",
      "[13,   171] loss: 0.202\n",
      "[13,   172] loss: 0.100\n",
      "[13,   173] loss: 0.076\n",
      "[13,   174] loss: 0.070\n",
      "[13,   175] loss: 0.181\n",
      "[13,   176] loss: 0.143\n",
      "[13,   177] loss: 0.101\n",
      "[13,   178] loss: 0.165\n",
      "[13,   179] loss: 0.184\n",
      "[13,   180] loss: 0.253\n",
      "[13,   181] loss: 0.120\n",
      "[13,   182] loss: 0.226\n",
      "[13,   183] loss: 0.163\n",
      "[13,   184] loss: 0.147\n",
      "[13,   185] loss: 0.069\n",
      "[13,   186] loss: 0.119\n",
      "[13,   187] loss: 0.195\n",
      "[13,   188] loss: 0.142\n",
      "[13,   189] loss: 0.098\n",
      "[13,   190] loss: 0.133\n",
      "[13,   191] loss: 0.159\n",
      "[13,   192] loss: 0.175\n",
      "[13,   193] loss: 0.126\n",
      "[13,   194] loss: 0.121\n",
      "[13,   195] loss: 0.211\n",
      "[13,   196] loss: 0.108\n",
      "[13,   197] loss: 0.152\n",
      "[13,   198] loss: 0.104\n",
      "[13,   199] loss: 0.135\n",
      "[13,   200] loss: 0.149\n",
      "[13,   201] loss: 0.193\n",
      "[13,   202] loss: 0.163\n",
      "[13,   203] loss: 0.082\n",
      "[13,   204] loss: 0.155\n",
      "[13,   205] loss: 0.154\n",
      "[13,   206] loss: 0.164\n",
      "[13,   207] loss: 0.127\n",
      "[13,   208] loss: 0.235\n",
      "[13,   209] loss: 0.102\n",
      "[13,   210] loss: 0.142\n",
      "[13,   211] loss: 0.150\n",
      "[13,   212] loss: 0.178\n",
      "[13,   213] loss: 0.145\n",
      "[13,   214] loss: 0.168\n",
      "[13,   215] loss: 0.158\n",
      "[13,   216] loss: 0.127\n",
      "[13,   217] loss: 0.083\n",
      "[13,   218] loss: 0.143\n",
      "[13,   219] loss: 0.137\n",
      "[13,   220] loss: 0.176\n",
      "[13,   221] loss: 0.098\n",
      "[13,   222] loss: 0.066\n",
      "[13,   223] loss: 0.175\n",
      "[13,   224] loss: 0.115\n",
      "[13,   225] loss: 0.096\n",
      "[13,   226] loss: 0.185\n",
      "[13,   227] loss: 0.081\n",
      "[13,   228] loss: 0.114\n",
      "[13,   229] loss: 0.196\n",
      "[13,   230] loss: 0.157\n",
      "[13,   231] loss: 0.066\n",
      "[13,   232] loss: 0.167\n",
      "[13,   233] loss: 0.170\n",
      "[13,   234] loss: 0.181\n",
      "[13,   235] loss: 0.170\n",
      "[13,   236] loss: 0.186\n",
      "[13,   237] loss: 0.160\n",
      "[13,   238] loss: 0.072\n",
      "[13,   239] loss: 0.099\n",
      "[13,   240] loss: 0.164\n",
      "[13,   241] loss: 0.182\n",
      "[13,   242] loss: 0.105\n",
      "[13,   243] loss: 0.096\n",
      "[13,   244] loss: 0.107\n",
      "[13,   245] loss: 0.129\n",
      "[13,   246] loss: 0.130\n",
      "[13,   247] loss: 0.151\n",
      "[13,   248] loss: 0.166\n",
      "[13,   249] loss: 0.136\n",
      "[13,   250] loss: 0.130\n",
      "[13,   251] loss: 0.121\n",
      "[13,   252] loss: 0.067\n",
      "[13,   253] loss: 0.125\n",
      "[13,   254] loss: 0.124\n",
      "[13,   255] loss: 0.148\n",
      "[13,   256] loss: 0.092\n",
      "[13,   257] loss: 0.182\n",
      "[13,   258] loss: 0.183\n",
      "[13,   259] loss: 0.086\n",
      "[13,   260] loss: 0.142\n",
      "[13,   261] loss: 0.173\n",
      "[13,   262] loss: 0.194\n",
      "[13,   263] loss: 0.043\n",
      "[13,   264] loss: 0.181\n",
      "[13,   265] loss: 0.137\n",
      "[13,   266] loss: 0.186\n",
      "[13,   267] loss: 0.122\n",
      "[13,   268] loss: 0.212\n",
      "[13,   269] loss: 0.159\n",
      "[13,   270] loss: 0.196\n",
      "[13,   271] loss: 0.154\n",
      "[13,   272] loss: 0.056\n",
      "[13,   273] loss: 0.057\n",
      "[13,   274] loss: 0.193\n",
      "[13,   275] loss: 0.074\n",
      "[13,   276] loss: 0.161\n",
      "[13,   277] loss: 0.084\n",
      "[13,   278] loss: 0.102\n",
      "[13,   279] loss: 0.147\n",
      "[13,   280] loss: 0.091\n",
      "[13,   281] loss: 0.157\n",
      "[13,   282] loss: 0.164\n",
      "[13,   283] loss: 0.176\n",
      "[13,   284] loss: 0.190\n",
      "[13,   285] loss: 0.150\n",
      "[13,   286] loss: 0.111\n",
      "[13,   287] loss: 0.100\n",
      "[13,   288] loss: 0.163\n",
      "[13,   289] loss: 0.059\n",
      "[13,   290] loss: 0.150\n",
      "[13,   291] loss: 0.164\n",
      "[13,   292] loss: 0.096\n",
      "[13,   293] loss: 0.110\n",
      "[13,   294] loss: 0.196\n",
      "[13,   295] loss: 0.195\n",
      "[13,   296] loss: 0.044\n",
      "[13,   297] loss: 0.251\n",
      "[13,   298] loss: 0.060\n",
      "[13,   299] loss: 0.172\n",
      "[13,   300] loss: 0.069\n",
      "[13,   301] loss: 0.181\n",
      "[13,   302] loss: 0.158\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "LOSS train 0.13160089381187168 valid 0.14639315721220694\n",
      "[14,     1] loss: 0.192\n",
      "[14,     2] loss: 0.151\n",
      "[14,     3] loss: 0.111\n",
      "[14,     4] loss: 0.142\n",
      "[14,     5] loss: 0.140\n",
      "[14,     6] loss: 0.140\n",
      "[14,     7] loss: 0.209\n",
      "[14,     8] loss: 0.177\n",
      "[14,     9] loss: 0.152\n",
      "[14,    10] loss: 0.120\n",
      "[14,    11] loss: 0.172\n",
      "[14,    12] loss: 0.178\n",
      "[14,    13] loss: 0.149\n",
      "[14,    14] loss: 0.088\n",
      "[14,    15] loss: 0.022\n",
      "[14,    16] loss: 0.111\n",
      "[14,    17] loss: 0.112\n",
      "[14,    18] loss: 0.144\n",
      "[14,    19] loss: 0.112\n",
      "[14,    20] loss: 0.181\n",
      "[14,    21] loss: 0.150\n",
      "[14,    22] loss: 0.014\n",
      "[14,    23] loss: 0.191\n",
      "[14,    24] loss: 0.117\n",
      "[14,    25] loss: 0.115\n",
      "[14,    26] loss: 0.079\n",
      "[14,    27] loss: 0.215\n",
      "[14,    28] loss: 0.202\n",
      "[14,    29] loss: 0.173\n",
      "[14,    30] loss: 0.104\n",
      "[14,    31] loss: 0.123\n",
      "[14,    32] loss: 0.087\n",
      "[14,    33] loss: 0.141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14,    34] loss: 0.126\n",
      "[14,    35] loss: 0.064\n",
      "[14,    36] loss: 0.079\n",
      "[14,    37] loss: 0.202\n",
      "[14,    38] loss: 0.141\n",
      "[14,    39] loss: 0.182\n",
      "[14,    40] loss: 0.152\n",
      "[14,    41] loss: 0.083\n",
      "[14,    42] loss: 0.152\n",
      "[14,    43] loss: 0.107\n",
      "[14,    44] loss: 0.198\n",
      "[14,    45] loss: 0.078\n",
      "[14,    46] loss: 0.161\n",
      "[14,    47] loss: 0.131\n",
      "[14,    48] loss: 0.070\n",
      "[14,    49] loss: 0.107\n",
      "[14,    50] loss: 0.143\n",
      "[14,    51] loss: 0.103\n",
      "[14,    52] loss: 0.074\n",
      "[14,    53] loss: 0.116\n",
      "[14,    54] loss: 0.075\n",
      "[14,    55] loss: 0.071\n",
      "[14,    56] loss: 0.121\n",
      "[14,    57] loss: 0.139\n",
      "[14,    58] loss: 0.120\n",
      "[14,    59] loss: 0.137\n",
      "[14,    60] loss: 0.103\n",
      "[14,    61] loss: 0.187\n",
      "[14,    62] loss: 0.067\n",
      "[14,    63] loss: 0.100\n",
      "[14,    64] loss: 0.153\n",
      "[14,    65] loss: 0.065\n",
      "[14,    66] loss: 0.124\n",
      "[14,    67] loss: 0.128\n",
      "[14,    68] loss: 0.154\n",
      "[14,    69] loss: 0.174\n",
      "[14,    70] loss: 0.146\n",
      "[14,    71] loss: 0.186\n",
      "[14,    72] loss: 0.078\n",
      "[14,    73] loss: 0.156\n",
      "[14,    74] loss: 0.107\n",
      "[14,    75] loss: 0.032\n",
      "[14,    76] loss: 0.152\n",
      "[14,    77] loss: 0.223\n",
      "[14,    78] loss: 0.155\n",
      "[14,    79] loss: 0.181\n",
      "[14,    80] loss: 0.110\n",
      "[14,    81] loss: 0.126\n",
      "[14,    82] loss: 0.121\n",
      "[14,    83] loss: 0.152\n",
      "[14,    84] loss: 0.068\n",
      "[14,    85] loss: 0.127\n",
      "[14,    86] loss: 0.099\n",
      "[14,    87] loss: 0.117\n",
      "[14,    88] loss: 0.093\n",
      "[14,    89] loss: 0.118\n",
      "[14,    90] loss: 0.130\n",
      "[14,    91] loss: 0.032\n",
      "[14,    92] loss: 0.129\n",
      "[14,    93] loss: 0.111\n",
      "[14,    94] loss: 0.111\n",
      "[14,    95] loss: 0.139\n",
      "[14,    96] loss: 0.181\n",
      "[14,    97] loss: 0.117\n",
      "[14,    98] loss: 0.081\n",
      "[14,    99] loss: 0.138\n",
      "[14,   100] loss: 0.061\n",
      "[14,   101] loss: 0.147\n",
      "[14,   102] loss: 0.147\n",
      "[14,   103] loss: 0.177\n",
      "[14,   104] loss: 0.216\n",
      "[14,   105] loss: 0.207\n",
      "[14,   106] loss: 0.068\n",
      "[14,   107] loss: 0.074\n",
      "[14,   108] loss: 0.212\n",
      "[14,   109] loss: 0.072\n",
      "[14,   110] loss: 0.033\n",
      "[14,   111] loss: 0.075\n",
      "[14,   112] loss: 0.164\n",
      "[14,   113] loss: 0.138\n",
      "[14,   114] loss: 0.081\n",
      "[14,   115] loss: 0.150\n",
      "[14,   116] loss: 0.120\n",
      "[14,   117] loss: 0.165\n",
      "[14,   118] loss: 0.130\n",
      "[14,   119] loss: 0.153\n",
      "[14,   120] loss: 0.202\n",
      "[14,   121] loss: 0.130\n",
      "[14,   122] loss: 0.066\n",
      "[14,   123] loss: 0.169\n",
      "[14,   124] loss: 0.094\n",
      "[14,   125] loss: 0.090\n",
      "[14,   126] loss: 0.122\n",
      "[14,   127] loss: 0.101\n",
      "[14,   128] loss: 0.059\n",
      "[14,   129] loss: 0.034\n",
      "[14,   130] loss: 0.121\n",
      "[14,   131] loss: 0.101\n",
      "[14,   132] loss: 0.061\n",
      "[14,   133] loss: 0.213\n",
      "[14,   134] loss: 0.129\n",
      "[14,   135] loss: 0.092\n",
      "[14,   136] loss: 0.123\n",
      "[14,   137] loss: 0.044\n",
      "[14,   138] loss: 0.118\n",
      "[14,   139] loss: 0.159\n",
      "[14,   140] loss: 0.133\n",
      "[14,   141] loss: 0.102\n",
      "[14,   142] loss: 0.108\n",
      "[14,   143] loss: 0.141\n",
      "[14,   144] loss: 0.139\n",
      "[14,   145] loss: 0.196\n",
      "[14,   146] loss: 0.120\n",
      "[14,   147] loss: 0.139\n",
      "[14,   148] loss: 0.162\n",
      "[14,   149] loss: 0.108\n",
      "[14,   150] loss: 0.093\n",
      "[14,   151] loss: 0.078\n",
      "[14,   152] loss: 0.199\n",
      "[14,   153] loss: 0.091\n",
      "[14,   154] loss: 0.112\n",
      "[14,   155] loss: 0.218\n",
      "[14,   156] loss: 0.201\n",
      "[14,   157] loss: 0.120\n",
      "[14,   158] loss: 0.175\n",
      "[14,   159] loss: 0.094\n",
      "[14,   160] loss: 0.030\n",
      "[14,   161] loss: 0.151\n",
      "[14,   162] loss: 0.035\n",
      "[14,   163] loss: 0.122\n",
      "[14,   164] loss: 0.066\n",
      "[14,   165] loss: 0.053\n",
      "[14,   166] loss: 0.079\n",
      "[14,   167] loss: 0.210\n",
      "[14,   168] loss: 0.109\n",
      "[14,   169] loss: 0.082\n",
      "[14,   170] loss: 0.061\n",
      "[14,   171] loss: 0.200\n",
      "[14,   172] loss: 0.101\n",
      "[14,   173] loss: 0.077\n",
      "[14,   174] loss: 0.071\n",
      "[14,   175] loss: 0.181\n",
      "[14,   176] loss: 0.139\n",
      "[14,   177] loss: 0.099\n",
      "[14,   178] loss: 0.165\n",
      "[14,   179] loss: 0.187\n",
      "[14,   180] loss: 0.260\n",
      "[14,   181] loss: 0.125\n",
      "[14,   182] loss: 0.226\n",
      "[14,   183] loss: 0.158\n",
      "[14,   184] loss: 0.142\n",
      "[14,   185] loss: 0.064\n",
      "[14,   186] loss: 0.122\n",
      "[14,   187] loss: 0.205\n",
      "[14,   188] loss: 0.148\n",
      "[14,   189] loss: 0.102\n",
      "[14,   190] loss: 0.135\n",
      "[14,   191] loss: 0.159\n",
      "[14,   192] loss: 0.183\n",
      "[14,   193] loss: 0.129\n",
      "[14,   194] loss: 0.125\n",
      "[14,   195] loss: 0.209\n",
      "[14,   196] loss: 0.109\n",
      "[14,   197] loss: 0.152\n",
      "[14,   198] loss: 0.106\n",
      "[14,   199] loss: 0.135\n",
      "[14,   200] loss: 0.146\n",
      "[14,   201] loss: 0.193\n",
      "[14,   202] loss: 0.161\n",
      "[14,   203] loss: 0.090\n",
      "[14,   204] loss: 0.155\n",
      "[14,   205] loss: 0.154\n",
      "[14,   206] loss: 0.165\n",
      "[14,   207] loss: 0.125\n",
      "[14,   208] loss: 0.234\n",
      "[14,   209] loss: 0.104\n",
      "[14,   210] loss: 0.158\n",
      "[14,   211] loss: 0.153\n",
      "[14,   212] loss: 0.180\n",
      "[14,   213] loss: 0.144\n",
      "[14,   214] loss: 0.161\n",
      "[14,   215] loss: 0.156\n",
      "[14,   216] loss: 0.130\n",
      "[14,   217] loss: 0.086\n",
      "[14,   218] loss: 0.134\n",
      "[14,   219] loss: 0.133\n",
      "[14,   220] loss: 0.173\n",
      "[14,   221] loss: 0.097\n",
      "[14,   222] loss: 0.064\n",
      "[14,   223] loss: 0.182\n",
      "[14,   224] loss: 0.116\n",
      "[14,   225] loss: 0.093\n",
      "[14,   226] loss: 0.185\n",
      "[14,   227] loss: 0.086\n",
      "[14,   228] loss: 0.114\n",
      "[14,   229] loss: 0.193\n",
      "[14,   230] loss: 0.157\n",
      "[14,   231] loss: 0.061\n",
      "[14,   232] loss: 0.170\n",
      "[14,   233] loss: 0.171\n",
      "[14,   234] loss: 0.181\n",
      "[14,   235] loss: 0.171\n",
      "[14,   236] loss: 0.188\n",
      "[14,   237] loss: 0.161\n",
      "[14,   238] loss: 0.073\n",
      "[14,   239] loss: 0.100\n",
      "[14,   240] loss: 0.163\n",
      "[14,   241] loss: 0.182\n",
      "[14,   242] loss: 0.102\n",
      "[14,   243] loss: 0.097\n",
      "[14,   244] loss: 0.107\n",
      "[14,   245] loss: 0.129\n",
      "[14,   246] loss: 0.130\n",
      "[14,   247] loss: 0.150\n",
      "[14,   248] loss: 0.166\n",
      "[14,   249] loss: 0.135\n",
      "[14,   250] loss: 0.129\n",
      "[14,   251] loss: 0.122\n",
      "[14,   252] loss: 0.064\n",
      "[14,   253] loss: 0.125\n",
      "[14,   254] loss: 0.126\n",
      "[14,   255] loss: 0.147\n",
      "[14,   256] loss: 0.092\n",
      "[14,   257] loss: 0.187\n",
      "[14,   258] loss: 0.184\n",
      "[14,   259] loss: 0.086\n",
      "[14,   260] loss: 0.143\n",
      "[14,   261] loss: 0.173\n",
      "[14,   262] loss: 0.193\n",
      "[14,   263] loss: 0.041\n",
      "[14,   264] loss: 0.180\n",
      "[14,   265] loss: 0.137\n",
      "[14,   266] loss: 0.188\n",
      "[14,   267] loss: 0.122\n",
      "[14,   268] loss: 0.211\n",
      "[14,   269] loss: 0.159\n",
      "[14,   270] loss: 0.194\n",
      "[14,   271] loss: 0.153\n",
      "[14,   272] loss: 0.055\n",
      "[14,   273] loss: 0.058\n",
      "[14,   274] loss: 0.192\n",
      "[14,   275] loss: 0.073\n",
      "[14,   276] loss: 0.161\n",
      "[14,   277] loss: 0.084\n",
      "[14,   278] loss: 0.100\n",
      "[14,   279] loss: 0.147\n",
      "[14,   280] loss: 0.091\n",
      "[14,   281] loss: 0.157\n",
      "[14,   282] loss: 0.164\n",
      "[14,   283] loss: 0.177\n",
      "[14,   284] loss: 0.190\n",
      "[14,   285] loss: 0.149\n",
      "[14,   286] loss: 0.109\n",
      "[14,   287] loss: 0.091\n",
      "[14,   288] loss: 0.163\n",
      "[14,   289] loss: 0.058\n",
      "[14,   290] loss: 0.146\n",
      "[14,   291] loss: 0.159\n",
      "[14,   292] loss: 0.097\n",
      "[14,   293] loss: 0.108\n",
      "[14,   294] loss: 0.196\n",
      "[14,   295] loss: 0.194\n",
      "[14,   296] loss: 0.042\n",
      "[14,   297] loss: 0.243\n",
      "[14,   298] loss: 0.068\n",
      "[14,   299] loss: 0.168\n",
      "[14,   300] loss: 0.067\n",
      "[14,   301] loss: 0.179\n",
      "[14,   302] loss: 0.154\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "LOSS train 0.13123158254161083 valid 0.15913792924525647\n",
      "[15,     1] loss: 0.194\n",
      "[15,     2] loss: 0.149\n",
      "[15,     3] loss: 0.108\n",
      "[15,     4] loss: 0.144\n",
      "[15,     5] loss: 0.143\n",
      "[15,     6] loss: 0.138\n",
      "[15,     7] loss: 0.208\n",
      "[15,     8] loss: 0.168\n",
      "[15,     9] loss: 0.152\n",
      "[15,    10] loss: 0.119\n",
      "[15,    11] loss: 0.172\n",
      "[15,    12] loss: 0.173\n",
      "[15,    13] loss: 0.148\n",
      "[15,    14] loss: 0.086\n",
      "[15,    15] loss: 0.020\n",
      "[15,    16] loss: 0.112\n",
      "[15,    17] loss: 0.111\n",
      "[15,    18] loss: 0.143\n",
      "[15,    19] loss: 0.110\n",
      "[15,    20] loss: 0.179\n",
      "[15,    21] loss: 0.146\n",
      "[15,    22] loss: 0.015\n",
      "[15,    23] loss: 0.189\n",
      "[15,    24] loss: 0.119\n",
      "[15,    25] loss: 0.114\n",
      "[15,    26] loss: 0.080\n",
      "[15,    27] loss: 0.211\n",
      "[15,    28] loss: 0.200\n",
      "[15,    29] loss: 0.171\n",
      "[15,    30] loss: 0.104\n",
      "[15,    31] loss: 0.120\n",
      "[15,    32] loss: 0.082\n",
      "[15,    33] loss: 0.141\n",
      "[15,    34] loss: 0.121\n",
      "[15,    35] loss: 0.060\n",
      "[15,    36] loss: 0.064\n",
      "[15,    37] loss: 0.198\n",
      "[15,    38] loss: 0.142\n",
      "[15,    39] loss: 0.182\n",
      "[15,    40] loss: 0.152\n",
      "[15,    41] loss: 0.075\n",
      "[15,    42] loss: 0.150\n",
      "[15,    43] loss: 0.095\n",
      "[15,    44] loss: 0.195\n",
      "[15,    45] loss: 0.051\n",
      "[15,    46] loss: 0.162\n",
      "[15,    47] loss: 0.139\n",
      "[15,    48] loss: 0.074\n",
      "[15,    49] loss: 0.106\n",
      "[15,    50] loss: 0.141\n",
      "[15,    51] loss: 0.099\n",
      "[15,    52] loss: 0.071\n",
      "[15,    53] loss: 0.118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15,    54] loss: 0.080\n",
      "[15,    55] loss: 0.071\n",
      "[15,    56] loss: 0.121\n",
      "[15,    57] loss: 0.143\n",
      "[15,    58] loss: 0.116\n",
      "[15,    59] loss: 0.136\n",
      "[15,    60] loss: 0.104\n",
      "[15,    61] loss: 0.184\n",
      "[15,    62] loss: 0.083\n",
      "[15,    63] loss: 0.112\n",
      "[15,    64] loss: 0.155\n",
      "[15,    65] loss: 0.075\n",
      "[15,    66] loss: 0.124\n",
      "[15,    67] loss: 0.129\n",
      "[15,    68] loss: 0.155\n",
      "[15,    69] loss: 0.174\n",
      "[15,    70] loss: 0.147\n",
      "[15,    71] loss: 0.190\n",
      "[15,    72] loss: 0.080\n",
      "[15,    73] loss: 0.159\n",
      "[15,    74] loss: 0.108\n",
      "[15,    75] loss: 0.033\n",
      "[15,    76] loss: 0.151\n",
      "[15,    77] loss: 0.222\n",
      "[15,    78] loss: 0.155\n",
      "[15,    79] loss: 0.180\n",
      "[15,    80] loss: 0.110\n",
      "[15,    81] loss: 0.120\n",
      "[15,    82] loss: 0.125\n",
      "[15,    83] loss: 0.154\n",
      "[15,    84] loss: 0.068\n",
      "[15,    85] loss: 0.126\n",
      "[15,    86] loss: 0.109\n",
      "[15,    87] loss: 0.117\n",
      "[15,    88] loss: 0.089\n",
      "[15,    89] loss: 0.119\n",
      "[15,    90] loss: 0.130\n",
      "[15,    91] loss: 0.033\n",
      "[15,    92] loss: 0.130\n",
      "[15,    93] loss: 0.110\n",
      "[15,    94] loss: 0.110\n",
      "[15,    95] loss: 0.145\n",
      "[15,    96] loss: 0.183\n",
      "[15,    97] loss: 0.120\n",
      "[15,    98] loss: 0.077\n",
      "[15,    99] loss: 0.138\n",
      "[15,   100] loss: 0.063\n",
      "[15,   101] loss: 0.147\n",
      "[15,   102] loss: 0.149\n",
      "[15,   103] loss: 0.186\n",
      "[15,   104] loss: 0.223\n",
      "[15,   105] loss: 0.207\n",
      "[15,   106] loss: 0.066\n",
      "[15,   107] loss: 0.075\n",
      "[15,   108] loss: 0.211\n",
      "[15,   109] loss: 0.071\n",
      "[15,   110] loss: 0.050\n",
      "[15,   111] loss: 0.074\n",
      "[15,   112] loss: 0.166\n",
      "[15,   113] loss: 0.136\n",
      "[15,   114] loss: 0.082\n",
      "[15,   115] loss: 0.164\n",
      "[15,   116] loss: 0.114\n",
      "[15,   117] loss: 0.166\n",
      "[15,   118] loss: 0.126\n",
      "[15,   119] loss: 0.157\n",
      "[15,   120] loss: 0.203\n",
      "[15,   121] loss: 0.133\n",
      "[15,   122] loss: 0.079\n",
      "[15,   123] loss: 0.173\n",
      "[15,   124] loss: 0.102\n",
      "[15,   125] loss: 0.100\n",
      "[15,   126] loss: 0.120\n",
      "[15,   127] loss: 0.105\n",
      "[15,   128] loss: 0.061\n",
      "[15,   129] loss: 0.037\n",
      "[15,   130] loss: 0.127\n",
      "[15,   131] loss: 0.101\n",
      "[15,   132] loss: 0.059\n",
      "[15,   133] loss: 0.232\n",
      "[15,   134] loss: 0.129\n",
      "[15,   135] loss: 0.098\n",
      "[15,   136] loss: 0.131\n",
      "[15,   137] loss: 0.048\n",
      "[15,   138] loss: 0.124\n",
      "[15,   139] loss: 0.155\n",
      "[15,   140] loss: 0.136\n",
      "[15,   141] loss: 0.103\n",
      "[15,   142] loss: 0.108\n",
      "[15,   143] loss: 0.144\n",
      "[15,   144] loss: 0.141\n",
      "[15,   145] loss: 0.206\n",
      "[15,   146] loss: 0.121\n",
      "[15,   147] loss: 0.135\n",
      "[15,   148] loss: 0.162\n",
      "[15,   149] loss: 0.108\n",
      "[15,   150] loss: 0.094\n",
      "[15,   151] loss: 0.080\n",
      "[15,   152] loss: 0.196\n",
      "[15,   153] loss: 0.087\n",
      "[15,   154] loss: 0.109\n",
      "[15,   155] loss: 0.220\n",
      "[15,   156] loss: 0.201\n",
      "[15,   157] loss: 0.119\n",
      "[15,   158] loss: 0.176\n",
      "[15,   159] loss: 0.094\n",
      "[15,   160] loss: 0.033\n",
      "[15,   161] loss: 0.147\n",
      "[15,   162] loss: 0.038\n",
      "[15,   163] loss: 0.126\n",
      "[15,   164] loss: 0.065\n",
      "[15,   165] loss: 0.051\n",
      "[15,   166] loss: 0.081\n",
      "[15,   167] loss: 0.212\n",
      "[15,   168] loss: 0.113\n",
      "[15,   169] loss: 0.083\n",
      "[15,   170] loss: 0.058\n",
      "[15,   171] loss: 0.201\n",
      "[15,   172] loss: 0.099\n",
      "[15,   173] loss: 0.078\n",
      "[15,   174] loss: 0.070\n",
      "[15,   175] loss: 0.181\n",
      "[15,   176] loss: 0.141\n",
      "[15,   177] loss: 0.097\n",
      "[15,   178] loss: 0.162\n",
      "[15,   179] loss: 0.184\n",
      "[15,   180] loss: 0.255\n",
      "[15,   181] loss: 0.119\n",
      "[15,   182] loss: 0.226\n",
      "[15,   183] loss: 0.156\n",
      "[15,   184] loss: 0.139\n",
      "[15,   185] loss: 0.064\n",
      "[15,   186] loss: 0.113\n",
      "[15,   187] loss: 0.200\n",
      "[15,   188] loss: 0.144\n",
      "[15,   189] loss: 0.102\n",
      "[15,   190] loss: 0.141\n",
      "[15,   191] loss: 0.164\n",
      "[15,   192] loss: 0.173\n",
      "[15,   193] loss: 0.122\n",
      "[15,   194] loss: 0.120\n",
      "[15,   195] loss: 0.232\n",
      "[15,   196] loss: 0.116\n",
      "[15,   197] loss: 0.153\n",
      "[15,   198] loss: 0.113\n",
      "[15,   199] loss: 0.136\n",
      "[15,   200] loss: 0.148\n",
      "[15,   201] loss: 0.196\n",
      "[15,   202] loss: 0.170\n",
      "[15,   203] loss: 0.108\n",
      "[15,   204] loss: 0.156\n",
      "[15,   205] loss: 0.153\n",
      "[15,   206] loss: 0.165\n",
      "[15,   207] loss: 0.126\n",
      "[15,   208] loss: 0.240\n",
      "[15,   209] loss: 0.103\n",
      "[15,   210] loss: 0.150\n",
      "[15,   211] loss: 0.152\n",
      "[15,   212] loss: 0.179\n",
      "[15,   213] loss: 0.144\n",
      "[15,   214] loss: 0.161\n",
      "[15,   215] loss: 0.156\n",
      "[15,   216] loss: 0.128\n",
      "[15,   217] loss: 0.086\n",
      "[15,   218] loss: 0.136\n",
      "[15,   219] loss: 0.134\n",
      "[15,   220] loss: 0.175\n",
      "[15,   221] loss: 0.096\n",
      "[15,   222] loss: 0.064\n",
      "[15,   223] loss: 0.175\n",
      "[15,   224] loss: 0.116\n",
      "[15,   225] loss: 0.094\n",
      "[15,   226] loss: 0.183\n",
      "[15,   227] loss: 0.083\n",
      "[15,   228] loss: 0.114\n",
      "[15,   229] loss: 0.194\n",
      "[15,   230] loss: 0.157\n",
      "[15,   231] loss: 0.062\n",
      "[15,   232] loss: 0.170\n",
      "[15,   233] loss: 0.172\n",
      "[15,   234] loss: 0.186\n",
      "[15,   235] loss: 0.170\n",
      "[15,   236] loss: 0.185\n",
      "[15,   237] loss: 0.159\n",
      "[15,   238] loss: 0.073\n",
      "[15,   239] loss: 0.098\n",
      "[15,   240] loss: 0.162\n",
      "[15,   241] loss: 0.182\n",
      "[15,   242] loss: 0.103\n",
      "[15,   243] loss: 0.095\n",
      "[15,   244] loss: 0.106\n",
      "[15,   245] loss: 0.129\n",
      "[15,   246] loss: 0.130\n",
      "[15,   247] loss: 0.150\n",
      "[15,   248] loss: 0.165\n",
      "[15,   249] loss: 0.135\n",
      "[15,   250] loss: 0.129\n",
      "[15,   251] loss: 0.121\n",
      "[15,   252] loss: 0.066\n",
      "[15,   253] loss: 0.122\n",
      "[15,   254] loss: 0.124\n",
      "[15,   255] loss: 0.148\n",
      "[15,   256] loss: 0.091\n",
      "[15,   257] loss: 0.182\n",
      "[15,   258] loss: 0.182\n",
      "[15,   259] loss: 0.086\n",
      "[15,   260] loss: 0.142\n",
      "[15,   261] loss: 0.170\n",
      "[15,   262] loss: 0.194\n",
      "[15,   263] loss: 0.045\n",
      "[15,   264] loss: 0.179\n",
      "[15,   265] loss: 0.137\n",
      "[15,   266] loss: 0.184\n",
      "[15,   267] loss: 0.122\n",
      "[15,   268] loss: 0.209\n",
      "[15,   269] loss: 0.160\n",
      "[15,   270] loss: 0.195\n",
      "[15,   271] loss: 0.153\n",
      "[15,   272] loss: 0.055\n",
      "[15,   273] loss: 0.057\n",
      "[15,   274] loss: 0.192\n",
      "[15,   275] loss: 0.073\n",
      "[15,   276] loss: 0.167\n",
      "[15,   277] loss: 0.084\n",
      "[15,   278] loss: 0.100\n",
      "[15,   279] loss: 0.146\n",
      "[15,   280] loss: 0.090\n",
      "[15,   281] loss: 0.157\n",
      "[15,   282] loss: 0.164\n",
      "[15,   283] loss: 0.176\n",
      "[15,   284] loss: 0.189\n",
      "[15,   285] loss: 0.149\n",
      "[15,   286] loss: 0.109\n",
      "[15,   287] loss: 0.091\n",
      "[15,   288] loss: 0.162\n",
      "[15,   289] loss: 0.059\n",
      "[15,   290] loss: 0.147\n",
      "[15,   291] loss: 0.160\n",
      "[15,   292] loss: 0.097\n",
      "[15,   293] loss: 0.108\n",
      "[15,   294] loss: 0.196\n",
      "[15,   295] loss: 0.194\n",
      "[15,   296] loss: 0.042\n",
      "[15,   297] loss: 0.242\n",
      "[15,   298] loss: 0.069\n",
      "[15,   299] loss: 0.167\n",
      "[15,   300] loss: 0.069\n",
      "[15,   301] loss: 0.181\n",
      "[15,   302] loss: 0.151\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "LOSS train 0.13152239171923785 valid 0.15230482295155526\n",
      "[16,     1] loss: 0.194\n",
      "[16,     2] loss: 0.148\n",
      "[16,     3] loss: 0.105\n",
      "[16,     4] loss: 0.143\n",
      "[16,     5] loss: 0.141\n",
      "[16,     6] loss: 0.141\n",
      "[16,     7] loss: 0.207\n",
      "[16,     8] loss: 0.170\n",
      "[16,     9] loss: 0.152\n",
      "[16,    10] loss: 0.118\n",
      "[16,    11] loss: 0.171\n",
      "[16,    12] loss: 0.172\n",
      "[16,    13] loss: 0.145\n",
      "[16,    14] loss: 0.087\n",
      "[16,    15] loss: 0.023\n",
      "[16,    16] loss: 0.111\n",
      "[16,    17] loss: 0.113\n",
      "[16,    18] loss: 0.143\n",
      "[16,    19] loss: 0.110\n",
      "[16,    20] loss: 0.181\n",
      "[16,    21] loss: 0.146\n",
      "[16,    22] loss: 0.015\n",
      "[16,    23] loss: 0.188\n",
      "[16,    24] loss: 0.116\n",
      "[16,    25] loss: 0.116\n",
      "[16,    26] loss: 0.081\n",
      "[16,    27] loss: 0.212\n",
      "[16,    28] loss: 0.200\n",
      "[16,    29] loss: 0.167\n",
      "[16,    30] loss: 0.096\n",
      "[16,    31] loss: 0.117\n",
      "[16,    32] loss: 0.078\n",
      "[16,    33] loss: 0.143\n",
      "[16,    34] loss: 0.122\n",
      "[16,    35] loss: 0.061\n",
      "[16,    36] loss: 0.059\n",
      "[16,    37] loss: 0.182\n",
      "[16,    38] loss: 0.137\n",
      "[16,    39] loss: 0.179\n",
      "[16,    40] loss: 0.152\n",
      "[16,    41] loss: 0.075\n",
      "[16,    42] loss: 0.150\n",
      "[16,    43] loss: 0.090\n",
      "[16,    44] loss: 0.193\n",
      "[16,    45] loss: 0.041\n",
      "[16,    46] loss: 0.158\n",
      "[16,    47] loss: 0.130\n",
      "[16,    48] loss: 0.069\n",
      "[16,    49] loss: 0.107\n",
      "[16,    50] loss: 0.142\n",
      "[16,    51] loss: 0.096\n",
      "[16,    52] loss: 0.068\n",
      "[16,    53] loss: 0.112\n",
      "[16,    54] loss: 0.076\n",
      "[16,    55] loss: 0.074\n",
      "[16,    56] loss: 0.116\n",
      "[16,    57] loss: 0.142\n",
      "[16,    58] loss: 0.117\n",
      "[16,    59] loss: 0.135\n",
      "[16,    60] loss: 0.101\n",
      "[16,    61] loss: 0.182\n",
      "[16,    62] loss: 0.069\n",
      "[16,    63] loss: 0.100\n",
      "[16,    64] loss: 0.154\n",
      "[16,    65] loss: 0.073\n",
      "[16,    66] loss: 0.122\n",
      "[16,    67] loss: 0.125\n",
      "[16,    68] loss: 0.153\n",
      "[16,    69] loss: 0.170\n",
      "[16,    70] loss: 0.144\n",
      "[16,    71] loss: 0.187\n",
      "[16,    72] loss: 0.076\n",
      "[16,    73] loss: 0.158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16,    74] loss: 0.107\n",
      "[16,    75] loss: 0.031\n",
      "[16,    76] loss: 0.150\n",
      "[16,    77] loss: 0.222\n",
      "[16,    78] loss: 0.154\n",
      "[16,    79] loss: 0.178\n",
      "[16,    80] loss: 0.109\n",
      "[16,    81] loss: 0.119\n",
      "[16,    82] loss: 0.124\n",
      "[16,    83] loss: 0.149\n",
      "[16,    84] loss: 0.067\n",
      "[16,    85] loss: 0.125\n",
      "[16,    86] loss: 0.105\n",
      "[16,    87] loss: 0.120\n",
      "[16,    88] loss: 0.088\n",
      "[16,    89] loss: 0.116\n",
      "[16,    90] loss: 0.128\n",
      "[16,    91] loss: 0.033\n",
      "[16,    92] loss: 0.128\n",
      "[16,    93] loss: 0.112\n",
      "[16,    94] loss: 0.109\n",
      "[16,    95] loss: 0.140\n",
      "[16,    96] loss: 0.180\n",
      "[16,    97] loss: 0.118\n",
      "[16,    98] loss: 0.077\n",
      "[16,    99] loss: 0.141\n",
      "[16,   100] loss: 0.070\n",
      "[16,   101] loss: 0.148\n",
      "[16,   102] loss: 0.147\n",
      "[16,   103] loss: 0.185\n",
      "[16,   104] loss: 0.225\n",
      "[16,   105] loss: 0.208\n",
      "[16,   106] loss: 0.065\n",
      "[16,   107] loss: 0.076\n",
      "[16,   108] loss: 0.206\n",
      "[16,   109] loss: 0.071\n",
      "[16,   110] loss: 0.036\n",
      "[16,   111] loss: 0.076\n",
      "[16,   112] loss: 0.165\n",
      "[16,   113] loss: 0.138\n",
      "[16,   114] loss: 0.079\n",
      "[16,   115] loss: 0.148\n",
      "[16,   116] loss: 0.117\n",
      "[16,   117] loss: 0.162\n",
      "[16,   118] loss: 0.130\n",
      "[16,   119] loss: 0.156\n",
      "[16,   120] loss: 0.202\n",
      "[16,   121] loss: 0.129\n",
      "[16,   122] loss: 0.064\n",
      "[16,   123] loss: 0.167\n",
      "[16,   124] loss: 0.094\n",
      "[16,   125] loss: 0.090\n",
      "[16,   126] loss: 0.124\n",
      "[16,   127] loss: 0.101\n",
      "[16,   128] loss: 0.058\n",
      "[16,   129] loss: 0.031\n",
      "[16,   130] loss: 0.120\n",
      "[16,   131] loss: 0.096\n",
      "[16,   132] loss: 0.059\n",
      "[16,   133] loss: 0.210\n",
      "[16,   134] loss: 0.130\n",
      "[16,   135] loss: 0.092\n",
      "[16,   136] loss: 0.123\n",
      "[16,   137] loss: 0.044\n",
      "[16,   138] loss: 0.114\n",
      "[16,   139] loss: 0.165\n",
      "[16,   140] loss: 0.133\n",
      "[16,   141] loss: 0.101\n",
      "[16,   142] loss: 0.104\n",
      "[16,   143] loss: 0.140\n",
      "[16,   144] loss: 0.138\n",
      "[16,   145] loss: 0.187\n",
      "[16,   146] loss: 0.119\n",
      "[16,   147] loss: 0.137\n",
      "[16,   148] loss: 0.163\n",
      "[16,   149] loss: 0.107\n",
      "[16,   150] loss: 0.091\n",
      "[16,   151] loss: 0.075\n",
      "[16,   152] loss: 0.190\n",
      "[16,   153] loss: 0.091\n",
      "[16,   154] loss: 0.114\n",
      "[16,   155] loss: 0.216\n",
      "[16,   156] loss: 0.199\n",
      "[16,   157] loss: 0.127\n",
      "[16,   158] loss: 0.174\n",
      "[16,   159] loss: 0.094\n",
      "[16,   160] loss: 0.030\n",
      "[16,   161] loss: 0.146\n",
      "[16,   162] loss: 0.035\n",
      "[16,   163] loss: 0.123\n",
      "[16,   164] loss: 0.072\n",
      "[16,   165] loss: 0.053\n",
      "[16,   166] loss: 0.083\n",
      "[16,   167] loss: 0.209\n",
      "[16,   168] loss: 0.104\n",
      "[16,   169] loss: 0.080\n",
      "[16,   170] loss: 0.062\n",
      "[16,   171] loss: 0.200\n",
      "[16,   172] loss: 0.104\n",
      "[16,   173] loss: 0.082\n",
      "[16,   174] loss: 0.074\n",
      "[16,   175] loss: 0.175\n",
      "[16,   176] loss: 0.139\n",
      "[16,   177] loss: 0.096\n",
      "[16,   178] loss: 0.163\n",
      "[16,   179] loss: 0.184\n",
      "[16,   180] loss: 0.258\n",
      "[16,   181] loss: 0.120\n",
      "[16,   182] loss: 0.228\n",
      "[16,   183] loss: 0.153\n",
      "[16,   184] loss: 0.138\n",
      "[16,   185] loss: 0.064\n",
      "[16,   186] loss: 0.114\n",
      "[16,   187] loss: 0.198\n",
      "[16,   188] loss: 0.141\n",
      "[16,   189] loss: 0.101\n",
      "[16,   190] loss: 0.139\n",
      "[16,   191] loss: 0.178\n",
      "[16,   192] loss: 0.175\n",
      "[16,   193] loss: 0.118\n",
      "[16,   194] loss: 0.113\n",
      "[16,   195] loss: 0.214\n",
      "[16,   196] loss: 0.123\n",
      "[16,   197] loss: 0.167\n",
      "[16,   198] loss: 0.109\n",
      "[16,   199] loss: 0.142\n",
      "[16,   200] loss: 0.143\n",
      "[16,   201] loss: 0.193\n",
      "[16,   202] loss: 0.156\n",
      "[16,   203] loss: 0.091\n",
      "[16,   204] loss: 0.166\n",
      "[16,   205] loss: 0.158\n",
      "[16,   206] loss: 0.169\n",
      "[16,   207] loss: 0.130\n",
      "[16,   208] loss: 0.231\n",
      "[16,   209] loss: 0.109\n",
      "[16,   210] loss: 0.144\n",
      "[16,   211] loss: 0.154\n",
      "[16,   212] loss: 0.181\n",
      "[16,   213] loss: 0.147\n",
      "[16,   214] loss: 0.167\n",
      "[16,   215] loss: 0.161\n",
      "[16,   216] loss: 0.130\n",
      "[16,   217] loss: 0.079\n",
      "[16,   218] loss: 0.133\n",
      "[16,   219] loss: 0.133\n",
      "[16,   220] loss: 0.176\n",
      "[16,   221] loss: 0.104\n",
      "[16,   222] loss: 0.065\n",
      "[16,   223] loss: 0.175\n",
      "[16,   224] loss: 0.112\n",
      "[16,   225] loss: 0.092\n",
      "[16,   226] loss: 0.181\n",
      "[16,   227] loss: 0.087\n",
      "[16,   228] loss: 0.114\n",
      "[16,   229] loss: 0.205\n",
      "[16,   230] loss: 0.161\n",
      "[16,   231] loss: 0.063\n",
      "[16,   232] loss: 0.164\n",
      "[16,   233] loss: 0.168\n",
      "[16,   234] loss: 0.176\n",
      "[16,   235] loss: 0.169\n",
      "[16,   236] loss: 0.185\n",
      "[16,   237] loss: 0.158\n",
      "[16,   238] loss: 0.071\n",
      "[16,   239] loss: 0.106\n",
      "[16,   240] loss: 0.168\n",
      "[16,   241] loss: 0.181\n",
      "[16,   242] loss: 0.104\n",
      "[16,   243] loss: 0.096\n",
      "[16,   244] loss: 0.106\n",
      "[16,   245] loss: 0.130\n",
      "[16,   246] loss: 0.131\n",
      "[16,   247] loss: 0.149\n",
      "[16,   248] loss: 0.165\n",
      "[16,   249] loss: 0.134\n",
      "[16,   250] loss: 0.129\n",
      "[16,   251] loss: 0.120\n",
      "[16,   252] loss: 0.064\n",
      "[16,   253] loss: 0.121\n",
      "[16,   254] loss: 0.125\n",
      "[16,   255] loss: 0.145\n",
      "[16,   256] loss: 0.090\n",
      "[16,   257] loss: 0.180\n",
      "[16,   258] loss: 0.181\n",
      "[16,   259] loss: 0.085\n",
      "[16,   260] loss: 0.141\n",
      "[16,   261] loss: 0.171\n",
      "[16,   262] loss: 0.192\n",
      "[16,   263] loss: 0.038\n",
      "[16,   264] loss: 0.179\n",
      "[16,   265] loss: 0.136\n",
      "[16,   266] loss: 0.182\n",
      "[16,   267] loss: 0.120\n",
      "[16,   268] loss: 0.210\n",
      "[16,   269] loss: 0.157\n",
      "[16,   270] loss: 0.193\n",
      "[16,   271] loss: 0.151\n",
      "[16,   272] loss: 0.054\n",
      "[16,   273] loss: 0.056\n",
      "[16,   274] loss: 0.190\n",
      "[16,   275] loss: 0.074\n",
      "[16,   276] loss: 0.156\n",
      "[16,   277] loss: 0.084\n",
      "[16,   278] loss: 0.100\n",
      "[16,   279] loss: 0.145\n",
      "[16,   280] loss: 0.090\n",
      "[16,   281] loss: 0.155\n",
      "[16,   282] loss: 0.161\n",
      "[16,   283] loss: 0.174\n",
      "[16,   284] loss: 0.188\n",
      "[16,   285] loss: 0.147\n",
      "[16,   286] loss: 0.108\n",
      "[16,   287] loss: 0.091\n",
      "[16,   288] loss: 0.156\n",
      "[16,   289] loss: 0.056\n",
      "[16,   290] loss: 0.146\n",
      "[16,   291] loss: 0.161\n",
      "[16,   292] loss: 0.104\n",
      "[16,   293] loss: 0.109\n",
      "[16,   294] loss: 0.194\n",
      "[16,   295] loss: 0.193\n",
      "[16,   296] loss: 0.040\n",
      "[16,   297] loss: 0.240\n",
      "[16,   298] loss: 0.065\n",
      "[16,   299] loss: 0.167\n",
      "[16,   300] loss: 0.075\n",
      "[16,   301] loss: 0.185\n",
      "[16,   302] loss: 0.159\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "LOSS train 0.13014579550147254 valid 0.15112980585545302\n",
      "[17,     1] loss: 0.192\n",
      "[17,     2] loss: 0.147\n",
      "[17,     3] loss: 0.108\n",
      "[17,     4] loss: 0.146\n",
      "[17,     5] loss: 0.141\n",
      "[17,     6] loss: 0.139\n",
      "[17,     7] loss: 0.208\n",
      "[17,     8] loss: 0.170\n",
      "[17,     9] loss: 0.149\n",
      "[17,    10] loss: 0.118\n",
      "[17,    11] loss: 0.171\n",
      "[17,    12] loss: 0.172\n",
      "[17,    13] loss: 0.144\n",
      "[17,    14] loss: 0.086\n",
      "[17,    15] loss: 0.020\n",
      "[17,    16] loss: 0.114\n",
      "[17,    17] loss: 0.112\n",
      "[17,    18] loss: 0.144\n",
      "[17,    19] loss: 0.113\n",
      "[17,    20] loss: 0.182\n",
      "[17,    21] loss: 0.148\n",
      "[17,    22] loss: 0.016\n",
      "[17,    23] loss: 0.189\n",
      "[17,    24] loss: 0.117\n",
      "[17,    25] loss: 0.113\n",
      "[17,    26] loss: 0.075\n",
      "[17,    27] loss: 0.212\n",
      "[17,    28] loss: 0.199\n",
      "[17,    29] loss: 0.172\n",
      "[17,    30] loss: 0.100\n",
      "[17,    31] loss: 0.114\n",
      "[17,    32] loss: 0.061\n",
      "[17,    33] loss: 0.141\n",
      "[17,    34] loss: 0.124\n",
      "[17,    35] loss: 0.064\n",
      "[17,    36] loss: 0.056\n",
      "[17,    37] loss: 0.169\n",
      "[17,    38] loss: 0.134\n",
      "[17,    39] loss: 0.175\n",
      "[17,    40] loss: 0.150\n",
      "[17,    41] loss: 0.079\n",
      "[17,    42] loss: 0.149\n",
      "[17,    43] loss: 0.096\n",
      "[17,    44] loss: 0.191\n",
      "[17,    45] loss: 0.039\n",
      "[17,    46] loss: 0.155\n",
      "[17,    47] loss: 0.129\n",
      "[17,    48] loss: 0.069\n",
      "[17,    49] loss: 0.104\n",
      "[17,    50] loss: 0.140\n",
      "[17,    51] loss: 0.095\n",
      "[17,    52] loss: 0.071\n",
      "[17,    53] loss: 0.110\n",
      "[17,    54] loss: 0.073\n",
      "[17,    55] loss: 0.071\n",
      "[17,    56] loss: 0.115\n",
      "[17,    57] loss: 0.140\n",
      "[17,    58] loss: 0.117\n",
      "[17,    59] loss: 0.137\n",
      "[17,    60] loss: 0.102\n",
      "[17,    61] loss: 0.181\n",
      "[17,    62] loss: 0.060\n",
      "[17,    63] loss: 0.098\n",
      "[17,    64] loss: 0.157\n",
      "[17,    65] loss: 0.067\n",
      "[17,    66] loss: 0.121\n",
      "[17,    67] loss: 0.124\n",
      "[17,    68] loss: 0.154\n",
      "[17,    69] loss: 0.168\n",
      "[17,    70] loss: 0.143\n",
      "[17,    71] loss: 0.189\n",
      "[17,    72] loss: 0.079\n",
      "[17,    73] loss: 0.155\n",
      "[17,    74] loss: 0.105\n",
      "[17,    75] loss: 0.031\n",
      "[17,    76] loss: 0.147\n",
      "[17,    77] loss: 0.220\n",
      "[17,    78] loss: 0.152\n",
      "[17,    79] loss: 0.178\n",
      "[17,    80] loss: 0.108\n",
      "[17,    81] loss: 0.119\n",
      "[17,    82] loss: 0.121\n",
      "[17,    83] loss: 0.149\n",
      "[17,    84] loss: 0.069\n",
      "[17,    85] loss: 0.125\n",
      "[17,    86] loss: 0.097\n",
      "[17,    87] loss: 0.117\n",
      "[17,    88] loss: 0.086\n",
      "[17,    89] loss: 0.115\n",
      "[17,    90] loss: 0.128\n",
      "[17,    91] loss: 0.031\n",
      "[17,    92] loss: 0.128\n",
      "[17,    93] loss: 0.114\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17,    94] loss: 0.111\n",
      "[17,    95] loss: 0.133\n",
      "[17,    96] loss: 0.178\n",
      "[17,    97] loss: 0.116\n",
      "[17,    98] loss: 0.076\n",
      "[17,    99] loss: 0.142\n",
      "[17,   100] loss: 0.067\n",
      "[17,   101] loss: 0.150\n",
      "[17,   102] loss: 0.138\n",
      "[17,   103] loss: 0.171\n",
      "[17,   104] loss: 0.213\n",
      "[17,   105] loss: 0.204\n",
      "[17,   106] loss: 0.066\n",
      "[17,   107] loss: 0.077\n",
      "[17,   108] loss: 0.199\n",
      "[17,   109] loss: 0.070\n",
      "[17,   110] loss: 0.029\n",
      "[17,   111] loss: 0.073\n",
      "[17,   112] loss: 0.161\n",
      "[17,   113] loss: 0.134\n",
      "[17,   114] loss: 0.078\n",
      "[17,   115] loss: 0.149\n",
      "[17,   116] loss: 0.109\n",
      "[17,   117] loss: 0.162\n",
      "[17,   118] loss: 0.124\n",
      "[17,   119] loss: 0.150\n",
      "[17,   120] loss: 0.199\n",
      "[17,   121] loss: 0.129\n",
      "[17,   122] loss: 0.063\n",
      "[17,   123] loss: 0.170\n",
      "[17,   124] loss: 0.093\n",
      "[17,   125] loss: 0.088\n",
      "[17,   126] loss: 0.116\n",
      "[17,   127] loss: 0.099\n",
      "[17,   128] loss: 0.058\n",
      "[17,   129] loss: 0.034\n",
      "[17,   130] loss: 0.119\n",
      "[17,   131] loss: 0.094\n",
      "[17,   132] loss: 0.056\n",
      "[17,   133] loss: 0.207\n",
      "[17,   134] loss: 0.127\n",
      "[17,   135] loss: 0.090\n",
      "[17,   136] loss: 0.120\n",
      "[17,   137] loss: 0.045\n",
      "[17,   138] loss: 0.114\n",
      "[17,   139] loss: 0.152\n",
      "[17,   140] loss: 0.131\n",
      "[17,   141] loss: 0.103\n",
      "[17,   142] loss: 0.109\n",
      "[17,   143] loss: 0.140\n",
      "[17,   144] loss: 0.137\n",
      "[17,   145] loss: 0.186\n",
      "[17,   146] loss: 0.120\n",
      "[17,   147] loss: 0.142\n",
      "[17,   148] loss: 0.162\n",
      "[17,   149] loss: 0.108\n",
      "[17,   150] loss: 0.094\n",
      "[17,   151] loss: 0.076\n",
      "[17,   152] loss: 0.190\n",
      "[17,   153] loss: 0.088\n",
      "[17,   154] loss: 0.112\n",
      "[17,   155] loss: 0.216\n",
      "[17,   156] loss: 0.199\n",
      "[17,   157] loss: 0.129\n",
      "[17,   158] loss: 0.175\n",
      "[17,   159] loss: 0.098\n",
      "[17,   160] loss: 0.033\n",
      "[17,   161] loss: 0.145\n",
      "[17,   162] loss: 0.035\n",
      "[17,   163] loss: 0.123\n",
      "[17,   164] loss: 0.068\n",
      "[17,   165] loss: 0.053\n",
      "[17,   166] loss: 0.079\n",
      "[17,   167] loss: 0.209\n",
      "[17,   168] loss: 0.103\n",
      "[17,   169] loss: 0.077\n",
      "[17,   170] loss: 0.056\n",
      "[17,   171] loss: 0.195\n",
      "[17,   172] loss: 0.098\n",
      "[17,   173] loss: 0.078\n",
      "[17,   174] loss: 0.069\n",
      "[17,   175] loss: 0.175\n",
      "[17,   176] loss: 0.138\n",
      "[17,   177] loss: 0.096\n",
      "[17,   178] loss: 0.159\n",
      "[17,   179] loss: 0.179\n",
      "[17,   180] loss: 0.248\n",
      "[17,   181] loss: 0.117\n",
      "[17,   182] loss: 0.223\n",
      "[17,   183] loss: 0.153\n",
      "[17,   184] loss: 0.136\n",
      "[17,   185] loss: 0.063\n",
      "[17,   186] loss: 0.111\n",
      "[17,   187] loss: 0.187\n",
      "[17,   188] loss: 0.139\n",
      "[17,   189] loss: 0.097\n",
      "[17,   190] loss: 0.136\n",
      "[17,   191] loss: 0.168\n",
      "[17,   192] loss: 0.173\n",
      "[17,   193] loss: 0.117\n",
      "[17,   194] loss: 0.108\n",
      "[17,   195] loss: 0.204\n",
      "[17,   196] loss: 0.112\n",
      "[17,   197] loss: 0.158\n",
      "[17,   198] loss: 0.107\n",
      "[17,   199] loss: 0.147\n",
      "[17,   200] loss: 0.151\n",
      "[17,   201] loss: 0.193\n",
      "[17,   202] loss: 0.150\n",
      "[17,   203] loss: 0.080\n",
      "[17,   204] loss: 0.156\n",
      "[17,   205] loss: 0.154\n",
      "[17,   206] loss: 0.168\n",
      "[17,   207] loss: 0.133\n",
      "[17,   208] loss: 0.234\n",
      "[17,   209] loss: 0.115\n",
      "[17,   210] loss: 0.142\n",
      "[17,   211] loss: 0.149\n",
      "[17,   212] loss: 0.177\n",
      "[17,   213] loss: 0.142\n",
      "[17,   214] loss: 0.163\n",
      "[17,   215] loss: 0.162\n",
      "[17,   216] loss: 0.133\n",
      "[17,   217] loss: 0.079\n",
      "[17,   218] loss: 0.135\n",
      "[17,   219] loss: 0.131\n",
      "[17,   220] loss: 0.175\n",
      "[17,   221] loss: 0.098\n",
      "[17,   222] loss: 0.064\n",
      "[17,   223] loss: 0.173\n",
      "[17,   224] loss: 0.111\n",
      "[17,   225] loss: 0.094\n",
      "[17,   226] loss: 0.178\n",
      "[17,   227] loss: 0.079\n",
      "[17,   228] loss: 0.114\n",
      "[17,   229] loss: 0.193\n",
      "[17,   230] loss: 0.157\n",
      "[17,   231] loss: 0.063\n",
      "[17,   232] loss: 0.163\n",
      "[17,   233] loss: 0.168\n",
      "[17,   234] loss: 0.179\n",
      "[17,   235] loss: 0.168\n",
      "[17,   236] loss: 0.186\n",
      "[17,   237] loss: 0.157\n",
      "[17,   238] loss: 0.072\n",
      "[17,   239] loss: 0.098\n",
      "[17,   240] loss: 0.163\n",
      "[17,   241] loss: 0.179\n",
      "[17,   242] loss: 0.102\n",
      "[17,   243] loss: 0.095\n",
      "[17,   244] loss: 0.105\n",
      "[17,   245] loss: 0.128\n",
      "[17,   246] loss: 0.128\n",
      "[17,   247] loss: 0.147\n",
      "[17,   248] loss: 0.165\n",
      "[17,   249] loss: 0.133\n",
      "[17,   250] loss: 0.127\n",
      "[17,   251] loss: 0.118\n",
      "[17,   252] loss: 0.064\n",
      "[17,   253] loss: 0.121\n",
      "[17,   254] loss: 0.123\n",
      "[17,   255] loss: 0.143\n",
      "[17,   256] loss: 0.089\n",
      "[17,   257] loss: 0.180\n",
      "[17,   258] loss: 0.179\n",
      "[17,   259] loss: 0.085\n",
      "[17,   260] loss: 0.140\n",
      "[17,   261] loss: 0.170\n",
      "[17,   262] loss: 0.191\n",
      "[17,   263] loss: 0.037\n",
      "[17,   264] loss: 0.178\n",
      "[17,   265] loss: 0.134\n",
      "[17,   266] loss: 0.181\n",
      "[17,   267] loss: 0.120\n",
      "[17,   268] loss: 0.206\n",
      "[17,   269] loss: 0.155\n",
      "[17,   270] loss: 0.192\n",
      "[17,   271] loss: 0.151\n",
      "[17,   272] loss: 0.055\n",
      "[17,   273] loss: 0.057\n",
      "[17,   274] loss: 0.190\n",
      "[17,   275] loss: 0.072\n",
      "[17,   276] loss: 0.155\n",
      "[17,   277] loss: 0.082\n",
      "[17,   278] loss: 0.099\n",
      "[17,   279] loss: 0.144\n",
      "[17,   280] loss: 0.090\n",
      "[17,   281] loss: 0.154\n",
      "[17,   282] loss: 0.161\n",
      "[17,   283] loss: 0.172\n",
      "[17,   284] loss: 0.187\n",
      "[17,   285] loss: 0.147\n",
      "[17,   286] loss: 0.107\n",
      "[17,   287] loss: 0.089\n",
      "[17,   288] loss: 0.156\n",
      "[17,   289] loss: 0.055\n",
      "[17,   290] loss: 0.146\n",
      "[17,   291] loss: 0.157\n",
      "[17,   292] loss: 0.095\n",
      "[17,   293] loss: 0.109\n",
      "[17,   294] loss: 0.193\n",
      "[17,   295] loss: 0.191\n",
      "[17,   296] loss: 0.040\n",
      "[17,   297] loss: 0.239\n",
      "[17,   298] loss: 0.059\n",
      "[17,   299] loss: 0.165\n",
      "[17,   300] loss: 0.070\n",
      "[17,   301] loss: 0.177\n",
      "[17,   302] loss: 0.157\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "LOSS train 0.12843277128968414 valid 0.1405178212489073\n",
      "[18,     1] loss: 0.190\n",
      "[18,     2] loss: 0.146\n",
      "[18,     3] loss: 0.106\n",
      "[18,     4] loss: 0.140\n",
      "[18,     5] loss: 0.138\n",
      "[18,     6] loss: 0.137\n",
      "[18,     7] loss: 0.205\n",
      "[18,     8] loss: 0.171\n",
      "[18,     9] loss: 0.150\n",
      "[18,    10] loss: 0.123\n",
      "[18,    11] loss: 0.172\n",
      "[18,    12] loss: 0.171\n",
      "[18,    13] loss: 0.142\n",
      "[18,    14] loss: 0.088\n",
      "[18,    15] loss: 0.021\n",
      "[18,    16] loss: 0.116\n",
      "[18,    17] loss: 0.117\n",
      "[18,    18] loss: 0.145\n",
      "[18,    19] loss: 0.110\n",
      "[18,    20] loss: 0.180\n",
      "[18,    21] loss: 0.146\n",
      "[18,    22] loss: 0.018\n",
      "[18,    23] loss: 0.187\n",
      "[18,    24] loss: 0.118\n",
      "[18,    25] loss: 0.121\n",
      "[18,    26] loss: 0.085\n",
      "[18,    27] loss: 0.208\n",
      "[18,    28] loss: 0.197\n",
      "[18,    29] loss: 0.166\n",
      "[18,    30] loss: 0.096\n",
      "[18,    31] loss: 0.117\n",
      "[18,    32] loss: 0.069\n",
      "[18,    33] loss: 0.139\n",
      "[18,    34] loss: 0.119\n",
      "[18,    35] loss: 0.061\n",
      "[18,    36] loss: 0.056\n",
      "[18,    37] loss: 0.176\n",
      "[18,    38] loss: 0.134\n",
      "[18,    39] loss: 0.175\n",
      "[18,    40] loss: 0.149\n",
      "[18,    41] loss: 0.074\n",
      "[18,    42] loss: 0.149\n",
      "[18,    43] loss: 0.089\n",
      "[18,    44] loss: 0.190\n",
      "[18,    45] loss: 0.042\n",
      "[18,    46] loss: 0.152\n",
      "[18,    47] loss: 0.131\n",
      "[18,    48] loss: 0.067\n",
      "[18,    49] loss: 0.104\n",
      "[18,    50] loss: 0.138\n",
      "[18,    51] loss: 0.095\n",
      "[18,    52] loss: 0.069\n",
      "[18,    53] loss: 0.109\n",
      "[18,    54] loss: 0.071\n",
      "[18,    55] loss: 0.070\n",
      "[18,    56] loss: 0.114\n",
      "[18,    57] loss: 0.136\n",
      "[18,    58] loss: 0.115\n",
      "[18,    59] loss: 0.135\n",
      "[18,    60] loss: 0.102\n",
      "[18,    61] loss: 0.179\n",
      "[18,    62] loss: 0.058\n",
      "[18,    63] loss: 0.097\n",
      "[18,    64] loss: 0.154\n",
      "[18,    65] loss: 0.066\n",
      "[18,    66] loss: 0.121\n",
      "[18,    67] loss: 0.123\n",
      "[18,    68] loss: 0.152\n",
      "[18,    69] loss: 0.167\n",
      "[18,    70] loss: 0.142\n",
      "[18,    71] loss: 0.183\n",
      "[18,    72] loss: 0.075\n",
      "[18,    73] loss: 0.155\n",
      "[18,    74] loss: 0.105\n",
      "[18,    75] loss: 0.031\n",
      "[18,    76] loss: 0.147\n",
      "[18,    77] loss: 0.219\n",
      "[18,    78] loss: 0.155\n",
      "[18,    79] loss: 0.176\n",
      "[18,    80] loss: 0.107\n",
      "[18,    81] loss: 0.118\n",
      "[18,    82] loss: 0.119\n",
      "[18,    83] loss: 0.148\n",
      "[18,    84] loss: 0.064\n",
      "[18,    85] loss: 0.124\n",
      "[18,    86] loss: 0.095\n",
      "[18,    87] loss: 0.121\n",
      "[18,    88] loss: 0.086\n",
      "[18,    89] loss: 0.114\n",
      "[18,    90] loss: 0.126\n",
      "[18,    91] loss: 0.032\n",
      "[18,    92] loss: 0.125\n",
      "[18,    93] loss: 0.112\n",
      "[18,    94] loss: 0.108\n",
      "[18,    95] loss: 0.132\n",
      "[18,    96] loss: 0.177\n",
      "[18,    97] loss: 0.115\n",
      "[18,    98] loss: 0.075\n",
      "[18,    99] loss: 0.134\n",
      "[18,   100] loss: 0.061\n",
      "[18,   101] loss: 0.149\n",
      "[18,   102] loss: 0.137\n",
      "[18,   103] loss: 0.169\n",
      "[18,   104] loss: 0.205\n",
      "[18,   105] loss: 0.202\n",
      "[18,   106] loss: 0.064\n",
      "[18,   107] loss: 0.072\n",
      "[18,   108] loss: 0.200\n"
     ]
    }
   ],
   "source": [
    "# Entrenamiento #\n",
    "\n",
    "# Loss and optimizer\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(unet.parameters(), lr=0.0001)\n",
    "\n",
    "# Codigo entrenamiento Martin\n",
    "\n",
    "# defino batches\n",
    "\n",
    "best_vloss = 1000000000\n",
    "\n",
    "batchSizeTrain = 4\n",
    "batchSizeValid = 4\n",
    "numBatchesTrain = np.round(trainingSet['input'].shape[0] / batchSizeTrain).astype(int)\n",
    "numBatchesValid = np.round(validSet['input'].shape[0] / batchSizeValid).astype(int)\n",
    "\n",
    "# Show dev set loss every showDevLossStep batches:\n",
    "showDevLossStep = 4\n",
    "\n",
    "printStep = 1\n",
    "# figImages, axs = plt.subplots(3, 1,figsize=(20,20))\n",
    "# figLoss, axLoss = plt.subplots(1, 1,figsize=(5,5))\n",
    "\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "# Train\n",
    "loss_values = []\n",
    "lossValuesTrainingSet = []\n",
    "iterationNumbers = []\n",
    "lossValuesDevSet = []\n",
    "iterationNumbersForDevSet = []\n",
    "lossValuesTrainingSetEpoch = []\n",
    "\n",
    "lossValuesEpoch = []\n",
    "lossValuesDevSetAllEpoch = []\n",
    "\n",
    "iter = 0\n",
    "\n",
    "EPOCHS = 20\n",
    "\n",
    "for epoch in range(EPOCHS):  # loop over the dataset multiple times\n",
    "    \n",
    "    lossValuesTrainingSetEpoch = []\n",
    "    lossValuesDevSetEpoch = []\n",
    "\n",
    "    running_loss = 0.0\n",
    "\n",
    "    unet.train(True)\n",
    "    for i in range(numBatchesTrain):\n",
    "        # get the inputs\n",
    "\n",
    "        inputs = torch.from_numpy(trainingSet['input'][i * batchSizeTrain:(i + 1) * batchSizeTrain, :, :, :])\n",
    "        gt = torch.from_numpy(trainingSet['output'][i * batchSizeTrain:(i + 1) * batchSizeTrain, :, :, :])\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = unet(inputs)\n",
    "        loss = criterion(outputs, gt)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        # Save loss values:\n",
    "        lossValuesTrainingSet.append(loss.item())\n",
    "        lossValuesTrainingSetEpoch.append(loss.item())\n",
    "        iterationNumbers.append(iter)\n",
    "\n",
    "        if i % printStep == (printStep - 1):  # print every printStep mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss))\n",
    "            running_loss = 0.0\n",
    "\n",
    "            # Show input images:\n",
    "            # plt.figure(figImages)\n",
    "            # plt.axes(axs[0])\n",
    "            # imshow(torchvision.utils.make_grid(inputs, normalize=True))\n",
    "            # axs[0].set_title('Input Batch {0}'.format(i))\n",
    "            # plt.axes(axs[1])\n",
    "            # imshow(torchvision.utils.make_grid(outputs, normalize=True))\n",
    "            # axs[1].set_title('Output Epoch {0}'.format(epoch))\n",
    "            # plt.axes(axs[2])\n",
    "            # imshow(torchvision.utils.make_grid(gt, normalize=True))\n",
    "            # axs[2].set_title('Ground Truth')\n",
    "            # Show loss:\n",
    "            # plt.figure(figLoss)\n",
    "            # axLoss.plot(iterationNumbers, lossValuesTrainingSet)\n",
    "            # axLoss.plot(iterationNumbersForDevSet, lossValuesDevSet)\n",
    "            # plt.draw()\n",
    "            # plt.pause(0.0001)\n",
    "\n",
    "            # Update iteration number:\n",
    "        iter = iter + 1\n",
    "\n",
    "    lossValuesEpoch.append(np.mean(lossValuesTrainingSetEpoch))\n",
    "    unet.train(False)\n",
    "    running_vloss = 0.0\n",
    "\n",
    "\n",
    "    for i in range(numBatchesValid):\n",
    "        print(i)\n",
    "\n",
    "        vinputs = torch.from_numpy(validSet['input'][i * batchSizeValid:(i + 1) * batchSizeValid, :, :, :])\n",
    "        vgt = torch.from_numpy(validSet['output'][i * batchSizeValid:(i + 1) * batchSizeValid, :, :, :])\n",
    "\n",
    "        voutputs = unet(vinputs)\n",
    "        vloss = criterion(voutputs, vgt)\n",
    "        vloss.backward()\n",
    "        running_vloss += vloss\n",
    "\n",
    "        lossValuesDevSet.append(vloss.item())\n",
    "        \n",
    "        lossValuesDevSetEpoch.append(vloss.item())\n",
    "\n",
    "\n",
    "    avg_vloss = np.mean(lossValuesDevSet)\n",
    "    lossValuesDevSetAllEpoch.append(np.mean(lossValuesDevSetEpoch))\n",
    "\n",
    "    if avg_vloss < best_vloss:\n",
    "        best_vloss = avg_vloss\n",
    "        model_path = 'modelDataSet2_{}_{}'.format(timestamp, epoch)\n",
    "        torch.save(unet.state_dict(), model_path)\n",
    "\n",
    "    print('LOSS train {} valid {}'.format(lossValuesEpoch[-1], lossValuesDevSetAllEpoch[-1]))\n",
    "    # CALCULAR PROMEDIO DE TODOS O VARIOS BATCH\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1698dd77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loss')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(lossValuesDevSet)\n",
    "plt.xlabel(\"Batch\", size = 16,)\n",
    "plt.ylabel(\"Loss\", size = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b2c258f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loss')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEPCAYAAACp/QjLAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAwwklEQVR4nO3dd3xW5f3/8deHQNibiLIDMsTBiiCIWxDEqnVUsNbZWhe16q8FHKioFaut9duvX6u1Vq2DukWk4q6ogEQZMgTCkilhywxJrt8f5yQ598i4b5L7Trjfz8cjD864zjnXSW7uz7nGuS5zziEiIhJUK9kZEBGR6kfBQUREIig4iIhIBAUHERGJoOAgIiIRFBxERCRCwoODmQ0zsyVmlmNmY6Ps72Bmn5jZHDObb2ZnJzqPIiKpzhL5noOZpQFLgSHAWmA2MMo5tyiQ5ilgjnPuCTPrCUx1znVKWCZFRCThJYf+QI5zboVzLg+YBJwXlsYBTfzlpsD6BOZPRESA2gm+XltgTWB9LTAgLM09wPtmNhpoCJxZ3klbtWrlOnXqVElZFBFJDV9//fVm51xGtH2JDg4VMQp41jn3JzMbCPzLzI5xzhUGE5nZtcC1AB06dCA7OzsJWRURqbnMbHVp+xJdrbQOaB9Yb+dvC7oGeAXAOTcDqAe0Cj+Rc+4p51yWcy4rIyNq4BMRkTglOjjMBrqaWaaZpQMjgclhab4HzgAws6PwgkNuQnMpIpLiEhocnHP5wE3ANGAx8IpzbqGZTTCzc/1ktwG/MrN5wMvAlU5Dx4qIJFTC2xycc1OBqWHbxgeWFwEnJjpfIiJSQm9Ii4hIBAUHERGJoOAgIiIRFByieHvuOn7cdyDZ2RARSRoFhzAL1+/g5klzGfv6t8nOiohI0ig4hNmbVwDAxp37kpwTEZHkUXAQEZEICg4iIhJBwUFERCIoOIiISAQFBxERiaDgICIiERQcREQkgoKDiIhEUHAQEZEICg4iIhJBwaEUmnxORFJZwoODmQ0zsyVmlmNmY6Psf9TM5vo/S81se6LzKCKS6hI6TaiZpQGPA0OAtcBsM5vsTw0KgHPulkD60UCfROYxcO1kXFZEpFpIdMmhP5DjnFvhnMsDJgHnlZF+FPByQnImIiLFEh0c2gJrAutr/W0RzKwjkAl8nIB8iYhIQHVukB4JvOacK4i208yuNbNsM8vOzc1NcNZERA5tiQ4O64D2gfV2/rZoRlJGlZJz7innXJZzLisjI6MSsygiIokODrOBrmaWaWbpeAFgcngiM+sBNAdmJDh/IiJCgoODcy4fuAmYBiwGXnHOLTSzCWZ2biDpSGCS08sGIiJJkdCurADOuanA1LBt48PW70lknkREJFR1bpAWEZEkSengsHrLbu6ZvJDCQtVeiYgEpXRwuP6Fb3j2y1Us3rgz2VkREalWUjo4FPrt3UbkUBlqCxeRVJbSwUFERKJTcAAckaUEDbwnIqkspYODAoCISHQpHRxERCQ6BQdAbc8iIqEUHEREJIKCA6CmBxGRUAoOqFpJRCRcSgcHFRhERKJL6eAgIiLRKTiIiEgEBQcREYmg4FAKDbwnIqlMwUFERCIkPDiY2TAzW2JmOWY2tpQ0PzOzRWa20MxeSnQe/Twk47IiItVCQueQNrM04HFgCLAWmG1mk51ziwJpugLjgBOdc9vM7LCqy09VnVlEpGZLdMmhP5DjnFvhnMsDJgHnhaX5FfC4c24bgHNuU4LzKCKS8hIdHNoCawLra/1tQd2Abmb2hZnNNLNh0U5kZteaWbaZZefm5h5UptT2LCISqjo2SNcGugKnAqOAv5tZs/BEzrmnnHNZzrmsjIyMuC6kaiURkegSHRzWAe0D6+38bUFrgcnOuQPOuZXAUrxgUekWrNsJwHcbd1bF6UVEaqxEB4fZQFczyzSzdGAkMDkszVt4pQbMrBVeNdOKqszUvLXbq/L0IiI1TkKDg3MuH7gJmAYsBl5xzi00swlmdq6fbBqwxcwWAZ8Av3PObUlkPkVEUl1Cu7ICOOemAlPDto0PLDvgVv8nIUzjs4qIhKiODdIiIpJkCg6l0NhKIpLKFBwAR0kgUPdWEREFByC0zUEFBhERBYdSaeA9EUllCg4iIhJBwUFERCIoOIiISAQFBxERiaDgICIiERQcREQkgoKDiIhEUHBAb0WLiIRTcBARkQgKDqXQwHsiksoUHMKoiklERMEhggoMIiJJCA5mNszMlphZjpmNjbL/SjPLNbO5/s8vqzpPma0aRstnVV9WRKTaSmhwMLM04HFgONATGGVmPaMk/bdzrrf/83RV5efU7hkAdGzZoKouISJSIyW65NAfyHHOrXDO5QGTgPMSnIdiKhuIiESX6ODQFlgTWF/rbwt3oZnNN7PXzKx9tBOZ2bVmlm1m2bm5uVWRVxGRlFUdG6TfATo5544DPgCei5bIOfeUcy7LOZeVkZFxUBeszEboDTv28uO+A5V3QhGRJEh0cFgHBEsC7fxtxZxzW5xz+/3Vp4F+VZWZqmh0Hvjgxwx/bHqln1dEJJESHRxmA13NLNPM0oGRwORgAjM7IrB6LrA4gfmrFGu37U12FkREDkrtRF7MOZdvZjcB04A04Bnn3EIzmwBkO+cmA78xs3OBfGArcGUi8ygiIgkODgDOuanA1LBt4wPL44Bxic6XiIiUqI4N0gkXrUFaYyuJSCpL6eAQrTlaL0aLiKR4cBARkegUHABVIImIhErp4BCtCklNDSIiKR4cygoEGpVVRFJZSgcHERGJLqWDgwoHIiLRpXRwEBGR6BQc0AtvIiLhKiU4mFnLyjhP4qleSUQkmpiCg5n9ysx+F1g/1szWApv8iXcOr/QcJoDKDSIioWItOYwGguNR/xnYDvwWaApMqJRciYhIUsU6KmtH4DsAM2sKnAKc75ybamZbgAcrOX8JEa1ySe0QIpLKYi051AIK/eXBeDUyn/rra4DDKidbiRUMA+reKiISe3BYBozwl0cCXzrn9vjrbfAm56kxFAhERKKLtVrpEeBfZnYF0By4OLDvNGB+ZWVMRESSJ6aSg3PuJbx2hgeB05xzbwR2/wD8tbxzmNkwM1tiZjlmNraMdBeamTOzrFjyGI9g84KaGkRE4pgm1Dn3OfB5lO13l3esmaUBjwNDgLXAbDOb7JxbFJauMXAzMCvW/MWirFolDbwnIqks1vccBpnZOYH1lmb2spl9a2aP+F/+ZekP5DjnVjjn8oBJwHlR0t0HPATsiyV/sVIhQUQkulgbpCcC/QLrDwNnA0uB64Hbyzm+LV6vpiJr/W3FzKwv0N45926MeRMRkUoSa3A4CsgGMLM6wEXALc65C4E7gEsPJjNmVgvvxbrbKpD2Wv+t7Ozc3Nz4rhfXUSIih75Yg0MjYKe/3B9oCEzx178BOpRz/DqgfWC9nb+tSGPgGOBTM1sFnABMjtYo7Zx7yjmX5ZzLysjIiPE2Is52kMeLiBxaYg0O64Be/vJwYIFzbpO/3hzYE/WoErOBrmaWaWbpeO9KTC7a6Zzb4Zxr5Zzr5JzrBMwEznXOZceYzwpRm7OISHSxBoeXgT+Y2WvArcALgX198V6SK5VzLh+4CZgGLAZecc4tNLMJZnZujHkREZEqEmtX1nvwehCdgNc4/WhgXy/g1fJO4JybCkwN2za+lLSnxpi/uOjdBhGRUDEFB+dcAfBAKfvOr4wMVRcaeE9EUlnML8EBmNkxeG9Kt8AbT+lT59zCysxYIgXbHtQOISISY3Aws9rAs8AoQnuCOjN7CbjSL13UKBUtJDw9fQWdMxpyeo/WVZshEZEki7VB+m7gZ8B4IBOo7/87HrjE/7fGsBjfdLj/3cVc/WyVdJwSEalWYq1Wugy43zkXbHdYDTzgD51xFV4AqbGS2dQwY/kWtuzezznHtUleJkREiD04tAG+LGXfl3hvSdc40eJBMgbeG/X3mQAKDiKSdLFWK60HTixl3yB/f42hxmcRkehiLTm8CNxhZoX+8gbgcLw3ne/AG0lVRERquHhegusM3OsvFzHgJWBCpeRKRESSKtaX4PKBS83sAeBkSt5z+Aw4Am/wveMqO5MiIpJYcb0E57/wFvLSm5n1AI6ujEwlWrQeSvmFjoJCR1otNUyISOqJtUH6kFLUIO2i9Feat2Y7Qx79b4JzJCJSPaR0cCjyu1fnR92+Ind3gnMiIlI9KDgAew+UjPih7q0iIhVoczCzzhU81+EHmZeEG3FsG6Z+uzHZ2RARqXYq0iCdQ8Xm0bQKpqs22jWvX7y8ccc+Dm9aL4m5ERGpPioSHK6q8lwkSTCSjX75G169blDS8iIiUp2UGxycc89V5gXNbBjwGJAGPO2cmxi2/zrgRqAA2AVc65xbVJl5KBKc0GfvgQK27NrP4g0/VsWlRERqlLjec4iXP3Lr48AQYC0w28wmh335v+Sc+5uf/lzgz8CwRORv+GPT2fTj/kRcSkSkWkt0b6X+QI5zboVzLg+YBJwXTOCc2xlYbUgVtmOEn1iBQUTEk9CSA9AWWBNYXwsMCE9kZjcCtwLpwOlVlRlNEy0iEl21fM/BOfe4c64LMAa4M1oaM7vWzLLNLDs3NzfeK8WdRxGRQ1mig8M6oH1gvZ2/rTSTgPOj7XDOPeWcy3LOZWVkZMSVGZUcRESiS3RwmA10NbNMM0vHmwdicjCBmXUNrI4AllVVZoKxIS+/sKouIyJS4yQ0OPhDft8ETAMWA6845xaa2QS/ZxLATWa20Mzm4rU7XJGIvC39YVfU7S/N+j4RlxcRqVYS3SCNc24qMDVs2/jA8s2Jy0v5aW5/81suHdCh6jMjIlKNVMsG6UQpVKODiEhUKR0cREQkupQODio4iIhEl9LBIRaFhYokIpI6Ujo4RJsetDR/+XBpFeZERKR6Se3gEENh4PVvynpXT0Tk0JLSwUFERKJL6eCgBmkRkehSOzjE0OZgVoUZERGpZlI7OKjkICISVWoHhxjSVveSw2MfLqPT2HfZd6Ag2VkRkUNAageHQ6jo8K+ZqwD4cV9+cjMiIoeElA4OIiISXUoHh0On3CAiUrlSOjhUNDoUFjqM2Bod9uSpekdEaq6UDg4V7cr69+krYj53z/HTYj5GRKS6SO3gUMGSw/Lc6LPEiYgcqlI6OIiISHQJDw5mNszMlphZjpmNjbL/VjNbZGbzzewjM+tYVXmJpSdrdX/PQUSkMiU0OJhZGvA4MBzoCYwys55hyeYAWc6544DXgD9WVX5iegmuqjIhIlINJbrk0B/Icc6tcM7lAZOA84IJnHOfOOf2+KszgXZVlZlD6SW4IrGMFyUiUppEB4e2wJrA+lp/W2muAf4TbYeZXWtm2WaWnZubG1dmKvo1umTjj+Wm3Z9fwCdLNsWVDxGR6qbaNkib2WVAFvBwtP3Ouaecc1nOuayMjIy4rlHRgsOabXvLrVZ6cOp3XPXP2XHlozLF+j5GkXXb91ZyTkSkJkt0cFgHtA+st/O3hTCzM4E7gHOdc/urKjN9OzSrUDrnHBZokT73fz+P2P/sl6sqMWeJ9d+luZw48WOmfrsh2VkRkWoi0cFhNtDVzDLNLB0YCUwOJjCzPsCTeIGhSutpDmtSr0LpCgodKzfvLl6fv3ZHyP68gsJKzVeiLVq/E4B5a7cnNyMiUm0kNDg45/KBm4BpwGLgFefcQjObYGbn+skeBhoBr5rZXDObXMrpEmZnqox0qrZsEfHVTvQFnXNTgalh28YHls9MdJ6qyv1TFnHnOV5P3fcWbGDl5j1cf2qXJOdKRKR81bZBurqrSAPu05+vLF6+7oVveOi976oyS8BBdmXVyxwi4lNwiNOJEz9mVaAdQkTkUKLgcBCW/vAjUL3moo63K6uISJCCg5SoRkFORJJLwSEBdu1Pkd5OInLIUHCoBOVVK81cvuWgzv/l8s0Mf2w6+/MLDuo85VKNlIj4FBwqQXk9hA52uO8731zA4g07Wbut+g1x4ZzjNy/P4cvlm5OdFRGpRAoOB8Gq4SQP0QLVjr0Hqux6eQWFTJ63niufSf64UiJSeRQcDtKCdTuYvWpbmWkqK4bE0ytq7prt9Lr3fd6dX4Fxk9QgLSK+hL8hfSj51fPZCblOQQxRIbwr67frvHGgvli+mRHHHVGp+YLq1Y1XRCqPSg4JUN67B3n5hdw8aU6p+1dv2VPqvnDh1UoxFVqiJH4le03IoIMikhpSPjg0a1CnSs+/J6/8bqwzV2zh7bnri9d37jvAgnU7yjgidvE+4f/+tfmM+J/plX5eEaneUj443H72UVV6/iue+arcx/fw79df/OMrzvnr5xVIGSm8lLJ9T165x5RnT17pXWgLy4gOnyzZxPRl8c3SJyLJlfJtDnVrV218nL1qG+vLGaQvfC7reWu2V9r1H3l/acUTx1EKKOuQopnxVk0cEft5/d9JdewRJpIKUr7kkNmqYZVf4443F5S5v6JVMxVJtycvn0emLSEvP3wCoti/+SPPEamskkNFLN6wk+W5uyK2j339WzLHTY1yRMXsO1DFLwyKHOJSPjh0zmiU0OsdPf69kPWCQse2g6z6+X7LnuIJif7y4TL+95McXvt6bewnCntIv+3VeeUecrBtDsMfm84Zf/pvxPZ/Z6+J+5zvzFtPj7veKx4YUURil/LBIT0tsb+C3XkFbNq5j8JC71t1/NsLuPWV6F/C4dVNpTn54U+Kn/L3+u0D+YVxTF0adrlpCzaWf0gpeSyvKq0qfbT4B4C4GvV378+nx13/4ePvfqjsbInUKAkPDmY2zMyWmFmOmY2Nsv9kM/vGzPLN7KKqzk96Fbc5RNP/Dx/xyPtLAHhx1velpovnqXyfP/5SRevqt+7O44ed+6LvrMApivIY3oX2uRmrKnT96mZF7m72HSjkT7G01QR0GvsuV/7zq7iOXZ67i2++L/uFSpFESeg3o5mlAY8Dw4GewCgz6xmW7HvgSuClROVrxLGV/3JYef7v0+UUFJb97e8gpD7eAfkFhWXWp3+6xOsdVCvsi720QNP3vg949stVxeszlm8pHkW2IuEleNrzHv+C8W8v8I+NvyF5x56S4T4qWnoKeivQLThWW/0qvoOpLiv6G8TqjD/9lwv+78u4jn1h5mo6jX23uOQYi0079zH4oY/jfp/l69VbK6VXnFQviX5s7g/kOOdWOOfygEnAecEEzrlVzrn5QBz1IvG5//xjEnWpEBf83xdl7t97oIA/+SUMgBte/Iaud/6HHnd57Rbb9+Qxo5QRX2uZRXyxFha6Mqt7nvxsBaP+PpNb/j23Qvl/Z956TnroY8ALBvPWbOf5Gau99YPoZHQgUCVW1pf0i7NWc9nTs0rdH88X/BXPeE/98cSGijTgV5UnPl0OwOZd+8tMl19QyHmPf8Hny0oGSpwyfwNrt+3lucBDQkU557jwiRn8vIy/Q1nuemsBD05dHNexa7ft4bOl6ipdVRIdHNoCwZbGtf62mJnZtWaWbWbZubkH9wFp3jD9oI6P17y1ZdeJH3P3tJAn8JxNu0K+8K56djaj/j4z6rG1rGToDID8QsdfP85h0MSP+d5/43r1luhPih8s+oGtu/PYH/Zl9+XyzeQXlGwb8/p8dvtPqnkFoWk37iilqsq3Zusesu7/sHj91lfm0nvC+xHpShs6ZMfeA9zx5gI+zyl9NNhEv5/3hzi/5IDiv0m8KjKnOUDurv3MW7Od/xfobHAwgbzoz7Nw/c64jv/XzNU8+dmKuI4969HPuPyZ+KrwXsleQ6ex77J2W+y/9715BQx/bDpz4qwCnLliS6n/98qzfvtecjYlpqNFjW2Qds495ZzLcs5lZWRkHPT5Hrzg2ErIVeX7YFH0htF3529gzvfbSz1uzOvfkh+otnrt67U8+qFXj75hx17eW7CRUx7+tNTjP1wcet3sVVu59O+zePTDpTjnuPvtBaW+HLdtdx5vzlkXsm3umu3k/ljyVPtq9pqQp9w3vlnHdr86KfhdFa2r7L4DBfS6tySQLM/dxbg35kdU05VWJbUid1fM755UxMG81b5oQ+W+Ef9lzmaWRemtVfSwsTHQznTvO4uA+O45t5ySSlXaHUcVWpHfvzYf8D6XsVq4fgeLN+zkvimL4rr2yKdmlvl/ryyDJn7MmX/+LK5jY5Xol+DWAe0D6+38bUk3qn8Hxr3xbbKzESH8ibzIjS99U+6xP5Ty9H7nWwvoEmMX3n/6VQ45m3axfc8BnvOrj6L5Tdg4UfkFhZz/+Be0apRO9p1DOOXhT8ocLypYZ19YCJ8tzWXfgQKGHn0405fl8t+wOv2irrA/H9CRY9o2Ld5e1Eaze38BTRvUYekPP3LflEVMD1Sp3HJmN/7n42W8cf0gerVvVubvwDnH9S98w3sLN/LYyN60b9GAvh2aF+8v7wl89/58pi3cSFbHFsxcuYXJc9fTu30z/t9Z3alIC8/SH37kyIxG1ApvUArJo/fvpX41z9L7h7N9Tx6HNakXkcevVm6lf2aLcq9blkuenBH3sdMWlt8brjTxBLLo54n9mKI2uXhysHhDfCWsZEh0cJgNdDWzTLygMBK4NMF5SBnXvxg9gCzbtItlmyJfPAsqerIqUjTk97SFPzCwc9nxPFhCALh78kIANu/KY29eQbkDCY59o+Tac77fVlx1sGriCH7xj9KrEdJqGQvXlzyBFxQ6fv/afN6Ys46VD57N+LcXMHPF1pBjikpTz89YzR8DgaXoPsa+Pp8/X9KbnXsPcNIfPyned/OkucXLvz65M+POPipk6Pb9+QX0vvcDHrroOM7t1YZOY9+NmufPczbz/87qzqYfQwP5Vyu30qxBHbq1bsyHi35g9uqtPPnfFTStX4cdew/w4a0ns2rzHs7s2TriizJY9dftzv8A0KZpPY7PbBEyhtfKzbvI6lgS3MK/7AoLHR99t4mOLRuw/0AhXy7fzMAuLRn98hzuO+8YTu6Wwaoy/pZLf/iRts3qsz+/kO+37qFOmpGeVosm9evQukk9vlq5tdRjd+/PJ62WUa9OGnvy8tm+5wBtmtUv3r++nGrL4ntyjvU79tE2cGzI/ijpDxS4MnsxXum/+R9PYBnz+vzyE5Ui0S92JjQ4OOfyzewmYBqQBjzjnFtoZhOAbOfcZDM7HngTaA78xMzudc4dnYj8XXZCB16YWXrXUvHc807ZxenvNoZWZwS76x4V9hJguPvDiuqXBho6i3pClWb2qq38uK9koMNgSXDl5t1s3lV6j5q0WqFPo99t/JHLn/mKxRt28srsNXQq4036Jz9bwbiwMbqenr6SvQcK+M3Lczi3V5sy8w0w/u2FIes/85/In/h535AgXzRxU1HVwqqJI/jH5yuL9zscl/49snF4/Y59IYEB4LOlm+nYMvS+9h0oYOH6HfTr2ILnZ6wq9W89YcoiPrz1lFLvZ+e+Awx9tPTqj1UTR5TZW+/ou6cVLzdrUIftew5w9YmZZK/eyuSbBoekdc6FdN3+7aQ5vDV3PVcO6sT+/AJe/moNf7usL3PX7GDMsO4hacMD63Nfevf8x4uOo13z+tw8aS6PXdKbQUe2ishjeO4PFBRy/5RFXNivHQcKHI9/ksOgLi1pUq8O/To1p0tGozLLh49+sJSBXVpy1OFNWL55F9t253HGUa2L9x9MSSseCR9byTk3FZgatm18YHk2XnVTwt1//rFc2r8jZ5cxCqlUracDX3Thni+jKgsiv2CDTo/yFnbQK9lrufbkziHbiqoAHqhAQ3N4L6GHp5X0MruqnPceFoU15nYeV1LKKK30V+Syp2dRr05a8foVz3xV5tN80Lvfbgiphnt+xmq+yNnM8tzdZDSuy5FlVD1uivJuzNert/LH95bw8EW9qJ1WdjXZ3ryCkC7U+/MLqFs7LWraoraoZ74o+Wy8OLPks7Bx5z7WbdtLVieviqyoK3Pw/Ne94P0eL+rXrswXRN+e5x0bLDnf9uo8NuzYx58u7sV5vQOBPiywfLT4B56bsTqkyvXj7zYBUK9OLb67b3iZnVAe+2gZj320LGRb7/bNmLtmOwvuPYt5ayq3Xao8Vll1d8mUlZXlsrMrb+Kd0qoARKqjroc1KreasCq8fv0gLnwivvcysjo2J3t19N4+Q3u25v1SOmIAjDy+PZNmRx9e5ecDOpT5YinArUO68ecPIl9y/MNPj+X2N8tud1x471khpZoij1zcK6QHWDT/ufkkhj8W+eA5bngP3pm/ngXrKt4e8buzurM/v5D9Bwq4qF87urZuXOFjg8zsa+dcVtR9Cg6RFBxEJJp7ftKz3GrV0jRMTzuoHlalueucnlwzODOuY8sKDjW2K2tVGuzXL34+5rQk50REqpN4AwMcXNfbsuRUUalRwSGKx3/el5d+OYB2zRtw1znho3uIiFQftcvo2nwwFByiaFq/TnHvhGsGZ3L2sYcD8McLj0tmtkREIqQpOCRPo7pep66mDeow6/YzuHVItyTnSETEs3t/+fPUx0PBoQLuPKcntw3pxplHtaZ1k3r85oyuyc6SiAgAM1dGH3zzYCk4VECTenUYfUbXkOLbvPFDeelXA0LSHd+pOQ9fdBxv33hiorMoIinq2pM6l58oDgl/Ce5Q0bRBHQZ1acX7t5xMi4bptGiQXjzmzbw4BvMSEYnH+X3iGti6XAoOB6lblJdPor05cniTeow+40iW/bCL6ctyWZ4b35C9IiJBjevVqZLzKjhUgWDfgfHn9KRt8/qcdfThIWm27s5j1FMzWRJlWGURkWRTm0MVOK5dU+4ccRTzxg/l6sGZEYEBoEXDdC7O8oaQeuemwbzy64H0ODz6K/CdWzXkb5f1BaBOmrFq4gie+HnfcvNxTNsmACHnLW9Y6qrSuYyB60Sk+lFwqAJmxi9P6kzTBmUX964ZnMms28/g2HZN6Z/ZgndGD+bBC45lxrjTueHULsy6/Qyevep4PrrtFAZ29t67uOyEjgA0qucV+gYf6bV7XNC3LeOG9yg+d/9OLZgy+iRWTRzBe789uXj72zeeWPwGOHjjvUTz+ZjTmPbbk/nglpJjl94/nIv6tQtJU1EPXXRccbACbwjp0rx23cCQ9YqMalpVrj+1S9zH3n52j/ITleLCvgc39uTo048sXlbvOomHgkMSmRmtm5R8SdZJq8Wo/h04oml9fj+sB62b1OPU7odhZjRtUIev7jiDO/yhoXu3b0b7FvW5dWg3urVuzJ9/1ptfn9KFj247hdevHxjRkyoo+AV/1BFN+O6+YfzvpX04v3cbLuzbjqcvz6Jd8wZ0P7xxyIBe6bVr8cuTSsZwade8AY9e0ov3bzm5+Ev00gEdWDVxBKsmjuBvl/WjmR8g69auxZTRJYHovVtO5tmrjqdfYD4BgL9d1rd4dM2S35M3xHOR35zRlY9uixwu+ug2Tfj75aHDxLRqlB5ybO1axvTfRw9qL1wzgAv6hjbujRnWgxsCAWLJ/cOiHhvNVSdm8j+j+hSvL7j3rOLlIw8re7Kl3u2bhuT7fy/tQ7fWFZugKbNVQ24b2r14/dYh3Zhwnjfq/cndyp81cd74obRuUrd4/clf9KvQdQG+uWsIVw7qVLw+564hFT728oEduerEkmPDHxJicfaxh9M9zsHoADq0aFDhtA/8NHQO+l/GMM7RL/yHvSLBB7ygM486jOZhD5s3ntaFt6qwZ6SCQw1yWON61E7z/mSN69Vh+u9PD5mJDKBLRiP6dWxRnC6a8/u05XdndeeFa7wAUq9OGucc14a/jOzDn37WizN7ti712B6HN6F1k7oc7ge1n/ZpR7fWjfn9Wd155dcDeeD8kv8ow445vHiSlVph06Slp9Xi1O6H8fr1g3jxlwO4oE9bpv/+NIYdcwQAE847ml7tvOGkw9//bNkwnS4ZjVg1cQS3nFnyQuJLvzqBIT1b88YNgxh9+pG8cM2AkIAE0KxBOu1bNGDVxBE8NrJ38fYpowczuGsr6tSK/L0FOxjUrZ3Gqokj+O2ZJU/jF/Rpy/I/nM2s288IOa52LWPEsUcUrzeqW5sl9w8j54HhfHjrKfzjiixeu24g8+4eyr+vPSH0omG/r+YN0pky+iQWTTiLE49sWbx93t1DuSSrPVN/cxKPXNwr6u8L4PKBnVg1cQTPX92fZ67MYlT/Dvz3d6fyzV1DWHL/MGaOK8l70wZ16NiipBpwaM/WPHJxr5AJc2aMO512zSMn0GnRMJ0TOpfkr3nD9JDfM8Cp3TMYM6wHvcOqOC8f2JG7f1IydUufDs2ZN35oxDWCpaIiF/drFxJMT+jckrdvivzifGxkb07plsH4c3pyceAhKXhs8wZ1mPKbwRHHhg/pXuTnAzryq8BDU/jcHgDn925Dk3qRTbz3nX8MM8adXrz+61O6FAfyoKd+kcWcsN9FxxYNI36HlUnBIUX888rjeScwScqNpx3J4K6RE5hE8/aNJ/LXwBPwrNvPZGbYF6GZ0T+zRchEKgCHNfaeQOvV8T5qOQ8MZ+74ISFzEJx4ZCv+fIk37WaRywd24vlrBtC7fTNu9gPAM1dmcWr3jOKqNfD+w3Zo0YB/XJFF0/rek1XfDs25bWh3BndtxeF+9VVR/t+4flDxsUP8IHhRv3bF8xp0aBn5xHisv29YoO3ot2d2o2G6dw/3//QY0mp5pcDgl6yZkVbLeO26gdzzE2+Mrrq104oD9xlHtSarUwua1q/DgM4tmXTtCQzwp+0M/4Lv3b4Z6bVr0SC9Ng9f5AWBX5/cmab16/DQRcfRs00Terf352bwD54yenDEFzPA6T1a8+AFx9KxZUNaNEynbu204t9TkZ5tvCrAF385ADPjon7t+GJsyZdYq0Z1+XzM6RFPzd75D2Pk8e2Lg+V5vduGfPledWIm158a+dRbNED0mGE9mHTtCaTVsoiq2dGnH8ltQ7uHnA9KYmnRDG6X9u8Q8hkrcl7vtjx3dX+uHpzJw34wDfezrPY0qVcnJAgD3H72UXx1xxkhn4MihzX2fn/dWjcirZbxz6uOD9n/l5F9yL5zCO8HqmmLpIc9yF0+sFPI+pL7h0WfGrZqRs0opt5KKeK0HofFfWyv9s3ibsj+yyV9+GDxDxx5mFfEr51Wi2YN0it0bNP6dUK+QE7v0ZrTe4SWauqnp/FZKdVEQT/p1YafhLVdNEivzYxxp9OyYUkVynWndKHnEU1oVK82hf5MZWcfewSf/e60iMCxcEJkFdPhTevx5g2D+MSf5AUgq1OLiKqyaE7o3JLOGY2YFZg+c9btZ5CeVouGdUv+q7ZpVj/iyzGo6DvjmLZNQybzicXtZx/Fub3bRJRM37lpMI3q1aaO/4V2Xu+2fLoklw8C8y+k167FxCjjkA3s3JJFG3ZySilVW0UltPB2nmevOp5H3l/CgnU7Q0qKabWseDY58+963vihOFxxAM5s1ZCVm71u4+VVwfzn5pN4d/6G4uFxjmjqlYwevOBYfuq/S3BY43rcfvZRbNuTF/J3unpwJoc1qRu1fayoii69di26tW7MP686nqv8qUYBWjaqy+OX9i0OyOGCkyB9c9cQ7nzrW6Z+u7GqY4M3TV4if4BhwBIgBxgbZX9d4N/+/llAp/LO2a9fPydyKFi0fofrfudUt377npiP3Xcg3w37y2fui5zcuK494IEP3c0vfxPXsf3ue991HDMlrmNvfPFr13HMFLdm6+5S0xQUFLr9BwpCtu3Ny3evf73GdRwzxT30n8VRj9uxN899v2W3yy8ojLq/45gp7qInvoi6b/f+A+7Nb9aWmqeL//alG/nkjKj7Nu3c5zqOmeLemrPW7dmfH7F/0IMflfn76jhmSqm/k/cWbHAdx0xxSzbuLPX4isKbnjnq92pCJ/sxszRgKTAEWAvMBkY55xYF0twAHOecu87MRgI/dc5dUtZ5K3uyHxGJzc59B9ibVxDSwaKi9uTlM3fNdgZ1qVg1Z5Bzjn/PXsNP+7YtdZrRsqze4k2J2iA9sZUouT/uZ+Xm3fTPjF6ifGHmao5t27TUEnthoYte1RSjajMTnJkNBO5xzp3lr48DcM49GEgzzU8zw8xqAxuBDFdGRhUcRERiV51mgmsLBCd/Xetvi5rGOZcP7ABaIiIiCVNjeyuZ2bVmlm1m2bm5ucnOjojIISXRwWEd0D6w3s7fFjWNX63UFIgYsNw595RzLss5l5WRUf6LPSIiUnGJDg6zga5mlmlm6cBIYHJYmsnAFf7yRcDHZbU3iIhI5UtoE71zLt/MbgKmAWnAM865hWY2Aa9L1WTgH8C/zCwH2IoXQEREJIES/hKcc24qMDVs2/jA8j7g4kTnS0REStTYBmkREak6Cg4iIhIhoS/BVRUzywVWx3l4K2BzJWYnmQ6Ve9F9VD+Hyr0cKvcBlXMvHZ1zUbt7HhLB4WCYWXZpbwjWNIfKveg+qp9D5V4OlfuAqr8XVSuJiEgEBQcREYmg4ABPJTsDlehQuRfdR/VzqNzLoXIfUMX3kvJtDiIiEkklBxERiZDSwcHMhpnZEjPLMbOxyc5PODN7xsw2mdmCwLYWZvaBmS3z/23ubzcz+x//XuabWd/AMVf46ZeZ2RXRrlXF99HezD4xs0VmttDMbq7B91LPzL4ys3n+vdzrb880s1l+nv/tjx2GmdX113P8/Z0C5xrnb19iZmcl+l78PKSZ2Rwzm1LD72OVmX1rZnPNLNvfVhM/X83M7DUz+87MFpvZwKTdR2lTxB3qP3hjOy0HOgPpwDygZ7LzFZbHk4G+wILAtj/iT68KjAUe8pfPBv6DN4XwCcAsf3sLYIX/b3N/uXmC7+MIoK+/3BhvNsCeNfReDGjkL9fBm8r2BOAVYKS//W/A9f7yDcDf/OWRwL/95Z7+Z64ukOl/FtOS8Bm7FXgJmOKv19T7WAW0CttWEz9fzwG/9JfTgWbJuo+E/gGr0w8wEJgWWB8HjEt2vqLksxOhwWEJcIS/fASwxF9+Em/K1ZB0wCjgycD2kHRJuqe38aaKrdH3AjQAvgEG4L2MVDv8s4U3yORAf7m2n87CP2/BdAnMfzvgI+B0YIqfrxp3H/51VxEZHGrU5wtveoKV+G3Byb6PVK5WqsisdNVRa+fcBn95I9DaXy7tfqrVffrVEX3wnrhr5L34VTFzgU3AB3hPy9udN3NheL5Km9mwOtzLX4DfA4X+ektq5n0AOOB9M/vazK71t9W0z1cmkAv806/qe9rMGpKk+0jl4FDjOe+xoMZ0NzOzRsDrwG+dczuD+2rSvTjnCpxzvfGevPsDPZKbo9iZ2TnAJufc18nOSyUZ7JzrCwwHbjSzk4M7a8jnqzZeNfITzrk+wG68aqRiibyPVA4OFZmVrjr6wcyOAPD/3eRvL+1+qsV9mlkdvMDwonPuDX9zjbyXIs657cAneNUvzcybuTA8X6XNbJjsezkRONfMVgGT8KqWHqPm3QcAzrl1/r+bgDfxgnZN+3ytBdY652b566/hBYuk3EcqB4eKzEpXHQVnyrsCr/6+aPvlfg+GE4AdflF0GjDUzJr7vRyG+tsSxswMbxKnxc65Pwd21cR7yTCzZv5yfby2k8V4QeIiP1n4vUSb2XAyMNLvBZQJdAW+SshNAM65cc65ds65Tnif/Y+dcz+nht0HgJk1NLPGRct4n4sF1LDPl3NuI7DGzLr7m84AFiXtPhLdcFSdfvBa+5fi1Rnfkez8RMnfy8AG4ADeU8U1ePW8HwHLgA+BFn5aAx737+VbICtwnquBHP/nqiTcx2C8ovB8YK7/c3YNvZfjgDn+vSwAxvvbO+N9KeYArwJ1/e31/PUcf3/nwLnu8O9xCTA8iZ+zUynprVTj7sPP8zz/Z2HR/+Ua+vnqDWT7n6+38HobJeU+9Ia0iIhESOVqJRERKYWCg4iIRFBwEBGRCAoOIiISQcFBREQiKDiI+MzsSjNzgZ8CM1tnZq8E+p7Her6r48zLs2a2Np5jRSpD7fKTiKSci/HeK0kDugB3AR+Z2dHOuR0xnOdKvP9jz1R6DkWqmIKDSKS5zrkcf/kLM1uPN8DeILwhkkUOeapWEilf0SCBdQDM7Egz+5eZrTSzvWa2wsyeKJqExU/zKXAKcGKgmurTwP5M/xwbzWy/f47Hwi9sZn3MbLqZ7fEnbrmuSu9UxKeSg0ikNH9wuTS8oRn+gDfY2af+/jZ4QyL/Ftjmp7kdmIo3CB94k+O84J/j1/62neAFBrwhKPYA4/GGReiANwZOUBO8iXj+AkwArgKeMLMlzrlPKuleRaJScBCJ9F3Y+nrgHOcPM+6c+wz4rGinmX2JN4bNdDPr45yb45xbZGY78SbOmRl2vnuB+kAv59z6wPbnwtI1Bm4oCgRm9hlwFt5kLgoOUqVUrSQS6afA8XjDPp+PNzLmVDM7CsDM0s3sdvPm+d2LNzDidP/YivRqGoo30N36ctLtCZYQnHP78QaK7BDLzYjEQyUHkUgLAg3SmNn7eNVI9wCXAA8Co/Gqer4EfsQbM/8NvNFLy9MSrzdUebZF2ba/gtcQOSgKDiLlcM7tNbMVeMN1gzf/wfPOufuL0viz3FXUZmrGlLSSwlStJFIOM2uA975Drr+pAV5VUtBVUQ7dj9e2EO594Jyi2b1EqiOVHEQi9TazVniTqRwB3AS0AP7q738PuMLMvsVriL4A7x2IcIuAG8zsErwJWX50zi0B7sab7OhLM/uDf462wDDn3GVVd1siFafgIBLp1cByLt6Mb8Occ0VTLY7GCxwP+OtT8XoQhU+P+RBeA/XTQCPgv8CpzrlV/rSO9+O1XzTCm+P3bUSqCc0EJyIiEdTmICIiERQcREQkgoKDiIhEUHAQEZEICg4iIhJBwUFERCIoOIiISAQFBxERiaDgICIiEf4/1llSHQC+DB0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(lossValuesTrainingSet)\n",
    "plt.xlabel(\"Batch\", size = 16,)\n",
    "plt.ylabel(\"Loss\", size = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5a8b246",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loss')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(lossValuesEpoch)\n",
    "plt.xlabel(\"Epoch\", size = 16,)\n",
    "plt.ylabel(\"Loss\", size = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d21ce27d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x19e14e58148>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(lossValuesDevSetAllEpoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c053e165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test set\n",
    "# PLANTEAMOS UN CONJUNTO DE TESTEO ROTADO PARA VER LOS RESULTADOS\n",
    "\n",
    "trainingSet = dict([('input',train_noisyImage), ('output', train_groundTruth)])\n",
    "\n",
    "inputsTestSet = torch.from_numpy(trainingSet['input'][:,:,:,:])\n",
    "groundTruthTestSet = torch.from_numpy(trainingSet['output'][:,:,:,:])\n",
    "\n",
    "inputsTestSet = torchvision.transforms.functional.rotate(inputsTestSet,15)\n",
    "groundTruthTestSet = torchvision.transforms.functional.rotate(groundTruthTestSet,15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "14101868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21297317780554295\n",
      "MSE antes de pasar por la red [0.35828256607055664]\n",
      "MSE dsp de pasar por la red [0.08926944434642792]\n"
     ]
    }
   ],
   "source": [
    "## Testeo con DataSet Rotado\n",
    "outArray = []\n",
    "\n",
    "#for i in range(0,inputsTestSet.shape[0]):\n",
    "for i in range(0,10):\n",
    "    inputs =  inputsTestSet[i]\n",
    "    inputs = torch.unsqueeze(inputs, dim = 0)\n",
    "    out = unet(inputs)\n",
    "    outArray.append(out)\n",
    "    \n",
    "# MSE antes y dsp\n",
    "\n",
    "mseBef = []\n",
    "mseAft = []\n",
    "\n",
    "# Antes\n",
    "img1 = torch.unsqueeze(inputsTestSet[9], dim = 0)\n",
    "img1 = (img1).detach().numpy()\n",
    "\n",
    "img2 = torch.unsqueeze(groundTruthTestSet[9], dim = 0)\n",
    "img2 = (img2).detach().numpy()\n",
    "mseBef.append(MSE(img1[0,:,:],img2[0,:,:]))\n",
    "\n",
    "# Dsp\n",
    "imgOut = (outArray[9]).detach().numpy()\n",
    "mseAft.append(MSE(imgOut[0,:,:],img2[0,:,:]))\n",
    "\n",
    "print('MSE antes de pasar por la red',mseBef)\n",
    "print('MSE dsp de pasar por la red',mseAft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0a75a36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar imagenes (opcional)\n",
    "\n",
    "img_inputs = sitk.GetImageFromArray(img1[0,:,:])\n",
    "sitk.WriteImage(img_inputs,'Entrada.nii')\n",
    "\n",
    "img_inputs = sitk.GetImageFromArray(imgOut[0,:,:])\n",
    "sitk.WriteImage(img_inputs,'Salida.nii')\n",
    "\n",
    "img_out = sitk.GetImageFromArray(img2[0,:,:])\n",
    "sitk.WriteImage(img_out,'groundTruthUnet.nii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "313cf6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TESTEO CON dataSet2\n",
    "\n",
    "# Create dictionaries with training sets:\n",
    "testDataSet1 = dict([('input',img_noisyDataSet1), ('output', img_groundTruth)])\n",
    "\n",
    "inputsTestSet1 = torch.from_numpy(testDataSet1['input'][:,:,:,:])\n",
    "groundTruthTestSet1 = torch.from_numpy(testDataSet1['output'][:,:,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "9178e9e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE antes de pasar por la red [0.6936010122299194]\n",
      "MSE dsp de pasar por la red [0.3665635585784912]\n"
     ]
    }
   ],
   "source": [
    "## Testeo ....\n",
    "outArray2 = []\n",
    "\n",
    "#for i in range(0,inputsTestSet.shape[0]):\n",
    "for i in range(0,40):\n",
    "    inputs =  inputsTestSet1[i]\n",
    "    inputs = torch.unsqueeze(inputs, dim = 0)\n",
    "    out = unet(inputs)\n",
    "    outArray1.append(out)\n",
    "    \n",
    "# MSE antes y dsp\n",
    "\n",
    "mseBef2 = []\n",
    "mseAft2 = []\n",
    "\n",
    "# Antes\n",
    "img1 = torch.unsqueeze(inputsTestSet1[30], dim = 0)\n",
    "img1 = (img1).detach().numpy()\n",
    "\n",
    "img2 = torch.unsqueeze(groundTruthTestSet1[30], dim = 0)\n",
    "img2 = (img2).detach().numpy()\n",
    "mseBef2.append(MSE(img1[0,:,:],img2[0,:,:]))\n",
    "\n",
    "# Dsp\n",
    "imgOut = (outArray1[30]).detach().numpy()\n",
    "mseAft2.append(MSE(imgOut[0,:,:],img2[0,:,:]))\n",
    "\n",
    "print('MSE antes de pasar por la red',mseBef2)\n",
    "print('MSE dsp de pasar por la red',mseAft2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "50cd3dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_inputs = sitk.GetImageFromArray(img1[0,:,:])\n",
    "sitk.WriteImage(img_inputs,'EntradaDataSet2.nii')\n",
    "\n",
    "img_inputs = sitk.GetImageFromArray(imgOut[0,:,:])\n",
    "sitk.WriteImage(img_inputs,'SalidaDataSet2.nii')\n",
    "\n",
    "img_out = sitk.GetImageFromArray(img2[0,:,:])\n",
    "sitk.WriteImage(img_out,'groundTruthUnetDataSet2.nii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6baa994a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSE materia gris y materia blanca #\n",
    "\n",
    "nroSliceDS1 = 9\n",
    "\n",
    "nroSliceDS2 = 30\n",
    "\n",
    "# Antes de pasar por la red\n",
    "\n",
    "# dataSet1\n",
    "greyMatterNoisyDataSet1Antes = inputsTestSet1[nroSliceDS1] * ((groundTruthTestSet1[nroSliceDS1]==8)*1.0)\n",
    "whiteMatterNoisyDataSet1Antes = inputsTestSet1[nroSliceDS1] * ((groundTruthTestSet2[nroSliceDS1]==2)*1.0)\n",
    "\n",
    "greyMatterNoisyDataSet1Dsp = outArray1[nroSliceDS1] * ((groundTruthTestSet1[nroSliceDS1]==8)*1.0)\n",
    "whiteMatterNoisyDataSet2Dsp = outArray2[nroSliceDS1] * ((groundTruthTestSet1[nroSliceDS1]==2)*1.0)\n",
    "\n",
    "\n",
    "# dataSet2 rotado\n",
    "greyMatterNoisyDataSet2RotateAntes = inputsTestSet[nroSliceDS2] * ((groundTruthTestSet[nroSlice2]==8)*1.0)\n",
    "whiteMatterNoisyDataSet2RotateAntes = inputsTestSet[nroSliceDS2] * ((groundTruthTestSet[nroSlice2]==2)*1.0)\n",
    "\n",
    "greyMatterNoisyDataSet2RotateDsp = outArray[nroSliceDS2] * ((groundTruthTestSet[nroSlice2]==8)*1.0)\n",
    "whiteMatterNoisyDataSet2RotateDsp = outArray[nroSliceDS2] * ((groundTruthTestSet[nroSlice2]==2)*1.0)\n",
    "\n",
    "\n",
    "\n",
    "# Antes y dsp dataSet1\n",
    "\n",
    "print('DataSet1')\n",
    "\n",
    "img1 = torch.unsqueeze(greyMatterNoisyDataSet1Antes, dim = 0)\n",
    "img1 = (img1).detach().numpy()\n",
    "img2 = torch.unsqueeze(((groundTruthTestSet1[nroSliceDS1]==8)*1.0), dim = 0)\n",
    "img2 = (img2).detach().numpy()\n",
    "cantPix = np.count_nonzero(img2)\n",
    "img_inputs = sitk.GetImageFromArray(img1[0,:,:])\n",
    "sitk.WriteImage(img_inputs,'EntradaDataSet1GM.nii')\n",
    "\n",
    "img_inputs = sitk.GetImageFromArray(img2[0,:,:])\n",
    "sitk.WriteImage(img_inputs,'MASKDataSet1GM.nii')\n",
    "\n",
    "print('Antes GM',MSE(img1[0,:,:],img2[0,:,:], cantPix))\n",
    "\n",
    "img1 = (greyMatterNoisyDataSet1Dsp).detach().numpy()\n",
    "img2 = torch.unsqueeze(((groundTruthTestSet1[nroSliceDS1]==8)*1.0), dim = 0)\n",
    "img2 = (img2).detach().numpy()\n",
    "cantPix = np.count_nonzero(img2)\n",
    "\n",
    "print('Despues GM',MSE(img1[0,:,:],img2[0,:,:]), cantPix)\n",
    "\n",
    "img1 = torch.unsqueeze(whiteMatterNoisyDataSet1Antes, dim = 0)\n",
    "img1 = (img1).detach().numpy()\n",
    "img2 = torch.unsqueeze(((groundTruthTestSet1[nroSliceDS1]==2)*1.0), dim = 0)\n",
    "img2 = (img2).detach().numpy()\n",
    "cantPix = np.count_nonzero(img2)\n",
    "\n",
    "img_inputs = sitk.GetImageFromArray(img1[0,:,:])\n",
    "sitk.WriteImage(img_inputs,'EntradaDataSet1WM.nii')\n",
    "\n",
    "img_inputs = sitk.GetImageFromArray(img2[0,:,:])\n",
    "sitk.WriteImage(img_inputs,'MASKDataSet1WM.nii')\n",
    "\n",
    "print('Antes WM',MSE(img1[0,:,:],img2[0,:,:]),cantPix)\n",
    "\n",
    "\n",
    "img1 = (whiteMatterNoisyDataSet1Dsp).detach().numpy()\n",
    "img2 = torch.unsqueeze(((groundTruthTestSet1[nroSliceDS1]==2)*1.0), dim = 0)\n",
    "img2 = (img2).detach().numpy()\n",
    "cantPix = np.count_nonzero(img2)\n",
    "\n",
    "print('Despues WM',MSE(img1[0,:,:],img2[0,:,:]), cantPix)\n",
    "\n",
    "\n",
    "# Antes y dsp dataSet2\n",
    "\n",
    "print('DataSet2')\n",
    "\n",
    "img1 = torch.unsqueeze(greyMatterNoisyDataSet2RotateAntes, dim = 0)\n",
    "img1 = (img1).detach().numpy()\n",
    "img2 = torch.unsqueeze(((groundTruthTestSet[nroSliceDS2]==8)*1.0), dim = 0)\n",
    "img2 = (img2).detach().numpy()\n",
    "cantPix = np.count_nonzero(img2)\n",
    "\n",
    "print('Antes GM',MSE(img1[0,:,:],img2[0,:,:]), cantPix)\n",
    "\n",
    "img1 = (greyMatterNoisyDataSet2RotateDsp).detach().numpy()\n",
    "img2 = torch.unsqueeze(((groundTruthTestSet[nroSliceDS2]==8)*1.0), dim = 0)\n",
    "img2 = (img2).detach().numpy()\n",
    "cantPix = np.count_nonzero(img2)\n",
    "\n",
    "print('Despues GM',MSE(img1[0,:,:],img2[0,:,:]), cantPix)\n",
    "\n",
    "img1 = torch.unsqueeze(whiteMatterNoisyDataSet2RotateAntes, dim = 0)\n",
    "img1 = (img1).detach().numpy()\n",
    "img2 = torch.unsqueeze(((groundTruthTestSet[nroSliceDS2]==2)*1.0), dim = 0)\n",
    "img2 = (img2).detach().numpy()\n",
    "cantPix = np.count_nonzero(img2)\n",
    "\n",
    "img_inputs = sitk.GetImageFromArray(img1[0,:,:])\n",
    "sitk.WriteImage(img_inputs,'EntradaDataSet2WM.nii')\n",
    "\n",
    "img_inputs = sitk.GetImageFromArray(img2[0,:,:])\n",
    "sitk.WriteImage(img_inputs,'MASKDataSet2WM.nii')\n",
    "\n",
    "print('Antes WM',MSE(img1[0,:,:],img2[0,:,:]), cantPix)\n",
    "\n",
    "img1 = (whiteMatterNoisyDataSet2RotateDsp).detach().numpy()\n",
    "img2 = torch.unsqueeze(((groundTruthTestSet[nroSliceDS2]==2)*1.0), dim = 0)\n",
    "img2 = (img2).detach().numpy()\n",
    "cantPix = np.count_nonzero(img2)\n",
    "\n",
    "img_inputs = sitk.GetImageFromArray(img1[0,:,:])\n",
    "sitk.WriteImage(img_inputs,'EntradaDataSet2WM.nii')\n",
    "\n",
    "img_inputs = sitk.GetImageFromArray(img2[0,:,:])\n",
    "sitk.WriteImage(img_inputs,'MASKDataSet2WM.nii')\n",
    "\n",
    "print('Despues WM',MSE(img1[0,:,:],img2[0,:,:]),cantPix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ae2ff4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
